<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Architectures Â· NeuralEstimators.jl</title><meta name="title" content="Architectures Â· NeuralEstimators.jl"/><meta property="og:title" content="Architectures Â· NeuralEstimators.jl"/><meta property="twitter:title" content="Architectures Â· NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../core/">Core</a></li><li class="is-active"><a class="tocitem" href>Architectures</a><ul class="internal"><li><a class="tocitem" href="#Layers"><span>Layers</span></a></li></ul></li><li><a class="tocitem" href="../summarystatistics/">User-defined summary statistics</a></li><li><a class="tocitem" href="../activationfunctions/">Output activation functions</a></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Architectures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Architectures</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/architectures.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ï„</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Architectures"><a class="docs-heading-anchor" href="#Architectures">Architectures</a><a id="Architectures-1"></a><a class="docs-heading-anchor-permalink" href="#Architectures" title="Permalink"></a></h1><ul><li><a href="#NeuralEstimators.DeepSet"><code>NeuralEstimators.DeepSet</code></a></li><li><a href="#NeuralEstimators.GNN"><code>NeuralEstimators.GNN</code></a></li><li><a href="#NeuralEstimators.UniversalPool"><code>NeuralEstimators.UniversalPool</code></a></li><li><a href="#NeuralEstimators.WeightedGraphConv"><code>NeuralEstimators.WeightedGraphConv</code></a></li></ul><p>Although the user is free to construct their neural estimator however they see fit (i.e., using arbitrary <code>Flux</code> code), <code>NeuralEstimators</code> provides several useful architectures described below that are specifically relevant to neural estimation. See also the convenience constructor <a href="../utility/#NeuralEstimators.initialise_estimator"><code>initialise_estimator</code></a>.  </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.DeepSet" href="#NeuralEstimators.DeepSet"><code>NeuralEstimators.DeepSet</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSet(Ïˆ, Ï•, a; S = nothing)
DeepSet(Ïˆ, Ï•; a::String = &quot;mean&quot;, S = nothing)</code></pre><p>The DeepSets representation,</p><p class="math-container">\[Î¸Ì‚(ğ™) = Ï•(ğ“(ğ™)),	â€‚	â€‚ğ“(ğ™) = ğš(\{Ïˆ(ğ™áµ¢) : i = 1, â€¦, m\}),\]</p><p>where ğ™ â‰¡ (ğ™â‚&#39;, â€¦, ğ™â‚˜&#39;)&#39; are independent replicates from the statistical model, <code>Ïˆ</code> and <code>Ï•</code> are neural networks, and <code>a</code> is a permutation-invariant function. Expert summary statistics can be incorporated as,</p><p class="math-container">\[Î¸Ì‚(ğ™) = Ï•((ğ“(ğ™)&#39;, ğ’(ğ™)&#39;)&#39;),\]</p><p>where <code>S</code> is a function that returns a vector of user-defined summary statistics. These user-defined summary statistics are typically provided either as a <code>Function</code> that returns a <code>Vector</code>, or a vector of such functions.</p><p>To ensure that the architecture is agnostic to the sample size <span>$m$</span>, the aggregation function <code>a</code> must aggregate over the replicates. It can be specified as a positional argument of type <code>Function</code>, or as a keyword argument with permissible values <code>&quot;mean&quot;</code>, <code>&quot;sum&quot;</code>, and <code>&quot;logsumexp&quot;</code>.</p><p><code>DeepSet</code> objects act on data of type <code>Vector{A}</code>, where each element of the vector is associated with one data set (i.e., one set of independent replicates from the statistical model), and where the type <code>A</code> depends on the form of the data and the chosen architecture for <code>Ïˆ</code>. As a rule of thumb, when <code>A</code> is an array, the replicates are stored in the final dimension. The final dimension is usually the &#39;batch&#39; dimension, but batching with <code>DeepSet</code> objects is done at the data set level (i.e., sets of replicates are batched together). For example, with gridded spatial data and <code>Ïˆ</code> a CNN, <code>A</code> should be a 4-dimensional array, with the replicates stored in the 4áµ—Ê° dimension.</p><p>Set-level information, <span>$ğ±$</span>, that is not a function of the data can be passed directly into the outer network <code>Ï•</code> in the following manner,</p><p class="math-container">\[Î¸Ì‚(ğ™) = Ï•((ğ“(ğ™)&#39;, ğ±&#39;)&#39;),	â€‚	â€‚\]</p><p>or, in the case that expert summary statistics are also used,</p><p class="math-container">\[Î¸Ì‚(ğ™) = Ï•((ğ“(ğ™)&#39;, ğ’(ğ™)&#39;, ğ±&#39;)&#39;).	â€‚\]</p><p>This is done by providing a <code>Tuple{Vector{A}, Vector{Vector}}</code>, where the first element of the tuple contains a vector of data sets and the second element contains a vector of set-level information (i.e., one vector for each data set).</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

n = 10 # dimension of each replicate
p = 4  # number of parameters in the statistical model

# Construct the neural estimator
S = samplesize
qâ‚› = 1  # dimension of expert summary statistic
qâ‚œ = 16 # dimension of neural summary statistic
w = 16 # width of each hidden layer
Ïˆ = Chain(Dense(n, w, relu), Dense(w, qâ‚œ, relu));
Ï• = Chain(Dense(qâ‚œ + qâ‚›, w, relu), Dense(w, p));
Î¸Ì‚ = DeepSet(Ïˆ, Ï•, S = S)

# Toy data
Z = [rand(Float32, n, m) for m âˆˆ (3, 4)]; # two data sets containing 3 and 4 replicates

# Apply the data
Î¸Ì‚(Z)

# Inference with set-level information
qâ‚“ = 2 # dimension of set-level vector
Ï•  = Chain(Dense(qâ‚œ + qâ‚› + qâ‚“, w, relu), Dense(w, p));
Î¸Ì‚  = DeepSet(Ïˆ, Ï•; S = S)
x  = [rand(Float32, qâ‚“) for _ âˆˆ eachindex(Z)]
Î¸Ì‚((Z, x))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/2acc9133073b3706f010d796ce3f616981660199/src/Architectures.jl#L48-L132">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.GNN" href="#NeuralEstimators.GNN"><code>NeuralEstimators.GNN</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GNN(propagation, readout, Ï•, a; S = nothing)
GNN(propagation, readout, Ï•; a::String = &quot;mean&quot;, S = nothing)</code></pre><p>A graph neural network (GNN) designed for parameter point estimation.</p><p>The <code>propagation</code> module transforms graphical input data into a set of hidden-feature graphs; the <code>readout</code> module aggregates these feature graphs into a single hidden feature vector of fixed length; the function <code>a</code>(â‹…) is a permutation-invariant aggregation function, and <code>Ï•</code> is a neural network. Expert, user-defined summary statistics <code>S</code> can also be utilised, as described in <a href="#NeuralEstimators.DeepSet"><code>DeepSet</code></a>.</p><p>The data should be stored as a <code>GNNGraph</code> or <code>Vector{GNNGraph}</code>, where each graph is associated with a single parameter vector. The graphs may contain sub-graphs corresponding to independent replicates from the model.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux
using Flux: batch
using GraphNeuralNetworks
using Statistics: mean

# Propagation module
d = 1      # dimension of response variable
nh = 32    # dimension of node feature vectors
propagation = GNNChain(GraphConv(d =&gt; nh), GraphConv(nh =&gt; nh), GraphConv(nh =&gt; nh))

# Readout module (using &quot;universal pooling&quot;)
nt = 64   # dimension of the summary vector for each node
no = 128  # dimension of the final summary vector for each graph
readout = UniversalPool(Dense(nh, nt), Dense(nt, nt))

# Alternative readout module (using the elementwise average)
# readout = GlobalPool(mean); no = nh

# Mapping module
p = 3     # number of parameters in the statistical model
w = 64    # width of layers used for the mapping network Ï•
Ï• = Chain(Dense(no, w, relu), Dense(w, w, relu), Dense(w, p))

# Construct the estimator
Î¸Ì‚ = GNN(propagation, readout, Ï•)

# Apply the estimator to:
# 	1. a single graph,
# 	2. a single graph with sub-graphs (corresponding to independent replicates), and
# 	3. a vector of graphs (corresponding to multiple spatial data sets).
gâ‚ = rand_graph(11, 30, ndata=rand(d, 11))
gâ‚‚ = rand_graph(13, 40, ndata=rand(d, 13))
gâ‚ƒ = batch([gâ‚, gâ‚‚])
Î¸Ì‚(gâ‚)
Î¸Ì‚(gâ‚ƒ)
Î¸Ì‚([gâ‚, gâ‚‚, gâ‚ƒ])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/2acc9133073b3706f010d796ce3f616981660199/src/Graphs.jl#L605-L661">source</a></section></article><h2 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.WeightedGraphConv" href="#NeuralEstimators.WeightedGraphConv"><code>NeuralEstimators.WeightedGraphConv</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WeightedGraphConv(in =&gt; out, Ïƒ=identity; aggr=mean, bias=true, init=glorot_uniform)</code></pre><p>Same as regular <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/stable/api/conv/#GraphNeuralNetworks.GraphConv"><code>GraphConv</code></a> layer, but where the neighbours of a node are weighted by their spatial distance to that node.</p><p><strong>Arguments</strong></p><ul><li><code>in</code>: The dimension of input features.</li><li><code>out</code>: The dimension of output features.</li><li><code>Ïƒ</code>: Activation function.</li><li><code>aggr</code>: Aggregation operator for the incoming messages (e.g. <code>+</code>, <code>*</code>, <code>max</code>, <code>min</code>, and <code>mean</code>).</li><li><code>bias</code>: Add learnable bias.</li><li><code>init</code>: Weights&#39; initializer.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using GraphNeuralNetworks

# Construct a spatially-weighted adjacency matrix based on k-nearest neighbours
# with k = 5, and convert to a graph with random (uncorrelated) dummy data:
n = 100
S = rand(n, 2)
d = 1 # dimension of each observation (univariate data here)
A = adjacencymatrix(S, 5)
Z = GNNGraph(A, ndata = rand(d, n))

# Construct the layer and apply it to the data to generate convolved features
layer = WeightedGraphConv(d =&gt; 16)
layer(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/2acc9133073b3706f010d796ce3f616981660199/src/Graphs.jl#L83-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.UniversalPool" href="#NeuralEstimators.UniversalPool"><code>NeuralEstimators.UniversalPool</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UniversalPool(Ïˆ, Ï•)</code></pre><p>Pooling layer (i.e., readout layer) from the paper <a href="https://ieeexplore.ieee.org/document/8852103">&#39;Universal Readout for Graph Convolutional Neural Networks&#39;</a>. It takes the form,</p><p class="math-container">\[\mathbf{V} = Ï•(|G|â»Â¹ \sum_{s\in G} Ïˆ(\mathbf{h}_s)),\]</p><p>where <span>$\mathbf{V}$</span> denotes the summary vector for graph <span>$G$</span>, <span>$\mathbf{h}_s$</span> denotes the vector of hidden features for node <span>$s \in G$</span>, and <code>Ïˆ</code> and <code>Ï•</code> are dense neural networks.</p><p>See also the pooling layers available from <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/stable/api/pool/"><code>GraphNeuralNetworks.jl</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using NeuralEstimators
using Flux
using GraphNeuralNetworks
using Graphs: random_regular_graph

# Construct an input graph G
n_h     = 16  # dimension of each feature node
n_nodes = 10
n_edges = 4
G = GNNGraph(random_regular_graph(n_nodes, n_edges), ndata = rand(n_h, n_nodes))

# Construct the pooling layer
n_t = 32  # dimension of the summary vector for each node
n_v = 64  # dimension of the final summary vector V
Ïˆ = Dense(n_h, n_t)
Ï• = Dense(n_t, n_v)
pool = UniversalPool(Ïˆ, Ï•)

# Apply the pooling layer
pool(G)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/2acc9133073b3706f010d796ce3f616981660199/src/Graphs.jl#L548-L584">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../core/">Â« Core</a><a class="docs-footer-nextpage" href="../summarystatistics/">User-defined summary statistics Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Sunday 17 March 2024 00:51">Sunday 17 March 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
