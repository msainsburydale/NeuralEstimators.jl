<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Architectures · NeuralEstimators.jl</title><meta name="title" content="Architectures · NeuralEstimators.jl"/><meta property="og:title" content="Architectures · NeuralEstimators.jl"/><meta property="twitter:title" content="Architectures · NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../methodology/">Methodology</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../core/">Core</a></li><li class="is-active"><a class="tocitem" href>Architectures</a><ul class="internal"><li><a class="tocitem" href="#Modules"><span>Modules</span></a></li><li class="toplevel"><a class="tocitem" href="#User-defined-summary-statistics"><span>User-defined summary statistics</span></a></li><li><a class="tocitem" href="#Layers"><span>Layers</span></a></li><li><a class="tocitem" href="#Output-layers"><span>Output layers</span></a></li></ul></li><li><a class="tocitem" href="../approximatedistributions/">Approximate distributions</a></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Architectures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Architectures</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/architectures.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Architectures"><a class="docs-heading-anchor" href="#Architectures">Architectures</a><a id="Architectures-1"></a><a class="docs-heading-anchor-permalink" href="#Architectures" title="Permalink"></a></h1><p>In principle, any <a href="https://fluxml.ai/Flux.jl/stable/"><code>Flux</code></a> model can be used to construct the neural network. To integrate it into the workflow, one need only define a method that transforms <span>$K$</span>-dimensional vectors of data sets into matrices with <span>$K$</span> columns, where the number of rows corresponds to the dimensionality of the output spaces listed in the <a href="../../workflow/overview/#Overview">Overview</a>. </p><h2 id="Modules"><a class="docs-heading-anchor" href="#Modules">Modules</a><a id="Modules-1"></a><a class="docs-heading-anchor-permalink" href="#Modules" title="Permalink"></a></h2><p>The following high-level modules are often used when constructing the neural network. In particular, the type <a href="#NeuralEstimators.DeepSet"><code>DeepSet</code></a> serves as a convenient wrapper for embedding standard neural networks (e.g., MLPs, CNNs, GNNs) in a framework for making inference with an arbitrary number of independent replicates, and it comes with pre-defined methods for handling the transformations from a <span>$K$</span>-dimensional vector of data to a matrix output described above. </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.DeepSet" href="#NeuralEstimators.DeepSet"><code>NeuralEstimators.DeepSet</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DeepSet(ψ, ϕ, a = mean; S = nothing)
(ds::DeepSet)(Z::Vector{A}) where A &lt;: Any
(ds::DeepSet)(tuple::Tuple{Vector{A}, Vector{Vector}}) where A &lt;: Any</code></pre><p>The DeepSets representation (<a href="https://arxiv.org/abs/1703.06114">Zaheer et al., 2017</a>; <a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2023.2249522">Sainsbury-Dale et al., 2024</a>),</p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\mathbf{Z}) = \boldsymbol{\phi}(\mathbf{T}(\mathbf{Z})), \quad
\mathbf{T}(\mathbf{Z}) = \mathbf{a}(\{\boldsymbol{\psi}(\mathbf{Z}_i) : i = 1, \dots, m\}),
\]</p><p>where 𝐙 ≡ (𝐙₁&#39;, …, 𝐙ₘ&#39;)&#39; are independent replicates of data,  <code>ψ</code> and <code>ϕ</code> are neural networks, and <code>a</code> is a permutation-invariant aggregation function. </p><p>The function <code>a</code> must operate on arrays and have a keyword argument <code>dims</code> for  specifying the dimension of aggregation (e.g., <code>sum</code>, <code>mean</code>, <code>maximum</code>, <code>minimum</code>, <code>logsumexp</code>).</p><p><code>DeepSet</code> objects act on data of type <code>Vector{A}</code>, where each element of the vector is associated with one data set (i.e., one set of independent replicates), and where <code>A</code> depends on the chosen architecture for <code>ψ</code>. As a rule of thumb, when <code>A</code> is an array, replicates are stored in the final dimension. For example, with gridded spatial data and <code>ψ</code> a CNN, <code>A</code> should be a 4-dimensional array, with replicates stored in the 4ᵗʰ dimension.  Note that, when using <code>Flux</code>, the final dimension is usually the &quot;batch&quot; dimension, but batching with <code>DeepSet</code> objects is done at the data-set level  (i.e., sets of replicates are always kept together). </p><p>For computational efficiency,  array data are first concatenated along their final dimension  (i.e., the replicates dimension) before being passed into the inner network <code>ψ</code>,  thereby ensuring that <code>ψ</code> is applied to a single large array, rather than multiple small ones. </p><p>Expert summary statistics can be incorporated as</p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\mathbf{Z}) = \boldsymbol{\phi}((\mathbf{T}(\mathbf{Z})&#39;, \mathbf{S}(\mathbf{Z})&#39;)&#39;),\]</p><p>where <code>S</code> is a function that returns a vector of user-defined summary statistics. These user-defined summary statistics are provided either as a <code>Function</code> that returns a <code>Vector</code>, or as a vector of functions. In the case that <code>ψ</code> is set to <code>nothing</code>, only expert summary statistics will be used. See <a href="../../workflow/advancedusage/#Expert-summary-statistics">Expert summary statistics</a> for further discussion on their use. </p><p>Set-level inputs (e.g., covariates) <span>$𝐗$</span> can be passed directly into the outer network <code>ϕ</code> in the following manner: </p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\mathbf{Z}) = \boldsymbol{\phi}((\mathbf{T}(\mathbf{Z})&#39;, \mathbf{X}&#39;)&#39;),\]</p><p>or, when expert summary statistics are also used,</p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\mathbf{Z}) = \boldsymbol{\phi}((\mathbf{T}(\mathbf{Z})&#39;, \mathbf{S}(\mathbf{Z})&#39;, \mathbf{X}&#39;)&#39;).\]</p><p>This is done by calling the <code>DeepSet</code> object on a <code>Tuple{Vector{A}, Vector{Vector}}</code>, where the first element of the tuple contains a vector of data sets and the second element contains a vector of set-level inputs (i.e., one vector for each data set).</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Two data sets containing 3 and 4 replicates
d = 5  # number of parameters in the model
n = 10 # dimension of each replicate
Z = [rand32(n, m) for m ∈ (3, 4)]

# Construct DeepSet object
S = samplesize
dₛ = 1   # dimension of expert summary statistic
dₜ = 16  # dimension of neural summary statistic
w  = 32  # width of hidden layers
ψ  = Chain(Dense(n, w, relu), Dense(w, dₜ, relu))
ϕ  = Chain(Dense(dₜ + dₛ, w, relu), Dense(w, d))
ds = DeepSet(ψ, ϕ; S = S)

# Apply DeepSet object to data
ds(Z)

# With set-level inputs 
dₓ = 2 # dimension of set-level inputs 
ϕ  = Chain(Dense(dₜ + dₛ + dₓ, w, relu), Dense(w, d))
ds = DeepSet(ψ, ϕ; S = S)
X  = [rand32(dₓ) for _ ∈ eachindex(Z)]
ds((Z, X))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L42-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.GNNSummary" href="#NeuralEstimators.GNNSummary"><code>NeuralEstimators.GNNSummary</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">GNNSummary(propagation, readout)</code></pre><p>A graph neural network (GNN) module designed to serve as the inner network <code>ψ</code> in the <a href="#NeuralEstimators.DeepSet"><code>DeepSet</code></a> representation when the data are graphical (e.g., irregularly observed spatial data).</p><p>The <code>propagation</code> module transforms graph data into a set of hidden-feature graphs. The <code>readout</code> module aggregates these feature graphs into a single hidden feature vector of fixed length. The network <code>ψ</code> is then defined as the composition of the propagation and readout modules.</p><p>The data should be stored as a <code>GNNGraph</code> or <code>Vector{GNNGraph}</code>, where each graph is associated with a single parameter vector. The graphs may contain subgraphs corresponding to independent replicates.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, GraphNeuralNetworks
using Flux: batch
using Statistics: mean

# Propagation module
r  = 1     # dimension of response variable
nₕ = 32    # dimension of node feature vectors
propagation = GNNChain(GraphConv(r =&gt; nₕ), GraphConv(nₕ =&gt; nₕ))

# Readout module
readout = GlobalPool(mean)

# Inner network
ψ = GNNSummary(propagation, readout)

# Outer network
d = 3     # output dimension 
w = 64    # width of hidden layer
ϕ = Chain(Dense(nₕ, w, relu), Dense(w, d))

# DeepSet object 
ds = DeepSet(ψ, ϕ)

# Apply to data 
g₁ = rand_graph(11, 30, ndata = rand32(r, 11)) 
g₂ = rand_graph(13, 40, ndata = rand32(r, 13))
g₃ = batch([g₁, g₂])  
ds(g₁)                # single graph 
ds(g₃)                # graph with subgraphs corresponding to independent replicates
ds([g₁, g₂, g₃])      # vector of graphs, corresponding to multiple data sets </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Graphs.jl#L484-L532">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.MLP" href="#NeuralEstimators.MLP"><code>NeuralEstimators.MLP</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MLP(in::Integer, out::Integer; kwargs...)</code></pre><p>A traditional fully-connected multilayer perceptron (MLP) with input dimension <code>in</code> and output dimension <code>out</code>.</p><p>The method <code>(mlp::MLP)(x, y)</code> concatenates <code>x</code> and <code>y</code> along their first dimension before passing the result through the neural <code>network</code>. This functionality is used in constructs such as <a href="../approximatedistributions/#NeuralEstimators.AffineCouplingBlock"><code>AffineCouplingBlock</code></a>. </p><p><strong>Keyword arguments</strong></p><ul><li><code>depth::Integer = 2</code>: the number of hidden layers.</li><li><code>width::Integer = 128</code>: the width of each hidden layer.</li><li><code>activation::Function = relu</code>: the (non-linear) activation function used in each hidden layer.</li><li><code>output_activation::Function = identity</code>: the activation function used in the output layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/ApproximateDistributions.jl#L140-L151">source</a></section></article><h1 id="User-defined-summary-statistics"><a class="docs-heading-anchor" href="#User-defined-summary-statistics">User-defined summary statistics</a><a id="User-defined-summary-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#User-defined-summary-statistics" title="Permalink"></a></h1><ul></ul><p>The following functions correspond to summary statistics that are often useful as user-defined summary statistics in <a href="#NeuralEstimators.DeepSet"><code>DeepSet</code></a> objects.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.samplesize" href="#NeuralEstimators.samplesize"><code>NeuralEstimators.samplesize</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">samplesize(Z::AbstractArray)</code></pre><p>Computes the sample size of a set of independent realisations <code>Z</code>.</p><p>Note that this function is a wrapper around <a href="../utility/#NeuralEstimators.numberreplicates"><code>numberreplicates</code></a>, but this function returns the number of replicates as the eltype of <code>Z</code>, rather than as an integer.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/summarystatistics.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.samplecorrelation" href="#NeuralEstimators.samplecorrelation"><code>NeuralEstimators.samplecorrelation</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">samplecorrelation(Z::AbstractArray)</code></pre><p>Computes the sample correlation matrix, R̂, and returns the vectorised strict lower triangle of R̂.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># 5 independent replicates of a 3-dimensional vector
z = rand(3, 5)
samplecorrelation(z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/summarystatistics.jl#L36-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.samplecovariance" href="#NeuralEstimators.samplecovariance"><code>NeuralEstimators.samplecovariance</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">samplecovariance(Z::AbstractArray)</code></pre><p>Computes the <a href="https://en.wikipedia.org/wiki/Sample_mean_and_covariance#Definition_of_sample_covariance">sample covariance matrix</a>, Σ̂, and returns the vectorised lower triangle of Σ̂.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># 5 independent replicates of a 3-dimensional vector
z = rand(3, 5)
samplecovariance(z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/summarystatistics.jl#L13-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.NeighbourhoodVariogram" href="#NeuralEstimators.NeighbourhoodVariogram"><code>NeuralEstimators.NeighbourhoodVariogram</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NeighbourhoodVariogram(h_max, n_bins) 
(l::NeighbourhoodVariogram)(g::GNNGraph)</code></pre><p>Computes the empirical variogram, </p><p class="math-container">\[\hat{\gamma}(h \pm \delta) = \frac{1}{2|N(h \pm \delta)|} \sum_{(i,j) \in N(h \pm \delta)} (Z_i - Z_j)^2\]</p><p>where <span>$N(h \pm \delta) \equiv \left\{(i,j) : \|\boldsymbol{s}_i - \boldsymbol{s}_j\| \in (h-\delta, h+\delta)\right\}$</span>  is the set of pairs of locations separated by a distance within <span>$(h-\delta, h+\delta)$</span>, and <span>$|\cdot|$</span> denotes set cardinality. </p><p>The distance bins are constructed to have constant width <span>$2\delta$</span>, chosen based on the maximum distance  <code>h_max</code> to be considered, and the specified number of bins <code>n_bins</code>. </p><p>The input type is a <code>GNNGraph</code>, and the empirical variogram is computed based on the corresponding graph structure.  Specifically, only locations that are considered neighbours will be used when computing the empirical variogram. </p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Distances, LinearAlgebra
  
# Simulate Gaussian spatial data with exponential covariance function 
θ = 0.1                                 # true range parameter 
n = 250                                 # number of spatial locations 
S = rand(n, 2)                          # spatial locations 
D = pairwise(Euclidean(), S, dims = 1)  # distance matrix 
Σ = exp.(-D ./ θ)                       # covariance matrix 
L = cholesky(Symmetric(Σ)).L            # Cholesky factor 
m = 5                                   # number of independent replicates 
Z = L * randn(n, m)                     # simulated data 

# Construct the spatial graph 
r = 0.15                                # radius of neighbourhood set
g = spatialgraph(S, Z, r = r)

# Construct the variogram object with 10 bins
nv = NeighbourhoodVariogram(r, 10) 

# Compute the empirical variogram 
nv(g)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/summarystatistics.jl#L113-L156">source</a></section></article><h2 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h2><p>In addition to the <a href="https://fluxml.ai/Flux.jl/stable/reference/models/layers/">built-in layers</a> provided by Flux, the following layers may be used when building a neural-network architecture.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.DensePositive" href="#NeuralEstimators.DensePositive"><code>NeuralEstimators.DensePositive</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DensePositive(layer::Dense; g::Function = relu, last_only::Bool = false)</code></pre><p>Wrapper around the standard <a href="https://fluxml.ai/Flux.jl/stable/models/layers/#Flux.Dense">Dense</a> layer that ensures positive weights (biases are left unconstrained).</p><p>This layer can be useful for constucting (partially) monotonic neural networks (see, e.g., <a href="../core/#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>).</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

l = DensePositive(Dense(5 =&gt; 2))
x = rand32(5, 64)
l(x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L678-L694">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PowerDifference" href="#NeuralEstimators.PowerDifference"><code>NeuralEstimators.PowerDifference</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PowerDifference(a, b)</code></pre><p>Function <span>$f(x, y) = |ax - (1-a)y|^b$</span> for trainable parameters a ∈ [0, 1] and b &gt; 0.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Generate some data
d = 5
K = 10000
X = randn32(d, K)
Y = randn32(d, K)
XY = (X, Y)
a = 0.2f0
b = 1.3f0
Z = (abs.(a .* X - (1 .- a) .* Y)).^b

# Initialise layer
f = PowerDifference([0.5f0], [2.0f0])

# Optimise the layer
loader = Flux.DataLoader((XY, Z), batchsize=32, shuffle=false)
optim = Flux.setup(Flux.Adam(0.01), f)
for epoch in 1:100
    for (xy, z) in loader
        loss, grads = Flux.withgradient(f) do m
            Flux.mae(m(xy), z)
        end
        Flux.update!(optim, f, grads[1])
    end
end

# Estimates of a and b
f.a
f.b</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L724-L761">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.ResidualBlock" href="#NeuralEstimators.ResidualBlock"><code>NeuralEstimators.ResidualBlock</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ResidualBlock(filter, in =&gt; out; stride = 1)</code></pre><p>Basic residual block (see <a href="https://en.wikipedia.org/wiki/Residual_neural_network#Basic_block">here</a>), consisting of two sequential convolutional layers and a skip (shortcut) connection that connects the input of the block directly to the output, facilitating the training of deep networks.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
z = rand(16, 16, 1, 1)
b = ResidualBlock((3, 3), 1 =&gt; 32)
b(z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L775-L790">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.SpatialGraphConv" href="#NeuralEstimators.SpatialGraphConv"><code>NeuralEstimators.SpatialGraphConv</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SpatialGraphConv(in =&gt; out, g=relu; args...)</code></pre><p>Implements a spatial graph convolution for isotropic spatial processes <a href="https://arxiv.org/abs/2310.02600">(Sainsbury-Dale et al., 2025)</a>, </p><p class="math-container">\[ \boldsymbol{h}^{(l)}_{j} =
 g\Big(
 \boldsymbol{\Gamma}_{\!1}^{(l)} \boldsymbol{h}^{(l-1)}_{j}
 +
 \boldsymbol{\Gamma}_{\!2}^{(l)} \bar{\boldsymbol{h}}^{(l)}_{j}
 +
 \boldsymbol{\gamma}^{(l)}
 \Big),
 \quad
 \bar{\boldsymbol{h}}^{(l)}_{j} = \sum_{j&#39; \in \mathcal{N}(j)}\boldsymbol{w}^{(l)}(\|\boldsymbol{s}_{j&#39;} - \boldsymbol{s}_j\|) \odot f^{(l)}(\boldsymbol{h}^{(l-1)}_{j}, \boldsymbol{h}^{(l-1)}_{j&#39;}),\]</p><p>where <span>$\boldsymbol{h}^{(l)}_{j}$</span> is the hidden feature vector at location <span>$\boldsymbol{s}_j$</span> at layer <span>$l$</span>, <span>$g(\cdot)$</span> is a non-linear activation function applied elementwise, <span>$\boldsymbol{\Gamma}_{\!1}^{(l)}$</span> and <span>$\boldsymbol{\Gamma}_{\!2}^{(l)}$</span> are trainable parameter matrices, <span>$\boldsymbol{\gamma}^{(l)}$</span> is a trainable bias vector, <span>$\mathcal{N}(j)$</span> denotes the indices of neighbours of <span>$\boldsymbol{s}_j$</span>, <span>$\boldsymbol{w}^{(l)}(\cdot)$</span> is a (learnable) spatial weighting function, <span>$\odot$</span> denotes elementwise multiplication,  and <span>$f^{(l)}(\cdot, \cdot)$</span> is a (learnable) function. </p><p>By default, the function <span>$f^{(l)}(\cdot, \cdot)$</span> is modelled using a <a href="#NeuralEstimators.PowerDifference"><code>PowerDifference</code></a> function.  One may alternatively employ a nonlearnable function, for example, <code>f = (hᵢ, hⱼ) -&gt; (hᵢ - hⱼ).^2</code>,  specified through the keyword argument <code>f</code>.  </p><p>The spatial distances between locations must be stored as an edge feature, as facilitated by <a href="../utility/#NeuralEstimators.spatialgraph"><code>spatialgraph()</code></a>.  The input to <span>$\boldsymbol{w}^{(l)}(\cdot)$</span> is a <span>$1 \times n$</span> matrix (i.e., a row vector) of spatial distances.  The output of <span>$\boldsymbol{w}^{(l)}(\cdot)$</span> must be either a scalar; a vector of the same dimension as the feature vectors of the previous layer;  or, if the features vectors of the previous layer are scalars, a vector of arbitrary dimension.  To promote identifiability, the weights are normalised to sum to one (row-wise) within each neighbourhood set.  By default, <span>$\boldsymbol{w}^{(l)}(\cdot)$</span> is taken to be a multilayer perceptron with a single hidden layer,  although a custom choice for this function can be provided using the keyword argument <code>w</code>. </p><p><strong>Arguments</strong></p><ul><li><code>in</code>: dimension of input features.</li><li><code>out</code>: dimension of output features.</li><li><code>g = relu</code>: activation function.</li><li><code>bias = true</code>: add learnable bias?</li><li><code>init = glorot_uniform</code>: initialiser for <span>$\boldsymbol{\Gamma}_{\!1}^{(l)}$</span>, <span>$\boldsymbol{\Gamma}_{\!2}^{(l)}$</span>, and <span>$\boldsymbol{\gamma}^{(l)}$</span>. </li><li><code>f = nothing</code></li><li><code>w = nothing</code> </li><li><code>w_width = 128</code> (applicable only if <code>w = nothing</code>): the width of the hidden layer in the MLP used to model <span>$\boldsymbol{w}^{(l)}(\cdot, \cdot)$</span>. </li><li><code>w_out = in</code> (applicable only if <code>w = nothing</code>): the output dimension of <span>$\boldsymbol{w}^{(l)}(\cdot, \cdot)$</span>.  </li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, GraphNeuralNetworks

# Toy spatial data
n = 250                # number of spatial locations
m = 5                  # number of independent replicates
S = rand(n, 2)         # spatial locations
Z = rand(n, m)         # data
g = spatialgraph(S, Z) # construct the graph

# Construct and apply spatial graph convolution layer
l = SpatialGraphConv(1 =&gt; 10)
l(g)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Graphs.jl#L277-L342">source</a></section></article><h2 id="Output-layers"><a class="docs-heading-anchor" href="#Output-layers">Output layers</a><a id="Output-layers-1"></a><a class="docs-heading-anchor-permalink" href="#Output-layers" title="Permalink"></a></h2><ul></ul><p>In addition to the <a href="https://fluxml.ai/Flux.jl/stable/models/activation/">standard activation functions</a> provided by Flux (e.g., <code>relu</code>, <code>softplus</code>), the following layers can be used at the end of an architecture to ensure valid estimates for certain models. Note that the Flux layer <code>Parallel</code> can be useful for applying several different parameter constraints, as shown in the <a href="../../workflow/examples/#Univariate-data">Univariate data</a> example.</p><div class="admonition is-info"><header class="admonition-header">Layers vs. activation functions</header><div class="admonition-body"><p>Although we may conceptualise the following types as &quot;output activation functions&quot;, they should be treated as separate layers included in the final stage of a Flux <code>Chain()</code>. In particular, they cannot be used as the activation function of a <code>Dense</code> layer. </p></div></div><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Compress" href="#NeuralEstimators.Compress"><code>NeuralEstimators.Compress</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Compress(a, b, k = 1)</code></pre><p>Layer that compresses its input to be within the range <code>a</code> and <code>b</code>, where each element of <code>a</code> is less than the corresponding element of <code>b</code>.</p><p>The layer uses a logistic function,</p><p class="math-container">\[l(θ) = a + \frac{b - a}{1 + e^{-kθ}},\]</p><p>where the arguments <code>a</code> and <code>b</code> together combine to shift and scale the logistic function to the range (<code>a</code>, <code>b</code>), and the growth rate <code>k</code> controls the steepness of the curve.</p><p>The logistic function given <a href="https://en.wikipedia.org/wiki/Logistic_function">here</a> contains an additional parameter, θ₀, which is the input value corresponding to the functions midpoint. In <code>Compress</code>, we fix θ₀ = 0, since the output of a randomly initialised neural network is typically around zero.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

a = [25, 0.5, -pi/2]
b = [500, 2.5, 0]
p = length(a)
K = 100
θ = randn(p, K)
l = Compress(a, b)
l(θ)

n = 20
θ̂ = Chain(Dense(n, p), l)
Z = randn(n, K)
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L338-L375">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.CorrelationMatrix" href="#NeuralEstimators.CorrelationMatrix"><code>NeuralEstimators.CorrelationMatrix</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CorrelationMatrix(d)
(object::CorrelationMatrix)(x::Matrix, cholesky::Bool = false)</code></pre><p>Transforms a vector 𝐯 ∈ ℝᵈ to the parameters of an unconstrained <code>d</code>×<code>d</code> correlation matrix or, if <code>cholesky = true</code>, the lower Cholesky factor of an unconstrained <code>d</code>×<code>d</code> correlation matrix.</p><p>The expected input is a <code>Matrix</code> with T(<code>d</code>-1) = (<code>d</code>-1)<code>d</code>÷2 rows, where T(<code>d</code>-1) is the (<code>d</code>-1)th triangular number (the number of free parameters in an unconstrained <code>d</code>×<code>d</code> correlation matrix), and the output is a <code>Matrix</code> of the same dimension. The columns of the input and output matrices correspond to independent parameter configurations (i.e., different correlation matrices).</p><p>Internally, the layer constructs a valid Cholesky factor 𝐋 for a correlation matrix, and then extracts the strict lower triangle from the correlation matrix 𝐑 = 𝐋𝐋&#39;. The lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering: for example, when modelling the correlation matrix</p><p class="math-container">\[\begin{bmatrix}
1   &amp; R₁₂ &amp;  R₁₃ \\
R₂₁ &amp; 1   &amp;  R₂₃\\
R₃₁ &amp; R₃₂ &amp; 1\\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CorrelationMatrix</code> layer are ordered as</p><p class="math-container">\[\begin{bmatrix}
R₂₁ \\
R₃₁ \\
R₃₂ \\
\end{bmatrix},\]</p><p>which means that the output can easily be transformed into the implied correlation matrices using <a href="../utility/#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p>See also <a href="#NeuralEstimators.CovarianceMatrix"><code>CovarianceMatrix</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, LinearAlgebra, Flux

d  = 4
l  = CorrelationMatrix(d)
p  = (d-1)*d÷2
θ  = randn(p, 100)

# Returns a matrix of parameters, which can be converted to correlation matrices
R = l(θ)
R = map(eachcol(R)) do r
	R = Symmetric(cpu(vectotril(r, strict = true)), :L)
	R[diagind(R)] .= 1
	R
end

# Obtain the Cholesky factor directly
L = l(θ, true)
L = map(eachcol(L)) do x
	# Only the strict lower diagonal elements are returned
	L = LowerTriangular(cpu(vectotril(x, strict = true)))

	# Diagonal elements are determined under the constraint diag(L*L&#39;) = 𝟏
	L[diagind(L)] .= sqrt.(1 .- rowwisenorm(L).^2)
	L
end
L[1] * L[1]&#39;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L523-L593">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.CovarianceMatrix" href="#NeuralEstimators.CovarianceMatrix"><code>NeuralEstimators.CovarianceMatrix</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CovarianceMatrix(d)
(object::CovarianceMatrix)(x::Matrix, cholesky::Bool = false)</code></pre><p>Transforms a vector 𝐯 ∈ ℝᵈ to the parameters of an unconstrained <code>d</code>×<code>d</code> covariance matrix or, if <code>cholesky = true</code>, the lower Cholesky factor of an unconstrained <code>d</code>×<code>d</code> covariance matrix.</p><p>The expected input is a <code>Matrix</code> with T(<code>d</code>) = <code>d</code>(<code>d</code>+1)÷2 rows, where T(<code>d</code>) is the <code>d</code>th triangular number (the number of free parameters in an unconstrained <code>d</code>×<code>d</code> covariance matrix), and the output is a <code>Matrix</code> of the same dimension. The columns of the input and output matrices correspond to independent parameter configurations (i.e., different covariance matrices).</p><p>Internally, the layer constructs a valid Cholesky factor 𝐋 and then extracts the lower triangle from the positive-definite covariance matrix 𝚺 = 𝐋𝐋&#39;. The lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering: for example, when modelling the covariance matrix</p><p class="math-container">\[\begin{bmatrix}
Σ₁₁ &amp; Σ₁₂ &amp; Σ₁₃ \\
Σ₂₁ &amp; Σ₂₂ &amp; Σ₂₃ \\
Σ₃₁ &amp; Σ₃₂ &amp; Σ₃₃ \\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CovarianceMatrix</code> are ordered as</p><p class="math-container">\[\begin{bmatrix}
Σ₁₁ \\
Σ₂₁ \\
Σ₃₁ \\
Σ₂₂ \\
Σ₃₂ \\
Σ₃₃ \\
\end{bmatrix},\]</p><p>which means that the output can easily be transformed into the implied covariance matrices using <a href="../utility/#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p>See also <a href="#NeuralEstimators.CorrelationMatrix"><code>CorrelationMatrix</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, LinearAlgebra

d = 4
l = CovarianceMatrix(d)
p = d*(d+1)÷2
θ = randn(p, 50)

# Returns a matrix of parameters, which can be converted to covariance matrices
Σ = l(θ)
Σ = [Symmetric(cpu(vectotril(x)), :L) for x ∈ eachcol(Σ)]

# Obtain the Cholesky factor directly
L = l(θ, true)
L = [LowerTriangular(cpu(vectotril(x))) for x ∈ eachcol(L)]
L[1] * L[1]&#39;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/3091dfee56aa0283cf6817e2e227bdcd2b95bc9a/src/Architectures.jl#L414-L476">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../core/">« Core</a><a class="docs-footer-nextpage" href="../approximatedistributions/">Approximate distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Friday 7 February 2025 12:56">Friday 7 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
