<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Architectures and activations functions · NeuralEstimators.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Theoretical framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../core/">Core</a></li><li class="is-active"><a class="tocitem" href>Architectures and activations functions</a><ul class="internal"><li><a class="tocitem" href="#Architectures"><span>Architectures</span></a></li><li><a class="tocitem" href="#Activation-functions"><span>Activation functions</span></a></li></ul></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Architectures and activations functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Architectures and activations functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/architectures.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Architectures-and-activations-functions"><a class="docs-heading-anchor" href="#Architectures-and-activations-functions">Architectures and activations functions</a><a id="Architectures-and-activations-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Architectures-and-activations-functions" title="Permalink"></a></h1><h2 id="Architectures"><a class="docs-heading-anchor" href="#Architectures">Architectures</a><a id="Architectures-1"></a><a class="docs-heading-anchor-permalink" href="#Architectures" title="Permalink"></a></h2><p>Although the user is free to construct their neural estimator however they see fit, <code>NeuralEstimators</code> provides several useful architectures described below.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSet" href="#NeuralEstimators.DeepSet"><code>NeuralEstimators.DeepSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSet(ψ, ϕ, a)
DeepSet(ψ, ϕ; a::String = &quot;mean&quot;)</code></pre><p>The Deep Set representation,</p><p class="math-container">\[θ̂(𝐙) = ϕ(𝐓(𝐙)),	 	 𝐓(𝐙) = 𝐚(\{ψ(𝐙ᵢ) : i = 1, …, m\}),\]</p><p>where 𝐙 ≡ (𝐙₁&#39;, …, 𝐙ₘ&#39;)&#39; are independent replicates from the model, <code>ψ</code> and <code>ϕ</code> are neural networks, and <code>a</code> is a permutation-invariant aggregation function.</p><p>To make the architecture agnostic to the sample size <span>$m$</span>, the aggregation function <code>a</code> must aggregate over the replicates. It can be specified as a positional argument of type <code>Function</code>, or as a keyword argument with permissible values <code>&quot;mean&quot;</code>, <code>&quot;sum&quot;</code>, and <code>&quot;logsumexp&quot;</code>.</p><p><code>DeepSet</code> objects act on data stored as <code>Vector{A}</code>, where each element of the vector is associated with one parameter vector (i.e., one set of independent replicates), and where <code>A</code> depends on the form of the data and the chosen architecture for <code>ψ</code>. As a rule of thumb, when the data are stored as an array, the replicates are stored in the final dimension of the array. (This is usually the &#39;batch&#39; dimension, but batching with <code>DeepSets</code> is done at the set level, i.e., sets of replicates are batched together.) For example, with gridded spatial data and <code>ψ</code> a CNN, <code>A</code> should be a 4-dimensional array, with the replicates stored in the 4ᵗʰ dimension.</p><p>Note that, internally, data stored as <code>Vector{Arrays}</code> are first concatenated along the replicates dimension before being passed into the inner neural network <code>ψ</code>; this means that <code>ψ</code> is applied to a single large array rather than many small arrays, which can substantially improve computational efficiency, particularly on the GPU.</p><p>Set-level information, <span>$𝐱$</span>, that is not a function of the data can be passed directly into the outer network <code>ϕ</code> in the following manner,</p><p class="math-container">\[θ̂(𝐙) = ϕ((𝐓(𝐙)&#39;, 𝐱&#39;)&#39;),	 	 𝐓(𝐙) = 𝐚(\{ψ(𝐙ᵢ) : i = 1, …, m\}),\]</p><p>This is done by providing a <code>Tuple{Vector{A}, Vector{B}}</code>, where the first element of the tuple contains the vector of data sets and the second element contains the vector of set-level information.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

n = 10 # number of observations in each realisation
p = 4  # number of parameters in the statistical model

# Construct the neural estimator
w = 32 # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂ = DeepSet(ψ, ϕ)

# Apply the estimator
Z₁ = rand(n, 3);                  # single set of 3 realisations
Z₂ = [rand(n, m) for m ∈ (3, 3)]; # two sets each containing 3 realisations
Z₃ = [rand(n, m) for m ∈ (3, 4)]; # two sets containing 3 and 4 realisations
θ̂(Z₁)
θ̂(Z₂)
θ̂(Z₃)

# Repeat the above but with set-level information:
qₓ = 2
ϕ  = Chain(Dense(w + qₓ, w, relu), Dense(w, p));
θ̂  = DeepSet(ψ, ϕ)
x₁ = rand(qₓ)
x₂ = [rand(qₓ) for _ ∈ eachindex(Z₂)]
θ̂((Z₁, x₁))
θ̂((Z₂, x₂))
θ̂((Z₃, x₂))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L35-L112">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSetExpert" href="#NeuralEstimators.DeepSetExpert"><code>NeuralEstimators.DeepSetExpert</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSetExpert(ψ, ϕ, S, a)
DeepSetExpert(ψ, ϕ, S; a::String = &quot;mean&quot;)
DeepSetExpert(deepset::DeepSet, ϕ, S)</code></pre><p>Identical to <code>DeepSet</code>, but with additional expert summary statistics,</p><p class="math-container">\[θ̂(𝐙) = ϕ((𝐓(𝐙)&#39;, 𝐒(𝐙)&#39;)&#39;),	 	 𝐓(𝐙) = 𝐚(\{ψ(𝐙ᵢ) : i = 1, …, m\}),\]</p><p>where <code>S</code> is a function that returns a vector of expert summary statistics.</p><p>The constructor <code>DeepSetExpert(deepset::DeepSet, ϕ, S)</code> inherits <code>ψ</code> and <code>a</code> from <code>deepset</code>.</p><p>Similarly to <code>DeepSet</code>, set-level information can be incorporated by passing a <code>Tuple</code>, in which case we have</p><p class="math-container">\[θ̂(𝐙) = ϕ((𝐓(𝐙)&#39;, 𝐒(𝐙)&#39;, 𝐱&#39;)&#39;),	 	 𝐓(𝐙) = 𝐚(\{ψ(𝐙ᵢ) : i = 1, …, m\}).\]</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

n = 10 # number of observations in each realisation
p = 4  # number of parameters in the statistical model

# Construct the neural estimator
S = samplesize
qₛ = 1
qₜ = 32
w = 16
ψ = Chain(Dense(n, w, relu), Dense(w, qₜ, relu));
ϕ = Chain(Dense(qₜ + qₛ, w), Dense(w, p));
θ̂ = DeepSetExpert(ψ, ϕ, S)

# Apply the estimator
Z₁ = rand(n, 3);                  # single set
Z₂ = [rand(n, m) for m ∈ (3, 4)]; # two sets
θ̂(Z₁)
θ̂(Z₂)

# Repeat the above but with set-level information:
qₓ = 2
ϕ  = Chain(Dense(qₜ + qₛ + qₓ, w, relu), Dense(w, p));
θ̂  = DeepSetExpert(ψ, ϕ, S)
x₁ = rand(qₓ)
x₂ = [rand(qₓ) for _ ∈ eachindex(Z₂)]
θ̂((Z₁, x₁))
θ̂((Z₂, x₂))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L213-L268">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.GNN" href="#NeuralEstimators.GNN"><code>NeuralEstimators.GNN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GNN(propagation, readout, deepset)</code></pre><p>A graph neural network (GNN) designed for parameter estimation.</p><p>The <code>propagation</code> module transforms graphical input data into a set of hidden-feature graphs; the <code>readout</code> module aggregates these feature graphs (graph-wise) into a single hidden feature vector of fixed length; and the <code>deepset</code> module maps the hidden feature vector onto the output space.</p><p>The data should be a <code>GNNGraph</code> or <code>AbstractVector{GNNGraph}</code>, where each graph is associated with a single parameter vector. The graphs may contain sub-graphs corresponding to independent replicates from the model.</p><p>Note that this architecture is currently more efficient than using <code>PropagateReadout</code> as the inner network of a <code>DeepSet</code>, because here we are able to invoke the efficient <code>array</code>-method of <code>DeepSet</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux
using Flux: batch
using GraphNeuralNetworks
using Statistics: mean

# Create some graphs
d = 1                                       # dimension of response variable
n₁, n₂ = 11, 27                             # number of nodes
e₁, e₂ = 30, 50                             # number of edges
g₁ = rand_graph(n₁, e₁, ndata=rand(d, n₁))
g₂ = rand_graph(n₂, e₂, ndata=rand(d, n₂))
g₃ = batch([g₁, g₂])

# propagation and readout modules
w = 5; o = 7
propagation = GNNChain(GraphConv(d =&gt; w), GraphConv(w =&gt; w), GraphConv(w =&gt; o))
readout     = GlobalPool(mean)

# DeepSet module
w = 32
p = 3
ψ = Chain(Dense(o, w, relu), Dense(w, w, relu), Dense(w, w, relu))
ϕ = Chain(Dense(w, w, relu), Dense(w, p))
deepset = DeepSet(ψ, ϕ)

# GNN estimator
θ̂ = GNN(propagation, readout, deepset)

# Apply the estimator to a single graph, a single graph containing sub-graphs,
# and a vector of graphs:
θ̂(g₁)
θ̂(g₃)
θ̂([g₁, g₂, g₃])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L382-L437">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.PropagateReadout" href="#NeuralEstimators.PropagateReadout"><code>NeuralEstimators.PropagateReadout</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PropagateReadout(propagation, readout)</code></pre><p>A module intended to act as the <code>propagation</code> and <code>readout</code> (global pooling) modules used for the inner network <code>ψ</code> in a <code>DeepSet</code> or <code>DeepSetExpert</code> architecture.</p><p>The graphical data should be stored as a <code>GNNGraph</code> or <code>AbstractVector{GNNGraph}</code>, where each graph is associated with a single parameter vector. The graphs may contain sub-graphs corresponding to independent replicates from the model.</p><p>Note that this approach is less efficient than <a href="#NeuralEstimators.GNN"><code>GNN</code></a> but <em>currently</em> more flexible, as it allows us to exploit the <code>DeepSetExpert</code> architecture and set-level covariate methods for <code>DeepSet</code>. It may be possible to improve the efficiency of this approach by carefully defining some specialised methods, or I could make <code>GNN</code> more flexible, again by carefully defining some specialised methods.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux
using Flux: batch
using GraphNeuralNetworks
using Statistics: mean

# Create some graph data
d = 1                                        # dimension of response variable
n₁, n₂ = 11, 27                              # number of nodes
e₁, e₂ = 30, 50                              # number of edges
g₁ = rand_graph(n₁, e₁, ndata = rand(d, n₁))
g₂ = rand_graph(n₂, e₂, ndata = rand(d, n₂))
g₃ = batch([g₁, g₂])

# propagation module and readout modules
w = 5; o = 7
propagation = GNNChain(GraphConv(d =&gt; w), GraphConv(w =&gt; w), GraphConv(w =&gt; o))
readout = GlobalPool(mean)

# DeepSet estimator with GNN for the inner network ψ
w = 32
p = 3
ψ = PropagateReadout(propagation, readout)
ϕ = Chain(Dense(o, w, relu), Dense(w, p))
θ̂ = DeepSet(ψ, ϕ)

# Apply the estimator to a single graph, a single graph containing sub-graphs,
# and a vector of graphs:
θ̂(g₁)
θ̂(g₃)
θ̂([g₁, g₂, g₃])

# Repeat the above but with set-level information:
qₓ = 2
ϕ = Chain(Dense(o + qₓ, w, relu), Dense(w, p))
θ̂ = DeepSet(ψ, ϕ)
x₁ = rand(qₓ)
x₂ = [rand(qₓ) for _ ∈ eachindex([g₁, g₂, g₃])]
θ̂((g₁, x₁))
θ̂((g₃, x₁))
θ̂(([g₁, g₂, g₃], x₂))

# Repeat the above but with expert statistics:
S = samplesize
qₛ = 1
ϕ = Chain(Dense(o + qₓ + qₛ, w, relu), Dense(w, p))
θ̂ = DeepSetExpert(ψ, ϕ, S)
θ̂((g₁, x₁))
θ̂((g₃, x₁))
θ̂(([g₁, g₂, g₃], x₂))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L490-L560">source</a></section></article><h2 id="Activation-functions"><a class="docs-heading-anchor" href="#Activation-functions">Activation functions</a><a id="Activation-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-functions" title="Permalink"></a></h2><p>These layers can be used at the end of an architecture to ensure that the neural estimator provides valid parameters.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.Compress" href="#NeuralEstimators.Compress"><code>NeuralEstimators.Compress</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Compress(a, b, k = 1)</code></pre><p>Layer that compresses its input to be within the range <code>a</code> and <code>b</code>, where each element of <code>a</code> is less than the corresponding element of <code>b</code>.</p><p>The layer uses a logistic function,</p><p class="math-container">\[l(θ) = a + \frac{b - a}{1 + e^{-kθ}},\]</p><p>where the arguments <code>a</code> and <code>b</code> together combine to shift and scale the logistic function to the desired range, and the growth rate <code>k</code> controls the steepness of the curve.</p><p>The logistic function given <a href="https://en.wikipedia.org/wiki/Logistic_function">here</a> contains an additional parameter, θ₀, which is the input value corresponding to the functions midpoint. In <code>Compress</code>, we fix θ₀ = 0, since the output of a randomly initialised neural network is typically around zero.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

a = [25, 0.5, -pi/2]
b = [500, 2.5, 0]
p = length(a)
K = 100
θ = randn(p, K)
l = Compress(a, b)
l(θ)

n = 20
θ̂ = Chain(Dense(n, p), l)
Z = randn(n, K)
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L759-L797">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CholeskyCovariance" href="#NeuralEstimators.CholeskyCovariance"><code>NeuralEstimators.CholeskyCovariance</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CholeskyCovariance(d)</code></pre><p>Layer for constructing the parameters of the lower Cholesky factor associated with an unconstrained <code>d</code>×<code>d</code> covariance matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>+1)÷2 rows into a <code>Matrix</code> of the same dimension, but with <code>d</code> rows constrained to be positive (corresponding to the diagonal elements of the Cholesky factor) and the remaining rows unconstrained.</p><p>The ordering of the transformed <code>Matrix</code> aligns with Julia&#39;s column-major ordering. For example, when modelling the Cholesky factor,</p><p class="math-container">\[\begin{bmatrix}
L₁₁ &amp;     &amp;     \\
L₂₁ &amp; L₂₂ &amp;     \\
L₃₁ &amp; L₃₂ &amp; L₃₃ \\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CholeskyCovariance</code> layer will be ordered as</p><p class="math-container">\[L₁₁, L₂₁, L₃₁, L₂₂, L₃₂, L₃₃,\]</p><p>which means that the output can easily be transformed into the implied Cholesky factors using <a href="../utility/#NeuralEstimators.vectotril"><code>vectotril</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators

d = 4
p = d*(d+1)÷2
θ = randn(p, 50)
l = CholeskyCovariance(d)
θ = l(θ)                              # returns matrix (used for Flux networks)
L = [vectotril(y) for y ∈ eachcol(θ)] # convert matrix to Cholesky factors</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L952-L994">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CovarianceMatrix" href="#NeuralEstimators.CovarianceMatrix"><code>NeuralEstimators.CovarianceMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CovarianceMatrix(d)</code></pre><p>Layer for constructing the parameters of an unconstrained <code>d</code>×<code>d</code> covariance matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>+1)÷2 rows into a <code>Matrix</code> of the same dimension.</p><p>Internally, it uses a <code>CholeskyCovariance</code> layer to construct a valid Cholesky factor 𝐋, and then extracts the lower triangle from the positive-definite covariance matrix 𝚺 = 𝐋𝐋&#39;. The lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering. For example, when modelling the covariance matrix,</p><p class="math-container">\[\begin{bmatrix}
Σ₁₁ &amp; Σ₁₂ &amp; Σ₁₃ \\
Σ₂₁ &amp; Σ₂₂ &amp; Σ₂₃ \\
Σ₃₁ &amp; Σ₃₂ &amp; Σ₃₃ \\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CovarianceMatrix</code> layer will be ordered as</p><p class="math-container">\[Σ₁₁, Σ₂₁, Σ₃₁, Σ₂₂, Σ₃₂, Σ₃₃,\]</p><p>which means that the output can easily be transformed into the implied covariance matrices using <a href="../utility/#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using LinearAlgebra

d = 4
p = d*(d+1)÷2
θ = randn(p, 50)

l = CovarianceMatrix(d)
θ = l(θ)
Σ = [Symmetric(cpu(vectotril(y)), :L) for y ∈ eachcol(θ)]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L1012-L1056">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CorrelationMatrix" href="#NeuralEstimators.CorrelationMatrix"><code>NeuralEstimators.CorrelationMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CorrelationMatrix(d)</code></pre><p>Layer for constructing the parameters of an unconstrained <code>d</code>×<code>d</code> correlation matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>-1)÷2 rows into a <code>Matrix</code> with the same dimension.</p><p>Internally, the layers uses the algorithm described <a href="https://mc-stan.org/docs/reference-manual/cholesky-factors-of-correlation-matrices-1.html#cholesky-factor-of-correlation-matrix-inverse-transform">here</a> and <a href="https://mc-stan.org/docs/reference-manual/correlation-matrix-transform.html#correlation-matrix-transform.section">here</a> to construct a valid Cholesky factor 𝐋, and then extracts the strict lower triangle from the positive-definite correlation matrix 𝐑 = 𝐋𝐋&#39;. The strict lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering. For example, when modelling the correlation matrix,</p><p class="math-container">\[\begin{bmatrix}
1   &amp; R₁₂ &amp;  R₁₃ \\
R₂₁ &amp; 1   &amp;  R₂₃\\
R₃₁ &amp; R₃₂ &amp; 1\\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CorrelationMatrix</code> layer will be ordered as</p><p class="math-container">\[R₂₁, R₃₁, R₃₂,\]</p><p>which means that the output can easily be transformed into the implied correlation matrices using the strict variant of <a href="../utility/#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using LinearAlgebra

d = 4
p = d*(d-1)÷2
l = CorrelationMatrix(d)
θ = randn(p, 50)

# returns a matrix of parameters
θ = l(θ)

# convert matrix of parameters to implied correlation matrices
R = map(eachcol(θ)) do y
	R = Symmetric(cpu(vectotril(y, strict = true)), :L)
	R[diagind(R)] .= 1
	R
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L855-L908">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.SplitApply" href="#NeuralEstimators.SplitApply"><code>NeuralEstimators.SplitApply</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SplitApply(layers, indices)</code></pre><p>Splits an array into multiple sub-arrays by subsetting the rows using the collection of <code>indices</code>, and then applies each layer in <code>layers</code> to the corresponding sub-array.</p><p>Specifically, for each <code>i</code> = 1, …, <span>$n$</span>, with <span>$n$</span> the number of <code>layers</code>, <code>SplitApply(x)</code> performs <code>layers[i](x[indices[i], :])</code>, and then vertically concatenates the resulting transformed arrays.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators

d = 4
K = 50
p₁ = 2          # number of non-covariance matrix parameters
p₂ = d*(d+1)÷2  # number of covariance matrix parameters
p = p₁ + p₂

a = [0.1, 4]
b = [0.9, 9]
l₁ = Compress(a, b)
l₂ = CovarianceMatrix(d)
l = SplitApply([l₁, l₂], [1:p₁, p₁+1:p])

θ = randn(p, K)
l(θ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/a9ee33ed0e997e88efd2854d865e4ad3a485a6cb/src/Architectures.jl#L812-L841">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../core/">« Core</a><a class="docs-footer-nextpage" href="../loss/">Loss functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 16 May 2023 01:42">Tuesday 16 May 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
