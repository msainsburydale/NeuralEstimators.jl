<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Core · NeuralEstimators.jl</title><meta name="title" content="Core · NeuralEstimators.jl"/><meta property="og:title" content="Core · NeuralEstimators.jl"/><meta property="twitter:title" content="Core · NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Core</a><ul class="internal"><li><a class="tocitem" href="#Sampling-parameters"><span>Sampling parameters</span></a></li><li><a class="tocitem" href="#Simulating-data"><span>Simulating data</span></a></li><li><a class="tocitem" href="#Types-of-estimators"><span>Types of estimators</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#Assessing-a-neural-estimator"><span>Assessing a neural estimator</span></a></li><li><a class="tocitem" href="#Uncertainty-quantification"><span>Uncertainty quantification</span></a></li></ul></li><li><a class="tocitem" href="../architectures/">Architectures</a></li><li><a class="tocitem" href="../summarystatistics/">User-defined summary statistics</a></li><li><a class="tocitem" href="../activationfunctions/">Output activation functions</a></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Core</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Core</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/core.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Core"><a class="docs-heading-anchor" href="#Core">Core</a><a id="Core-1"></a><a class="docs-heading-anchor-permalink" href="#Core" title="Permalink"></a></h1><p>This page documents the functions that are central to the workflow of <code>NeuralEstimators</code>. Its organisation reflects the order in which these functions appear in a standard implementation; that is, from sampling parameters from the prior distribution, to uncertainty quantification of the final estimates via bootstrapping.</p><h2 id="Sampling-parameters"><a class="docs-heading-anchor" href="#Sampling-parameters">Sampling parameters</a><a id="Sampling-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-parameters" title="Permalink"></a></h2><p>Parameters sampled from the prior distribution <span>$\Omega(\cdot)$</span> are stored as a <span>$p \times K$</span> matrix, where <span>$p$</span> is the number of parameters in the model and <span>$K$</span> is the number of parameter vectors sampled from the prior distribution.</p><p>It can sometimes be helpful to wrap the parameter matrix in a user-defined type that also stores expensive intermediate objects needed for data simulated (e.g., Cholesky factors). In this case, the user-defined type should be a subtype of the abstract type <a href="#NeuralEstimators.ParameterConfigurations"><code>ParameterConfigurations</code></a>, whose only requirement is a field <code>θ</code> that stores the matrix of parameters. See <a href="../../workflow/advancedusage/#Storing-expensive-intermediate-objects-for-data-simulation">Storing expensive intermediate objects for data simulation</a> for further discussion.   </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.ParameterConfigurations" href="#NeuralEstimators.ParameterConfigurations"><code>NeuralEstimators.ParameterConfigurations</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ParameterConfigurations</code></pre><p>An abstract supertype for user-defined types that store parameters and any intermediate objects needed for data simulation.</p><p>The user-defined type must have a field <code>θ</code> that stores the <span>$p$</span> × <span>$K$</span> matrix of parameters, where <span>$p$</span> is the number of parameters in the model and <span>$K$</span> is the number of parameter vectors sampled from the prior distribution. There are no other restrictions.</p><p>See <a href="../utility/#NeuralEstimators.subsetparameters"><code>subsetparameters</code></a> for the generic function for subsetting these objects.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">struct P &lt;: ParameterConfigurations
	θ
	# other expensive intermediate objects...
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/Parameters.jl#L1-L22">source</a></section></article><h2 id="Simulating-data"><a class="docs-heading-anchor" href="#Simulating-data">Simulating data</a><a id="Simulating-data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-data" title="Permalink"></a></h2><p><code>NeuralEstimators</code> facilitates neural estimation for arbitrary statistical models by having the user implicitly define the model via simulated data. The user may provide simulated data directly, or provide a function that simulates data from the model.</p><p>The data should be stored as a <code>Vector{A}</code>, where each element of the vector is associated with one parameter configuration, and where <code>A</code> depends on the architecture of the neural estimator.</p><h2 id="Types-of-estimators"><a class="docs-heading-anchor" href="#Types-of-estimators">Types of estimators</a><a id="Types-of-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Types-of-estimators" title="Permalink"></a></h2><p>See also <a href="../architectures/#Architectures">Architectures</a> that are often used when constructing neural estimators, and the convenience constructor <a href="../utility/#NeuralEstimators.initialise_estimator"><code>initialise_estimator</code></a>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.NeuralEstimator" href="#NeuralEstimators.NeuralEstimator"><code>NeuralEstimators.NeuralEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NeuralEstimator</code></pre><p>An abstract supertype for neural estimators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/Estimators.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PointEstimator" href="#NeuralEstimators.PointEstimator"><code>NeuralEstimators.PointEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PointEstimator(arch)</code></pre><p>A neural point estimator, that is, a mapping from the sample space to the parameter space, defined by the given neural-network architecture <code>arch</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/Estimators.jl#L13-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.IntervalEstimator" href="#NeuralEstimators.IntervalEstimator"><code>NeuralEstimators.IntervalEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">IntervalEstimator(u, v = u; probs = [0.025, 0.975])
IntervalEstimator(u, g::Compress; probs = [0.025, 0.975])
IntervalEstimator(u, v, g::Compress; probs = [0.025, 0.975])</code></pre><p>A neural interval estimator which, given data <span>$Z$</span>, jointly estimates credible intervals based on the probability levels <code>probs</code> of the form,</p><p class="math-container">\[[g(u(Z)), 	g(u(Z)) + \mathrm{exp}(v(Z)))],\]</p><p>where</p><ul><li><span>$u(⋅)$</span> and <span>$v(⋅)$</span> are neural networks, both of which should transform data into <span>$p$</span>-dimensional vectors (with <span>$p$</span> the number of parameters in the statistical model);</li><li><span>$g(⋅)$</span> is either the identity function or a logistic function that maps its input to the prior support.</li></ul><p>The prior support may be defined by a <span>$p$</span>-dimensional object of type <a href="../activationfunctions/#NeuralEstimators.Compress"><code>Compress</code></a>. Otherwise, the range of the intervals will be unrestricted (i.e., <span>$g(⋅)$</span> will be the identity function).</p><p>Note that, in addition to ensuring that the interval remains in the prior support, this construction also ensures that the intervals are valid (i.e., it prevents quantile crossing, in the sense that the upper bound is always greater than the lower bound).</p><p>If only a single neural-network architecture is provided, it will be used for both <code>u</code> and <code>v</code>.</p><p>The returned value is a matrix with <span>$2p$</span> rows, where the first and second <span>$p$</span> rows correspond to the lower and upper bounds, respectively.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

# Generate some toy data
n = 2   # bivariate data
m = 100 # number of independent replicates
Z = rand(n, m)

# prior
p = 3  # number of parameters in the statistical model
min_supp = [25, 0.5, -pi/2]
max_supp = [500, 2.5, 0]
g = Compress(min_supp, max_supp)

# Create an architecture
w = 8  # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
u = DeepSet(ψ, ϕ)
v = deepcopy(u) # use the same architecture for both u and v

# Initialise the interval estimator
estimator = IntervalEstimator(u, v, g)

# Apply the (untrained) interval estimator
estimator(Z)
interval(estimator, Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/Estimators.jl#L30-L92">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PiecewiseEstimator" href="#NeuralEstimators.PiecewiseEstimator"><code>NeuralEstimators.PiecewiseEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PiecewiseEstimator(estimators, breaks)</code></pre><p>Creates a piecewise estimator from a collection of <code>estimators</code>, based on the collection of changepoints, <code>breaks</code>, which should contain one element fewer than the number of <code>estimators</code>.</p><p>Any estimator can be included in <code>estimators</code>, including any of the subtypes of <code>NeuralEstimator</code> exported with the package <code>NeuralEstimators</code> (e.g., <code>PointEstimator</code>, <code>IntervalEstimator</code>, etc.).</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Suppose that we&#39;ve trained two neural estimators. The first, θ̂₁, is trained
# for small sample sizes (e.g., m ≤ 30), and the second, `θ̂₂`, is trained for
# moderate-to-large sample sizes (e.g., m &gt; 30). We construct a piecewise
# estimator with a sample-size changepoint of 30, which dispatches θ̂₁ if m ≤ 30
# and θ̂₂ if m &gt; 30.

using NeuralEstimators
using Flux

n = 2  # bivariate data
p = 3  # number of parameters in the statistical model
w = 8  # width of each layer

ψ₁ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ₁ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂₁ = DeepSet(ψ₁, ϕ₁)

ψ₂ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ₂ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂₂ = DeepSet(ψ₂, ϕ₂)

θ̂ = PiecewiseEstimator([θ̂₁, θ̂₂], [30])
Z = [rand(n, 1, m) for m ∈ (10, 50)]
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/Estimators.jl#L115-L152">source</a></section></article><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><p>The function <a href="#NeuralEstimators.train"><code>train</code></a> is used to train a single neural estimator, while the wrapper function <a href="#NeuralEstimators.trainx"><code>trainx</code></a> is useful for training multiple neural estimators over a range of sample sizes, making using of the technique known as pre-training.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.train" href="#NeuralEstimators.train"><code>NeuralEstimators.train</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train(θ̂, sampler::Function, simulator::Function; ...)
train(θ̂, θ_train::P, θ_val::P, simulator::Function; ...) where {P &lt;: Union{AbstractMatrix, ParameterConfigurations}}
train(θ̂, θ_train::P, θ_val::P, Z_train::T, Z_val::T; ...) where {T, P &lt;: Union{AbstractMatrix, ParameterConfigurations}}</code></pre><p>Train a neural estimator <code>θ̂</code>.</p><p>The methods cater for different variants of &quot;on-the-fly&quot; simulation. Specifically, a <code>sampler</code> can be provided to continuously sample new parameter vectors from the prior, and a <code>simulator</code> can be provided to continuously simulate new data conditional on the parameters. If provided with specific sets of parameters (<code>θ_train</code> and <code>θ_val</code>) and/or data (<code>Z_train</code> and <code>Z_val</code>), they will be held fixed during training.</p><p>In all methods, the validation parameters and data are held fixed to reduce noise when evaluating the validation risk.</p><p><strong>Keyword arguments common to all methods:</strong></p><ul><li><code>loss = mae</code></li><li><code>epochs::Integer = 100</code></li><li><code>batchsize::Integer = 32</code></li><li><code>optimiser = ADAM(1e-4)</code></li><li><code>savepath::String = &quot;&quot;</code>: path to save the neural-network weights during training (as <code>bson</code> files) and other information, such as the risk vs epoch (the risk function evaluated over the training and validation sets are saved in the first and second columns of <code>loss_per_epoch.csv</code>). If <code>savepath</code> is an empty string (default), nothing is saved.</li><li><code>stopping_epochs::Integer = 5</code>: cease training if the risk doesn&#39;t improve in this number of epochs.</li><li><code>use_gpu::Bool = true</code></li><li><code>verbose::Bool = true</code></li></ul><p><strong>Keyword arguments common to <code>train(θ̂, sampler, simulator)</code> and <code>train(θ̂, θ_train, θ_val, simulator)</code>:</strong></p><ul><li><code>m</code>: sample sizes (either an <code>Integer</code> or a collection of <code>Integers</code>). The <code>simulator</code> is called as <code>simulator(θ, m)</code>.</li><li><code>epochs_per_Z_refresh::Integer = 1</code>: how often to refresh the training data.</li><li><code>simulate_just_in_time::Bool = false</code>: flag indicating whether we should simulate just-in-time, in the sense that only a <code>batchsize</code> number of parameter vectors and corresponding data are in memory at a given time.</li></ul><p><strong>Keyword arguments unique to <code>train(θ̂, sampler, simulator)</code>:</strong></p><ul><li><code>K::Integer = 10000</code>: number of parameter vectors in the training set; the size of the validation set is <code>K ÷ 5</code>.</li><li><code>ξ = nothing</code>: an arbitrary collection of objects that are fixed (e.g., distance matrices). If provided, the parameter sampler is called as <code>sampler(K, ξ)</code>; otherwise, the parameter sampler will be called as <code>sampler(K)</code>. Can also be provided as <code>xi</code>.</li><li><code>epochs_per_θ_refresh::Integer = 1</code>: how often to refresh the training parameters. Must be a multiple of <code>epochs_per_Z_refresh</code>. Can also be provided as <code>epochs_per_theta_refresh</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

# parameter sampler
function sampler(K)
	μ = randn(K) # Gaussian prior
	σ = rand(K)  # Uniform prior
	θ = hcat(μ, σ)&#39;
	θ = Float32.(θ)
	return θ
end

# data simulator
simulator(θ_matrix, m) = [θ[1] .+ θ[2] * randn(Float32, 1, m) for θ ∈ eachcol(θ_matrix)]

# architecture
d = 1   # dimension of each replicate
p = 2   # number of parameters in the statistical model
ψ = Chain(Dense(1, 32, relu), Dense(32, 32, relu))
ϕ = Chain(Dense(32, 32, relu), Dense(32, p))
θ̂ = DeepSet(ψ, ϕ)

# number of independent replicates to use during training
m = 15

# training: full simulation on-the-fly
θ̂ = train(θ̂, sampler, simulator, m = m, epochs = 5)

# training: simulation on-the-fly with fixed parameters
K = 10000
θ_train = sampler(K)
θ_val   = sampler(K ÷ 5)
θ̂ 		 = train(θ̂, θ_train, θ_val, simulator, m = m, epochs = 5)

# training: fixed parameters and fixed data
Z_train = simulator(θ_train, m)
Z_val   = simulator(θ_val, m)
θ̂ 		 = train(θ̂, θ_train, θ_val, Z_train, Z_val, epochs = 5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/train.jl#L1-L78">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.trainx" href="#NeuralEstimators.trainx"><code>NeuralEstimators.trainx</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">trainx(θ̂, sampler::Function, simulator::Function, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, simulator::Function, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, Z_train, Z_val, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, Z_train::V, Z_val::V; ...) where {V &lt;: AbstractVector{AbstractVector{Any}}}</code></pre><p>A wrapper around <code>train()</code> to construct neural estimators for different sample sizes.</p><p>The positional argument <code>m</code> specifies the desired sample sizes. Each estimator is pre-trained with the estimator for the previous sample size. For example, if <code>m = [m₁, m₂]</code>, the estimator for sample size <code>m₂</code> is pre-trained with the estimator for sample size <code>m₁</code>.</p><p>The method for <code>Z_train</code> and <code>Z_val</code> subsets the data using <code>subsetdata(Z, 1:mᵢ)</code> for each <code>mᵢ ∈ m</code>. The method for <code>Z_train::V</code> and <code>Z_val::V</code> trains an estimator for each element of <code>Z_train::V</code> and <code>Z_val::V</code> and, hence, it does not need to invoke <code>subsetdata()</code>, which can be slow or difficult to define in some cases (e.g., for graphical data). Note that, in this case, <code>m</code> is inferred from the data.</p><p>The keyword arguments inherit from <code>train()</code>. The keyword arguments <code>epochs</code>, <code>batchsize</code>, <code>stopping_epochs</code>, and <code>optimiser</code> can each be given as vectors. For example, if we are training two estimators, we can use a different number of epochs for each estimator by providing <code>epochs = [epoch₁, epoch₂]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/train.jl#L484-L508">source</a></section></article><h2 id="Assessing-a-neural-estimator"><a class="docs-heading-anchor" href="#Assessing-a-neural-estimator">Assessing a neural estimator</a><a id="Assessing-a-neural-estimator-1"></a><a class="docs-heading-anchor-permalink" href="#Assessing-a-neural-estimator" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.assess" href="#NeuralEstimators.assess"><code>NeuralEstimators.assess</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">assess(estimators, θ, Z)</code></pre><p>Using a collection of <code>estimators</code>, compute estimates from data <code>Z</code> simulated based on true parameter vectors stored in <code>θ</code>.</p><p>The data <code>Z</code> should be a <code>Vector</code>, with each element corresponding to a single simulated data set. If <code>Z</code> contains more data sets than parameter vectors, the parameter matrix <code>θ</code> will be recycled by horizontal concatenation via the call <code>θ = repeat(θ, outer = (1, J))</code> where <code>J = length(Z) ÷ K</code> is the number of simulated data sets and <code>K = size(θ, 2)</code> is the number of parameter vectors.</p><p>The output is of type <code>Assessment</code>; see <code>?Assessment</code> for details.</p><p><strong>Keyword arguments</strong></p><ul><li><code>estimator_names::Vector{String}</code>: names of the estimators (sensible defaults provided).</li><li><code>parameter_names::Vector{String}</code>: names of the parameters (sensible defaults provided). If <code>ξ</code> is provided with a field <code>parameter_names</code>, those names will be used.</li><li><code>ξ = nothing</code>: an arbitrary collection of objects that are fixed (e.g., distance matrices). Can also be provided as <code>xi</code>.</li><li><code>use_ξ = false</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators. Specifies whether or not the estimator uses <code>ξ</code>: if it does, the estimator will be applied as <code>estimator(Z, ξ)</code>. This argument is useful when multiple <code>estimators</code> are provided, only some of which need <code>ξ</code>; hence, if only one estimator is provided and <code>ξ</code> is not <code>nothing</code>, <code>use_ξ</code> is automatically set to <code>true</code>. Can also be provided as <code>use_xi</code>.</li><li><code>use_gpu = true</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators.</li><li><code>verbose::Bool = true</code></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

n = 10 # number of observations in each realisation
p = 4  # number of parameters in the statistical model

# Construct the neural estimator
w = 32 # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂ = DeepSet(ψ, ϕ)

# Generate testing parameters
K = 100
θ = rand(Float32, p, K)

# Data for a single sample size
m = 30
Z = [rand(Float32, n, m) for _ ∈ 1:K];
assessment = assess(θ̂, θ, Z);
risk(assessment)

# Multiple data sets for each parameter vector
J = 5
Z = repeat(Z, J);
assessment = assess(θ̂, θ, Z);
risk(assessment)

# With set-level information
qₓ = 2
ϕ  = Chain(Dense(w + qₓ, w, relu), Dense(w, p));
θ̂ = DeepSet(ψ, ϕ)
x = [rand(qₓ) for _ ∈ eachindex(Z)]
assessment = assess(θ̂, θ, (Z, x));
risk(assessment)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L298-L358">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Assessment" href="#NeuralEstimators.Assessment"><code>NeuralEstimators.Assessment</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Assessment(df::DataFrame, runtime::DataFrame)</code></pre><p>A type for storing the output of <code>assess()</code>. The field <code>runtime</code> contains the total time taken for each estimator. The field <code>df</code> is a long-form <code>DataFrame</code> with columns:</p><ul><li><code>estimator</code>: the name of the estimator</li><li><code>parameter</code>: the name of the parameter</li><li><code>truth</code>:     the true value of the parameter</li><li><code>estimate</code>:  the estimated value of the parameter</li><li><code>m</code>:         the sample size (number of iid replicates) for the given data set</li><li><code>k</code>:         the index of the parameter vector</li><li><code>j</code>:         the index of the data set (in the case that multiple data sets are associated with each parameter vector)</li></ul><p>Note that if <code>estimator</code> is an <code>IntervalEstimator</code>, the column <code>estimate</code> will be replaced by the columns <code>lower</code> and <code>upper</code>, containing the lower and upper bounds of the interval, respectively.</p><p>Multiple <code>Assessment</code> objects can be combined with <code>merge()</code> (used for combining assessments from multiple point estimators) or <code>join()</code> (used for combining assessments from a point estimator and an interval estimator).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.diagnostics" href="#NeuralEstimators.diagnostics"><code>NeuralEstimators.diagnostics</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">diagnostics(assessment::Assessment; args...)</code></pre><p>Computes all applicable diagnostics.</p><p>For a <a href="#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a>, the relevant diagnostics are the estimator&#39;s <a href="#NeuralEstimators.bias"><code>bias</code></a>, <a href="#NeuralEstimators.rmse"><code>rmse</code></a>, and <a href="#NeuralEstimators.risk"><code>risk</code></a>, while for an <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> the relevant diagnostics are the <a href="#NeuralEstimators.coverage"><code>coverage</code></a> and <a href="../loss/#NeuralEstimators.intervalscore"><code>intervalscore</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L263-L271">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.risk" href="#NeuralEstimators.risk"><code>NeuralEstimators.risk</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">risk(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s Bayes risk,</p><p class="math-container">\[r(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K L(\boldsymbol{\theta}^{(k)}, \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)})),\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>loss = (x, y) -&gt; abs(x - y)</code>: a binary operator defining the loss function (default absolute-error loss).</li><li><code>average_over_parameters::Bool = false</code>: if true, the loss is averaged over all parameters; otherwise (default), the loss is averaged over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the loss is averaged over all sample sizes <span>$m$</span>; otherwise, the loss is averaged over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L108-L126">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bias" href="#NeuralEstimators.bias"><code>NeuralEstimators.bias</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bias(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s bias,</p><p class="math-container">\[{\rm{bias}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L146-L161">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.rmse" href="#NeuralEstimators.rmse"><code>NeuralEstimators.rmse</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">rmse(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s root-mean-squared error,</p><p class="math-container">\[{\rm{rmse}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\sqrt{\frac{1}{K} \sum_{k=1}^K (\hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)})^2},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L173-L188">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.coverage" href="#NeuralEstimators.coverage"><code>NeuralEstimators.coverage</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">coverage(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an interval estimator&#39;s expected coverage.</p><p><strong>Keyword arguments</strong></p><ul><li><code>average_over_parameters::Bool = false</code>: if true, the coverage is averaged over all parameters; otherwise (default), it is computed over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the coverage is averaged over all sample sizes <span>$m$</span>; otherwise, it is computed over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/assess.jl#L203-L211">source</a></section></article><h2 id="Uncertainty-quantification"><a class="docs-heading-anchor" href="#Uncertainty-quantification">Uncertainty quantification</a><a id="Uncertainty-quantification-1"></a><a class="docs-heading-anchor-permalink" href="#Uncertainty-quantification" title="Permalink"></a></h2><p>Uncertainty quantification often proceeds through the bootstrap distribution, which is essentially available &quot;for free&quot; when bootstrap data sets can be quickly generated. Alternatively, one may approximate a set of low and high marginal posterior quantiles using a specially constructed neural Bayes estimator, which can then be used to construct credible intervals: see <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> and its variants.  </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bootstrap" href="#NeuralEstimators.bootstrap"><code>NeuralEstimators.bootstrap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bootstrap(θ̂, parameters::P, Z) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(θ̂, parameters::P, simulator, m::Integer; B = 400) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(θ̂, Z; B = 400, blocks = nothing)</code></pre><p>Generates <code>B</code> bootstrap estimates from an estimator <code>θ̂</code>.</p><p>Parametric bootstrapping is facilitated by passing a single parameter configuration, <code>parameters</code>, and corresponding simulated data, <code>Z</code>, whose length implicitly defines <code>B</code>. Alternatively, one may provide a <code>simulator</code> and the desired sample size, in which case the data will be simulated using <code>simulator(parameters, m)</code>.</p><p>Non-parametric bootstrapping is facilitated by passing a single data set, <code>Z</code>. The argument <code>blocks</code> caters for block bootstrapping, and it should be a vector of integers specifying the block for each replicate. For example, with 5 replicates, the first two corresponding to block 1 and the remaining three corresponding to block 2, <code>blocks</code> should be <code>[1, 1, 2, 2, 2]</code>. The resampling algorithm aims to produce resampled data sets that are of a similar size to <code>Z</code>, but this can only be achieved exactly if all blocks are equal in length.</p><p>The keyword argument <code>use_gpu</code> is a flag determining whether to use the GPU, if it is available (default <code>true</code>).</p><p>The return type is a p × <code>B</code> matrix, where p is the number of parameters in the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/bootstrap.jl#L89-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.interval" href="#NeuralEstimators.interval"><code>NeuralEstimators.interval</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">interval(bs::Matrix; probs = [0.05, 0.95], parameter_names = nothing)
interval(estimator::IntervalEstimator, Z; parameter_names = nothing, use_gpu = true)</code></pre><p>Compute a confidence interval based on a p × B matrix of bootstrap estimates, <code>bs</code>, where p is the number of parameters in the model, or from an <code>IntervalEstimator</code> and data <code>Z</code>.</p><p>The bootstrap-based interval is constructed by taking the quantiles of <code>bs</code>, where the quantile levels are controlled by the keyword argument <code>probs</code>.</p><p>The return type is a p × 2 matrix, whose first and second columns respectively contain the lower and upper bounds of the interval. The rows of this matrix can be named by passing a vector of strings to the keyword argument <code>parameter_names</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
p = 3
B = 50
bs = rand(p, B)
θ̂ = rand(p)
interval(bs)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/d05036519e479b2c62ae080dded3b197f470144e/src/bootstrap.jl#L1-L25">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../workflow/advancedusage/">« Advanced usage</a><a class="docs-footer-nextpage" href="../architectures/">Architectures »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Friday 1 March 2024 06:12">Friday 1 March 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
