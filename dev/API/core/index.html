<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Core · NeuralEstimators.jl</title><meta name="title" content="Core · NeuralEstimators.jl"/><meta property="og:title" content="Core · NeuralEstimators.jl"/><meta property="twitter:title" content="Core · NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Core</a><ul class="internal"><li><a class="tocitem" href="#Sampling-parameters"><span>Sampling parameters</span></a></li><li><a class="tocitem" href="#Simulating-data"><span>Simulating data</span></a></li><li><a class="tocitem" href="#Estimators"><span>Estimators</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#Assessment/calibration"><span>Assessment/calibration</span></a></li><li><a class="tocitem" href="#Inference-with-observed-data"><span>Inference with observed data</span></a></li></ul></li><li><a class="tocitem" href="../architectures/">Architectures</a></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Core</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Core</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/core.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Core"><a class="docs-heading-anchor" href="#Core">Core</a><a id="Core-1"></a><a class="docs-heading-anchor-permalink" href="#Core" title="Permalink"></a></h1><p>This page documents the classes and functions that are central to the workflow of <code>NeuralEstimators</code>. Its organisation reflects the order in which these classes and functions appear in a standard implementation; that is, from sampling parameters from the prior distribution, to using a neural Bayes estimator to make inference with observed data sets.</p><h2 id="Sampling-parameters"><a class="docs-heading-anchor" href="#Sampling-parameters">Sampling parameters</a><a id="Sampling-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-parameters" title="Permalink"></a></h2><p>Parameters sampled from the prior distribution are stored as a <span>$p \times K$</span> matrix, where <span>$p$</span> is the number of parameters in the statistical model and <span>$K$</span> is the number of parameter vectors sampled from the prior distribution.</p><p>It can sometimes be helpful to wrap the parameter matrix in a user-defined type that also stores expensive intermediate objects needed for data simulated (e.g., Cholesky factors). In this case, the user-defined type should be a subtype of the abstract type <a href="#NeuralEstimators.ParameterConfigurations"><code>ParameterConfigurations</code></a>, whose only requirement is a field <code>θ</code> that stores the matrix of parameters. See <a href="../../workflow/advancedusage/#Storing-expensive-intermediate-objects-for-data-simulation">Storing expensive intermediate objects for data simulation</a> for further discussion.   </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.ParameterConfigurations" href="#NeuralEstimators.ParameterConfigurations"><code>NeuralEstimators.ParameterConfigurations</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ParameterConfigurations</code></pre><p>An abstract supertype for user-defined types that store parameters and any intermediate objects needed for data simulation.</p><p>The user-defined type must have a field <code>θ</code> that stores the <span>$p$</span> × <span>$K$</span> matrix of parameters, where <span>$p$</span> is the number of parameters in the model and <span>$K$</span> is the number of parameter vectors sampled from the prior distribution. There are no other restrictions.</p><p>See <a href="../utility/#NeuralEstimators.subsetparameters"><code>subsetparameters</code></a> for the generic function for subsetting these objects.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">struct P &lt;: ParameterConfigurations
	θ
	# other expensive intermediate objects...
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Parameters.jl#L1-L22">source</a></section></article><h2 id="Simulating-data"><a class="docs-heading-anchor" href="#Simulating-data">Simulating data</a><a id="Simulating-data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-data" title="Permalink"></a></h2><p><code>NeuralEstimators</code> facilitates neural estimation for arbitrary statistical models by having the user implicitly define their model via simulated data, either as fixed instances or via a function that simulates data from the statistical model.</p><p>The data are always stored as a <code>Vector{A}</code>, where each element of the vector corresponds to a data set of <span>$m$</span> independent replicates associated with one parameter vector (note that <span>$m$</span> is arbitrary), and where the type <code>A</code> depends on the multivariate structure of the data:</p><ul><li>For univariate and unstructured multivariate data, <code>A</code> is a <span>$d \times m$</span> matrix where <span>$d$</span> is the dimension each replicate (e.g., <span>$d=1$</span> for univariate data).</li><li>For data collected over a regular grid, <code>A</code> is a (<span>$N + 2$</span>)-dimensional array, where <span>$N$</span> is the dimension of the grid (e.g., <span>$N = 1$</span> for time series, <span>$N = 2$</span> for two-dimensional spatial grids, etc.). The first <span>$N$</span> dimensions of the array correspond to the dimensions of the grid; the penultimate dimension stores the so-called &quot;channels&quot; (this dimension is singleton for univariate processes, two for bivariate processes, and so on); and the final dimension stores the independent replicates. For example, to store 50 independent replicates of a bivariate spatial process measured over a 10x15 grid, one would construct an array of dimension 10x15x2x50.</li><li>For spatial data collected over irregular spatial locations, <code>A</code> is a <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/dev/api/gnngraph/#GraphNeuralNetworks.GNNGraphs.GNNGraph"><code>GNNGraph</code></a> with independent replicates (possibly with differing spatial locations) stored as subgraphs using the function <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/dev/api/gnngraph/#MLUtils.batch-Tuple{AbstractVector{%3C:GNNGraph}}"><code>batch</code></a>.</li></ul><h2 id="Estimators"><a class="docs-heading-anchor" href="#Estimators">Estimators</a><a id="Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Estimators" title="Permalink"></a></h2><p>Several classes of neural estimators are available in the package.</p><p>The simplest class is <a href="#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a>, used for constructing arbitrary mappings from the sample space to the parameter space. When constructing a generic point estimator, the user defines the loss function and therefore the Bayes estimator that will be targeted.</p><p>Several classes cater for the estimation of marginal posterior quantiles, based on the quantile loss function (see <a href="../loss/#NeuralEstimators.quantileloss"><code>quantileloss()</code></a>); in particular, see <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> and <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a> for estimating marginal posterior quantiles for a fixed set of probability levels, and <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a> for estimating marginal posterior quantiles with the probability level as an input to the neural network.</p><p>In addition to point estimation, the package also provides the class <a href="#NeuralEstimators.RatioEstimator"><code>RatioEstimator</code></a> for approximating the so-called likelihood-to-evidence ratio. The binary classification problem at the heart of this approach proceeds based on the binary cross-entropy loss.</p><p>Users are free to choose the neural-network architecture of these estimators as they see fit (subject to some class-specific requirements), but the package also provides the convenience constructor <a href="../utility/#NeuralEstimators.initialise_estimator"><code>initialise_estimator()</code></a>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.NeuralEstimator" href="#NeuralEstimators.NeuralEstimator"><code>NeuralEstimators.NeuralEstimator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NeuralEstimator</code></pre><p>An abstract supertype for neural estimators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PointEstimator" href="#NeuralEstimators.PointEstimator"><code>NeuralEstimators.PointEstimator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PointEstimator(deepset::DeepSet)</code></pre><p>A neural point estimator, a mapping from the sample space to the parameter space.</p><p>The estimator leverages the <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a> architecture. The only requirement is that number of output neurons in the final layer of the inference network (i.e., the outer network) is equal to the number of parameters in the statistical model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L10-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.IntervalEstimator" href="#NeuralEstimators.IntervalEstimator"><code>NeuralEstimators.IntervalEstimator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">IntervalEstimator(u::DeepSet, v::DeepSet = u; probs = [0.025, 0.975], g::Function = exp)
IntervalEstimator(u::DeepSet, c::Union{Function,Compress}; probs = [0.025, 0.975], g::Function = exp)
IntervalEstimator(u::DeepSet, v::DeepSet, c::Union{Function,Compress}; probs = [0.025, 0.975], g::Function = exp)</code></pre><p>A neural interval estimator which, given data <span>$Z$</span>, jointly estimates marginal posterior credible intervals based on the probability levels <code>probs</code>.</p><p>The estimator employs a representation that prevents quantile crossing, namely, it constructs marginal posterior credible intervals for each parameter <span>$\theta_i$</span>, <span>$i = 1, \dots, p,$</span>  of the form,</p><p class="math-container">\[[c_i(u_i(\boldsymbol{Z})), \;\; c_i(u_i(\boldsymbol{Z})) + g(v_i(\boldsymbol{Z})))],\]</p><p>where  <span>$\boldsymbol{u}(⋅) \equiv (u_1(\cdot), \dots, u_p(\cdot))&#39;$</span> and <span>$\boldsymbol{v}(⋅) \equiv (v_1(\cdot), \dots, v_p(\cdot))&#39;$</span> are neural networks that transform data into <span>$p$</span>-dimensional vectors; <span>$g(\cdot)$</span> is a monotonically increasing function (e.g., exponential or softplus); and each <span>$c_i(⋅)$</span> is a monotonically increasing function that maps its input to the prior support of <span>$\theta_i$</span>.</p><p>The functions <span>$c_i(⋅)$</span> may be defined by a <span>$p$</span>-dimensional object of type <a href="../architectures/#NeuralEstimators.Compress"><code>Compress</code></a>. If these functions are unspecified, they will be set to the identity function so that the range of the intervals will be unrestricted.</p><p>If only a single neural-network architecture is provided, it will be used for both <span>$\boldsymbol{u}(⋅)$</span> and <span>$\boldsymbol{v}(⋅)$</span>.</p><p>The return value  when applied to data is a matrix with <span>$2p$</span> rows, where the first and second <span>$p$</span> rows correspond to the lower and upper bounds, respectively.</p><p>See also <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a> and <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Generate some toy data
n = 2   # bivariate data
m = 100 # number of independent replicates
Z = rand(n, m)

# prior
p = 3  # number of parameters in the statistical model
min_supp = [25, 0.5, -pi/2]
max_supp = [500, 2.5, 0]
g = Compress(min_supp, max_supp)

# Create an architecture
w = 8  # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
u = DeepSet(ψ, ϕ)

# Initialise the interval estimator
estimator = IntervalEstimator(u, g)

# Apply the (untrained) interval estimator
estimator(Z)
interval(estimator, Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L31-L93">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.QuantileEstimatorDiscrete" href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>NeuralEstimators.QuantileEstimatorDiscrete</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">QuantileEstimatorDiscrete(v::DeepSet; probs = [0.05, 0.25, 0.5, 0.75, 0.95], g = Flux.softplus, i = nothing)
(estimator::QuantileEstimatorDiscrete)(Z)
(estimator::QuantileEstimatorDiscrete)(Z, θ₋ᵢ)</code></pre><p>A neural estimator that jointly estimates a fixed set of marginal posterior quantiles with probability levels <span>$\{\tau_1, \dots, \tau_T\}$</span>, controlled by the keyword argument <code>probs</code>.</p><p>By default, the estimator approximates the marginal quantiles for all parameters in the model, that is, the quantiles of</p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}\]</p><p>for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_p)&#39;$</span>. Alternatively, if initialised with <code>i</code> set to a positive integer, the estimator approximates the quantiles of the full conditional distribution</p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \boldsymbol{\theta}_{-i},\]</p><p>where <span>$\boldsymbol{\theta}_{-i}$</span> denotes the parameter vector with its <span>$i$</span>th element removed. For ease of exposition, when targetting marginal posteriors of the form <span>$\theta_i \mid \boldsymbol{Z}$</span> (i.e., the default behaviour), we define <span>$\text{dim}(\boldsymbol{\theta}_{-i}) ≡ 0$</span>.</p><p>The estimator leverages the <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a> architecture, subject to two requirements. First, the number of input neurons in the first layer of the inference network (i.e., the outer network) must be equal to the number of neurons in the final layer of the summary network plus <span>$\text{dim}(\boldsymbol{\theta}_{-i})$</span>. Second, the number of output neurons in the final layer of the inference network must be equal to <span>$p - \text{dim}(\boldsymbol{\theta}_{-i})$</span>.  The estimator employs a representation that prevents quantile crossing, namely,</p><p class="math-container">\[\begin{aligned}
\boldsymbol{q}^{(\tau_1)}(\boldsymbol{Z}) &amp;= \boldsymbol{v}^{(\tau_1)}(\boldsymbol{Z}),\\
\boldsymbol{q}^{(\tau_t)}(\boldsymbol{Z}) &amp;= \boldsymbol{v}^{(\tau_1)}(\boldsymbol{Z}) + \sum_{j=2}^t g(\boldsymbol{v}^{(\tau_j)}(\boldsymbol{Z})), \quad t = 2, \dots, T,
\end{aligned}\]</p><p>where <span>$\boldsymbol{q}^{(\tau)}(\boldsymbol{Z})$</span> denotes the vector of <span>$\tau$</span>-quantiles for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_p)&#39;$</span>, and <span>$\boldsymbol{v}^{(\tau_t)}(\cdot)$</span>, <span>$t = 1, \dots, T$</span>, are unconstrained neural networks that transform data into <span>$p$</span>-dimensional vectors, and <span>$g(\cdot)$</span> is a non-negative function (e.g., exponential or softplus) applied elementwise to its arguments. If <code>g=nothing</code>, the quantiles are estimated independently through the representation,</p><p class="math-container">\[\boldsymbol{q}^{(\tau_t)}(\boldsymbol{Z}) = \boldsymbol{v}^{(\tau_t)}(\boldsymbol{Z}), \quad t = 1, \dots, T.\]</p><p>The return value is a matrix with <span>$(p - \text{dim}(\boldsymbol{\theta}_{-i})) \times T$</span> rows, where the first set of <span>$T$</span> rows corresponds to the estimated quantiles for the first parameter, the second set of <span>$T$</span> rows corresponds to the estimated quantiles for the second parameter, and so on.</p><p>See also <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> and <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, Distributions
using AlgebraOfGraphics, CairoMakie

# Model: Z|θ ~ N(θ, 1) with θ ~ N(0, 1)
d = 1   # dimension of each independent replicate
p = 1   # number of unknown parameters in the statistical model
m = 30  # number of independent replicates in each data set
prior(K) = randn32(p, K)
simulate(θ, m) = [μ .+ randn32(1, m) for μ ∈ eachcol(θ)]

# Architecture
ψ = Chain(Dense(d, 64, relu), Dense(64, 64, relu))
ϕ = Chain(Dense(64, 64, relu), Dense(64, p))
v = DeepSet(ψ, ϕ)

# Initialise the estimator
τ = [0.05, 0.25, 0.5, 0.75, 0.95]
q̂ = QuantileEstimatorDiscrete(v; probs = τ)

# Train the estimator
q̂ = train(q̂, prior, simulate, m = m)

# Assess the estimator
θ = prior(1000)
Z = simulate(θ, m)
assessment = assess(q̂, θ, Z)
plot(assessment)

# Estimate posterior quantiles
q̂(Z)


# -------------------------------------------------------------
# --------------------- Full conditionals ---------------------
# -------------------------------------------------------------


# Model: Z|μ,σ ~ N(μ, σ²) with μ ~ N(0, 1), σ ∼ IG(3,1)
d = 1         # dimension of each independent replicate
p = 2         # number of unknown parameters in the statistical model
m = 30        # number of independent replicates in each data set
function prior(K)
	μ = randn(1, K)
	σ = rand(InverseGamma(3, 1), 1, K)
	θ = Float32.(vcat(μ, σ))
end
simulate(θ, m) = [ϑ[1] .+ ϑ[2] .* randn32(1, m) for ϑ ∈ eachcol(θ)]

# Architecture
ψ = Chain(Dense(d, 64, relu), Dense(64, 64, relu))
ϕ = Chain(Dense(64 + 1, 64, relu), Dense(64, 1))
v = DeepSet(ψ, ϕ)

# Initialise estimators respectively targetting quantiles of μ∣Z,σ and σ∣Z,μ
τ = [0.05, 0.25, 0.5, 0.75, 0.95]
q₁ = QuantileEstimatorDiscrete(v; probs = τ, i = 1)
q₂ = QuantileEstimatorDiscrete(v; probs = τ, i = 2)

# Train the estimators
q₁ = train(q₁, prior, simulate, m = m)
q₂ = train(q₂, prior, simulate, m = m)

# Assess the estimators
θ = prior(1000)
Z = simulate(θ, m)
assessment = assess([q₁, q₂], θ, Z, parameter_names = [&quot;μ&quot;, &quot;σ&quot;])
plot(assessment)

# Estimate quantiles of μ∣Z,σ with σ = 0.5 and for many data sets
θ₋ᵢ = 0.5f0
q₁(Z, θ₋ᵢ)

# Estimate quantiles of μ∣Z,σ with σ = 0.5 for only a single data set
q₁(Z[1], θ₋ᵢ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L117-L251">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.QuantileEstimatorContinuous" href="#NeuralEstimators.QuantileEstimatorContinuous"><code>NeuralEstimators.QuantileEstimatorContinuous</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">QuantileEstimatorContinuous(deepset::DeepSet; i = nothing, num_training_probs::Integer = 1)
(estimator::QuantileEstimatorContinuous)(Z, τ)
(estimator::QuantileEstimatorContinuous)(Z, θ₋ᵢ, τ)</code></pre><p>A neural estimator targetting posterior quantiles.</p><p>Given as input data <span>$\boldsymbol{Z}$</span> and the desired probability level <span>$\tau ∈ (0, 1)$</span>, by default the estimator approximates the <span>$\tau$</span>-quantile of</p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}\]</p><p>for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_p)&#39;$</span>. Alternatively, if initialised with <code>i</code> set to a positive integer, the estimator approximates the <span>$\tau$</span>-quantile of the full conditional distribution</p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \boldsymbol{\theta}_{-i},\]</p><p>where <span>$\boldsymbol{\theta}_{-i}$</span> denotes the parameter vector with its <span>$i$</span>th element removed. For ease of exposition, when targetting marginal posteriors of the form <span>$\theta_i \mid \boldsymbol{Z}$</span> (i.e., the default behaviour), we define <span>$\text{dim}(\boldsymbol{\theta}_{-i}) ≡ 0$</span>.</p><p>The estimator leverages the <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a> architecture, subject to two requirements. First, the number of input neurons in the first layer of the inference network (i.e., the outer network) must be equal to the number of neurons in the final layer of the summary network plus <span>$1 + \text{dim}(\boldsymbol{\theta}_{-i})$</span>. Second, the number of output neurons in the final layer of the inference network must be equal to <span>$p - \text{dim}(\boldsymbol{\theta}_{-i})$</span>.</p><p>Although not a requirement, one may employ a (partially) monotonic neural network to prevent quantile crossing (i.e., to ensure that the <span>$\tau_1$</span>-quantile does not exceed the <span>$\tau_2$</span>-quantile for any <span>$\tau_2 &gt; \tau_1$</span>). There are several ways to construct such a neural network: one simple yet effective approach is to ensure that all weights associated with <span>$\tau$</span> are strictly positive (see, e.g., <a href="https://link.springer.com/article/10.1007/s00477-018-1573-6">Cannon, 2018</a>), and this can be done using the <a href="../architectures/#NeuralEstimators.DensePositive"><code>DensePositive</code></a> layer as illustrated in the examples below.</p><p>The return value is a matrix with <span>$p - \text{dim}(\boldsymbol{\theta}_{-i})$</span> rows, corresponding to the estimated quantile for each parameter not in <span>$\boldsymbol{\theta}_{-i}$</span>.</p><p>See also <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, Distributions , InvertedIndices, Statistics
using AlgebraOfGraphics, CairoMakie

# Model: Z|θ ~ N(θ, 1) with θ ~ N(0, 1)
d = 1         # dimension of each independent replicate
p = 1         # number of unknown parameters in the statistical model
m = 30        # number of independent replicates in each data set
prior(K) = randn32(p, K)
simulateZ(θ, m) = [ϑ .+ randn32(1, m) for ϑ ∈ eachcol(θ)]
simulateτ(K)    = [rand32(10) for k in 1:K]
simulate(θ, m)  = simulateZ(θ, m), simulateτ(size(θ, 2))

# Architecture: partially monotonic network to preclude quantile crossing
w = 64  # width of each hidden layer
ψ = Chain(
	Dense(d, w, relu),
	Dense(w, w, relu),
	Dense(w, w, relu)
	)
ϕ = Chain(
	DensePositive(Dense(w + 1, w, relu); last_only = true),
	DensePositive(Dense(w, w, relu)),
	DensePositive(Dense(w, p))
	)
deepset = DeepSet(ψ, ϕ)

# Initialise the estimator
q̂ = QuantileEstimatorContinuous(deepset)

# Train the estimator
q̂ = train(q̂, prior, simulate, m = m)

# Assess the estimator
θ = prior(1000)
Z = simulateZ(θ, m)
assessment = assess(q̂, θ, Z)
plot(assessment)

# Estimate 0.1-quantile for many data sets
τ = 0.1f0
q̂(Z, τ)

# Estimate several quantiles for a single data set
# (note that τ is given as a row vector)
z = Z[1]
τ = Float32.([0.1, 0.25, 0.5, 0.75, 0.9])&#39;
q̂(z, τ)

# -------------------------------------------------------------
# --------------------- Full conditionals ---------------------
# -------------------------------------------------------------

# Model: Z|μ,σ ~ N(μ, σ²) with μ ~ N(0, 1), σ ∼ IG(3,1)
d = 1         # dimension of each independent replicate
p = 2         # number of unknown parameters in the statistical model
m = 30        # number of independent replicates in each data set
function prior(K)
	μ = randn(1, K)
	σ = rand(InverseGamma(3, 1), 1, K)
	θ = vcat(μ, σ)
	θ = Float32.(θ)
	return θ
end
simulateZ(θ, m) = [ϑ[1] .+ ϑ[2] .* randn32(1, m) for ϑ ∈ eachcol(θ)]
simulateτ(θ)    = [rand32(10) for k in 1:size(θ, 2)]
simulate(θ, m)  = simulateZ(θ, m), simulateτ(θ)

# Architecture: partially monotonic network to preclude quantile crossing
w = 64  # width of each hidden layer
ψ = Chain(
	Dense(d, w, relu),
	Dense(w, w, relu),
	Dense(w, w, relu)
	)
ϕ = Chain(
	DensePositive(Dense(w + 2, w, relu); last_only = true),
	DensePositive(Dense(w, w, relu)),
	DensePositive(Dense(w, 1))
	)
deepset = DeepSet(ψ, ϕ)

# Initialise the estimator for the first parameter, targetting μ∣Z,σ
i = 1
q̂ = QuantileEstimatorContinuous(deepset; i = i)

# Train the estimator
q̂ = train(q̂, prior, simulate, m = m)

# Assess the estimator
θ = prior(1000)
Z = simulateZ(θ, m)
assessment = assess(q̂, θ, Z)
plot(assessment)

# Estimate quantiles of μ∣Z,σ with σ = 0.5 and for many data sets
# (use θ[Not(i), :] to determine the order in which the conditioned parameters should be given)
θ = prior(1000)
Z = simulateZ(θ, m)
θ₋ᵢ = 0.5f0
τ = Float32.([0.1, 0.25, 0.5, 0.75, 0.9])
q̂(Z, θ₋ᵢ, τ)

# Estimate quantiles for a single data set
q̂(Z[1], θ₋ᵢ, τ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L308-L462">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.RatioEstimator" href="#NeuralEstimators.RatioEstimator"><code>NeuralEstimators.RatioEstimator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RatioEstimator(deepset::DeepSet)</code></pre><p>A neural estimator that estimates the likelihood-to-evidence ratio,</p><p class="math-container">\[r(\boldsymbol{Z}, \boldsymbol{\theta}) \equiv p(\boldsymbol{Z} \mid \boldsymbol{\theta})/p(\boldsymbol{Z}),\]</p><p>where <span>$p(\boldsymbol{Z} \mid \boldsymbol{\theta})$</span> is the likelihood and <span>$p(\boldsymbol{Z})$</span> is the marginal likelihood, also known as the model evidence.</p><p>The estimator leverages the <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a> architecture, subject to two requirements. First, the number of input neurons in the first layer of the inference network (i.e., the outer network) must equal the number of output neurons in the final layer of the summary network plus the number of parameters in the statistical model. Second, the number of output neurons in the final layer of the inference network must be equal to one.</p><p>The ratio estimator is trained by solving a relatively straightforward binary classification problem. Specifically, consider the problem of distinguishing dependent parameter–data pairs <span>${(\boldsymbol{\theta}&#39;, \boldsymbol{Z}&#39;)&#39; \sim p(\boldsymbol{Z}, \boldsymbol{\theta})}$</span> with class labels <span>$Y=1$</span> from independent parameter–data pairs <span>${(\tilde{\boldsymbol{\theta}}&#39;, \tilde{\boldsymbol{Z}}&#39;)&#39; \sim p(\boldsymbol{\theta})p(\boldsymbol{Z})}$</span> with class labels <span>$Y=0$</span>, and where the classes are balanced. Then the Bayes classifier under binary cross-entropy loss is given by</p><p class="math-container">\[c(\boldsymbol{Z}, \boldsymbol{\theta}) = \frac{p(\boldsymbol{Z}, \boldsymbol{\theta})}{p(\boldsymbol{Z}, \boldsymbol{\theta}) + p(\boldsymbol{\theta})p(\boldsymbol{Z})},\]</p><p>and hence,</p><p class="math-container">\[r(\boldsymbol{Z}, \boldsymbol{\theta}) = \frac{c(\boldsymbol{Z}, \boldsymbol{\theta})}{1 - c(\boldsymbol{Z}, \boldsymbol{\theta})}.\]</p><p>For numerical stability, training is done on the log-scale using <span>$\log r(\boldsymbol{Z}, \boldsymbol{\theta}) = \text{logit}(c(\boldsymbol{Z}, \boldsymbol{\theta}))$</span>.</p><p>When applying the estimator to data, by default the likelihood-to-evidence ratio <span>$r(\boldsymbol{Z}, \boldsymbol{\theta})$</span> is returned (setting the keyword argument <code>classifier = true</code> will yield class probability estimates). The estimated ratio can then be used in various downstream Bayesian (e.g., <a href="https://proceedings.mlr.press/v119/hermans20a.html">Hermans et al., 2020</a>) or Frequentist (e.g., <a href="https://arxiv.org/abs/2305.04634">Walchessen et al., 2023</a>) inferential algorithms.</p><p>See also <a href="#NeuralEstimators.mlestimate"><code>mlestimate</code></a> and <a href="#NeuralEstimators.mapestimate"><code>mapestimate</code></a> for obtaining approximate maximum-likelihood and maximum-a-posteriori estimates, and <a href="#NeuralEstimators.sampleposterior"><code>sampleposterior</code></a> for obtaining approximate posterior samples.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux, Statistics, Optim

# Generate data from Z|μ,σ ~ N(μ, σ²) with μ, σ ~ U(0, 1)
p = 2     # number of unknown parameters in the statistical model
d = 1     # dimension of each independent replicate
m = 100   # number of independent replicates

prior(K) = rand32(p, K)
simulate(θ, m) = θ[1] .+ θ[2] .* randn32(d, m)
simulate(θ::AbstractMatrix, m) = simulate.(eachcol(θ), m)

# Architecture
w = 64 # width of each hidden layer
ψ = Chain(
	Dense(d, w, relu),
	Dense(w, w, relu),
	Dense(w, w, relu)
	)
ϕ = Chain(
	Dense(w + p, w, relu),
	Dense(w, w, relu),
	Dense(w, 1)
	)
deepset = DeepSet(ψ, ϕ)

# Initialise the estimator
r̂ = RatioEstimator(deepset)

# Train the estimator
r̂ = train(r̂, prior, simulate, m = m)

# Inference with &quot;observed&quot; data set
θ = prior(1)
z = simulate(θ, m)[1]
θ₀ = [0.5, 0.5]                           # initial estimate
mlestimate(r̂, z;  θ₀ = θ₀)                # maximum-likelihood estimate (requires Optim.jl to be loaded)
mapestimate(r̂, z; θ₀ = θ₀)                # maximum-a-posteriori estimate (requires Optim.jl to be loaded)
θ_grid = expandgrid(0:0.01:1, 0:0.01:1)&#39;  # fine gridding of the parameter space
θ_grid = Float32.(θ_grid)
r̂(z, θ_grid)                              # likelihood-to-evidence ratios over grid
mlestimate(r̂, z;  θ_grid = θ_grid)        # maximum-likelihood estimate
mapestimate(r̂, z; θ_grid = θ_grid)        # maximum-a-posteriori estimate
sampleposterior(r̂, z; θ_grid = θ_grid)    # posterior samples</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L531-L625">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PiecewiseEstimator" href="#NeuralEstimators.PiecewiseEstimator"><code>NeuralEstimators.PiecewiseEstimator</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PiecewiseEstimator(estimators, changepoints)</code></pre><p>Creates a piecewise estimator (<a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2023.2249522">Sainsbury-Dale et al., 2024</a>, sec. 2.2.2) from a collection of <code>estimators</code> and sample-size <code>changepoints</code>.</p><p>Specifically, with <span>$l$</span> estimators and sample-size changepoints <span>$m_1 &lt; m_2 &lt; \dots &lt; m_{l-1}$</span>, the piecewise etimator takes the form,</p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\boldsymbol{Z})
=
\begin{cases}
\hat{\boldsymbol{\theta}}_1(\boldsymbol{Z}) &amp; m \leq m_1,\\
\hat{\boldsymbol{\theta}}_2(\boldsymbol{Z}) &amp; m_1 &lt; m \leq m_2,\\
\quad \vdots \\
\hat{\boldsymbol{\theta}}_l(\boldsymbol{Z}) &amp; m &gt; m_{l-1}.
\end{cases}\]</p><p>For example, given an estimator  <span>$\hat{\boldsymbol{\theta}}_1(\cdot)$</span> trained for small sample sizes (e.g., m ≤ 30) and an estimator <span>$\hat{\boldsymbol{\theta}}_2(\cdot)$</span> trained for moderate-to-large sample sizes (e.g., m &gt; 30), we may construct a <code>PiecewiseEstimator</code> that dispatches <span>$\hat{\boldsymbol{\theta}}_1(\cdot)$</span> if m ≤ 30 and <span>$\hat{\boldsymbol{\theta}}_2(\cdot)$</span> otherwise.</p><p>See also <a href="#NeuralEstimators.trainx"><code>trainx()</code></a> for training estimators for a range of sample sizes.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

d = 2  # bivariate data
p = 3  # number of parameters in the statistical model
w = 8  # width of each hidden layer

# Small-sample estimator
ψ₁ = Chain(Dense(d, w, relu), Dense(w, w, relu));
ϕ₁ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂₁ = PointEstimator(DeepSet(ψ₁, ϕ₁))

# Large-sample estimator
ψ₂ = Chain(Dense(d, w, relu), Dense(w, w, relu));
ϕ₂ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂₂ = PointEstimator(DeepSet(ψ₂, ϕ₂))

# Piecewise estimator with changepoint m=30
θ̂ = PiecewiseEstimator([θ̂₁, θ̂₂], 30)

# Apply the (untrained) piecewise estimator to data
Z = [rand(d, 1, m) for m ∈ (10, 50)]
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L659-L712">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Ensemble" href="#NeuralEstimators.Ensemble"><code>NeuralEstimators.Ensemble</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Ensemble(estimators)
Ensemble(architecture::Function, J::Integer)
(ensemble::Ensemble)(Z; aggr = median)</code></pre><p>Defines an ensemble based on a collection of <code>estimators</code> which, when applied to data <code>Z</code>, returns the median (or another summary defined by <code>aggr</code>) of the estimates.</p><p>The ensemble can be initialised with a collection of trained <code>estimators</code> and then applied immediately to observed data. Alternatively, the ensemble can be initialised with a collection of untrained <code>estimators</code> (or a function defining the architecture of each estimator, and the number of estimators in the ensemble), trained with <code>train()</code>, and then applied to observed data. In the latter case, where the ensemble is trained directly, if <code>savepath</code> is specified both the ensemble and component estimators will be saved.</p><p>Note that <code>train()</code> currently acts sequentially on the component estimators.</p><p>The ensemble components can be accessed by indexing the ensemble directly; the number of component estimators can be obtained using <code>length()</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Define the model, Z|θ ~ N(θ, 1), θ ~ N(0, 1)
d = 1   # dimension of each replicate
p = 1   # number of unknown parameters in the statistical model
m = 30  # number of independent replicates in each data set
sampler(K) = randn32(p, K)
simulator(θ, m) = [μ .+ randn32(d, m) for μ ∈ eachcol(θ)]

# Architecture of each ensemble component
function architecture()
	ψ = Chain(Dense(d, 64, relu), Dense(64, 64, relu))
	ϕ = Chain(Dense(64, 64, relu), Dense(64, p))
	deepset = DeepSet(ψ, ϕ)
	PointEstimator(deepset)
end

# Initialise ensemble with three components
ensemble = Ensemble(architecture, 3)
ensemble[1]      # access component estimators by indexing
length(ensemble) # number of component estimators

# Training
ensemble = train(ensemble, sampler, simulator, m = m, epochs = 5)

# Assessment
θ = sampler(1000)
Z = simulator(θ, m)
assessment = assess(ensemble, θ, Z)
rmse(assessment)

# Apply to data
ensemble(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/Estimators.jl#L881-L938">source</a></section></article><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><p>The function <a href="#NeuralEstimators.train"><code>train</code></a> is used to train a single neural estimator, while the wrapper function <a href="#NeuralEstimators.trainx"><code>trainx</code></a> is useful for training multiple neural estimators over a range of sample sizes, making using of the technique known as pre-training.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.train" href="#NeuralEstimators.train"><code>NeuralEstimators.train</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">train(θ̂, sampler::Function, simulator::Function; ...)
train(θ̂, θ_train::P, θ_val::P, simulator::Function; ...) where {P &lt;: Union{AbstractMatrix, ParameterConfigurations}}
train(θ̂, θ_train::P, θ_val::P, Z_train::T, Z_val::T; ...) where {T, P &lt;: Union{AbstractMatrix, ParameterConfigurations}}</code></pre><p>Train a neural estimator <code>θ̂</code>.</p><p>The methods cater for different variants of &quot;on-the-fly&quot; simulation. Specifically, a <code>sampler</code> can be provided to continuously sample new parameter vectors from the prior, and a <code>simulator</code> can be provided to continuously simulate new data conditional on the parameters. If provided with specific sets of parameters (<code>θ_train</code> and <code>θ_val</code>) and/or data (<code>Z_train</code> and <code>Z_val</code>), they will be held fixed during training.</p><p>In all methods, the validation parameters and data are held fixed to reduce noise when evaluating the validation risk.</p><p><strong>Keyword arguments common to all methods:</strong></p><ul><li><code>loss = mae</code></li><li><code>epochs = 100</code></li><li><code>batchsize = 32</code></li><li><code>optimiser = ADAM()</code></li><li><code>savepath::String = &quot;&quot;</code>: path to save the trained estimator and other information; if an empty string (default), nothing is saved. Otherwise, the neural-network parameters (i.e., the weights and biases) will be saved during training as <code>bson</code> files; the risk function evaluated over the training and validation sets will also be saved, in the first and second columns of <code>loss_per_epoch.csv</code>, respectively; the best parameters (as measured by validation risk) will be saved as <code>best_network.bson</code>.</li><li><code>stopping_epochs = 5</code>: cease training if the risk doesn&#39;t improve in this number of epochs.</li><li><code>use_gpu = true</code></li><li><code>verbose = true</code></li></ul><p><strong>Keyword arguments common to <code>train(θ̂, sampler, simulator)</code> and <code>train(θ̂, θ_train, θ_val, simulator)</code>:</strong></p><ul><li><code>m</code>: sample sizes (either an <code>Integer</code> or a collection of <code>Integers</code>). The <code>simulator</code> is called as <code>simulator(θ, m)</code>.</li><li><code>epochs_per_Z_refresh = 1</code>: the number of passes to make through the training set before the training data are refreshed.</li><li><code>simulate_just_in_time = false</code>: flag indicating whether we should simulate just-in-time, in the sense that only a <code>batchsize</code> number of parameter vectors and corresponding data are in memory at a given time.</li></ul><p><strong>Keyword arguments unique to <code>train(θ̂, sampler, simulator)</code>:</strong></p><ul><li><code>K = 10000</code>: number of parameter vectors in the training set; the size of the validation set is <code>K ÷ 5</code>.</li><li><code>ξ = nothing</code>: an arbitrary collection of objects that, if provided, will be passed to the parameter sampler as <code>sampler(K, ξ)</code>; otherwise, the parameter sampler will be called as <code>sampler(K)</code>. Can also be provided as <code>xi</code>.</li><li><code>epochs_per_θ_refresh = 1</code>: the number of passes to make through the training set before the training parameters are refreshed. Must be a multiple of <code>epochs_per_Z_refresh</code>. Can also be provided as <code>epochs_per_theta_refresh</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

function sampler(K)
	μ = randn(K) # Gaussian prior
	σ = rand(K)  # Uniform prior
	θ = hcat(μ, σ)&#39;
	return θ
end

function simulator(θ_matrix, m)
	[θ[1] .+ θ[2] * randn(1, m) for θ ∈ eachcol(θ_matrix)]
end

# architecture
d = 1   # dimension of each replicate
p = 2   # number of parameters in the statistical model
ψ = Chain(Dense(1, 32, relu), Dense(32, 32, relu))
ϕ = Chain(Dense(32, 32, relu), Dense(32, p))
θ̂ = DeepSet(ψ, ϕ)

# number of independent replicates to use during training
m = 15

# training: full simulation on-the-fly
θ̂ = train(θ̂, sampler, simulator, m = m, epochs = 5)

# training: simulation on-the-fly with fixed parameters
K = 10000
θ_train = sampler(K)
θ_val   = sampler(K ÷ 5)
θ̂       = train(θ̂, θ_train, θ_val, simulator, m = m, epochs = 5)

# training: fixed parameters and fixed data
Z_train = simulator(θ_train, m)
Z_val   = simulator(θ_val, m)
θ̂       = train(θ̂, θ_train, θ_val, Z_train, Z_val, epochs = 5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/train.jl#L3-L78">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.trainx" href="#NeuralEstimators.trainx"><code>NeuralEstimators.trainx</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">trainx(θ̂, sampler::Function, simulator::Function, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, simulator::Function, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, Z_train, Z_val, m::Vector{Integer}; ...)
trainx(θ̂, θ_train, θ_val, Z_train::V, Z_val::V; ...) where {V &lt;: AbstractVector{AbstractVector{Any}}}</code></pre><p>A wrapper around <code>train()</code> to construct neural estimators for different sample sizes.</p><p>The positional argument <code>m</code> specifies the desired sample sizes. Each estimator is pre-trained with the estimator for the previous sample size. For example, if <code>m = [m₁, m₂]</code>, the estimator for sample size <code>m₂</code> is pre-trained with the estimator for sample size <code>m₁</code>.</p><p>The method for <code>Z_train</code> and <code>Z_val</code> subsets the data using <code>subsetdata(Z, 1:mᵢ)</code> for each <code>mᵢ ∈ m</code>. The method for <code>Z_train::V</code> and <code>Z_val::V</code> trains an estimator for each element of <code>Z_train::V</code> and <code>Z_val::V</code> and, hence, it does not need to invoke <code>subsetdata()</code>, which can be slow or difficult to define in some cases (e.g., for graphical data). Note that, in this case, <code>m</code> is inferred from the data.</p><p>The keyword arguments inherit from <code>train()</code>. The keyword arguments <code>epochs</code>, <code>batchsize</code>, <code>stopping_epochs</code>, and <code>optimiser</code> can each be given as vectors. For example, if training two estimators, one may use a different number of epochs for each estimator by providing <code>epochs = [epoch₁, epoch₂]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/train.jl#L659-L683">source</a></section></article><h2 id="Assessment/calibration"><a class="docs-heading-anchor" href="#Assessment/calibration">Assessment/calibration</a><a id="Assessment/calibration-1"></a><a class="docs-heading-anchor-permalink" href="#Assessment/calibration" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.assess" href="#NeuralEstimators.assess"><code>NeuralEstimators.assess</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">assess(estimator, θ, Z)</code></pre><p>Using an <code>estimator</code> (or a collection of estimators), computes estimates from data <code>Z</code> simulated based on true parameter vectors stored in <code>θ</code>.</p><p>The data <code>Z</code> should be a <code>Vector</code>, with each element corresponding to a single simulated data set. If <code>Z</code> contains more data sets than parameter vectors, the parameter matrix <code>θ</code> will be recycled by horizontal concatenation via the call <code>θ = repeat(θ, outer = (1, J))</code> where <code>J = length(Z) ÷ K</code> is the number of simulated data sets and <code>K = size(θ, 2)</code> is the number of parameter vectors.</p><p>The output is of type <code>Assessment</code>; see <code>?Assessment</code> for details.</p><p><strong>Keyword arguments</strong></p><ul><li><code>estimator_names::Vector{String}</code>: names of the estimators (sensible defaults provided).</li><li><code>parameter_names::Vector{String}</code>: names of the parameters (sensible defaults provided). If <code>ξ</code> is provided with a field <code>parameter_names</code>, those names will be used.</li><li><code>ξ = nothing</code>: an arbitrary collection of objects that are fixed (e.g., distance matrices). Can also be provided as <code>xi</code>.</li><li><code>use_ξ = false</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators. Specifies whether or not the estimator uses <code>ξ</code>: if it does, the estimator will be applied as <code>estimator(Z, ξ)</code>. This argument is useful when multiple <code>estimators</code> are provided, only some of which need <code>ξ</code>; hence, if only one estimator is provided and <code>ξ</code> is not <code>nothing</code>, <code>use_ξ</code> is automatically set to <code>true</code>. Can also be provided as <code>use_xi</code>.</li><li><code>use_gpu = true</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators.</li><li><code>probs = range(0.01, stop=0.99, length=100)</code>: (relevant only for <code>estimator::QuantileEstimatorContinuous</code>) a collection of probability levels in (0, 1)</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

n = 10 # number of observations in each realisation
p = 4  # number of parameters in the statistical model

# Construct the neural estimator
w = 32 # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂ = DeepSet(ψ, ϕ)

# Generate testing parameters
K = 100
θ = rand32(p, K)

# Data for a single sample size
m = 30
Z = [rand32(n, m) for _ ∈ 1:K];
assessment = assess(θ̂, θ, Z);
risk(assessment)

# Multiple data sets for each parameter vector
J = 5
Z = repeat(Z, J);
assessment = assess(θ̂, θ, Z);
risk(assessment)

# With set-level information
qₓ = 2
ϕ  = Chain(Dense(w + qₓ, w, relu), Dense(w, p));
θ̂ = DeepSet(ψ, ϕ)
x = [rand(qₓ) for _ ∈ eachindex(Z)]
assessment = assess(θ̂, θ, (Z, x));
risk(assessment)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L250-L309">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Assessment" href="#NeuralEstimators.Assessment"><code>NeuralEstimators.Assessment</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Assessment(df::DataFrame, runtime::DataFrame)</code></pre><p>A type for storing the output of <code>assess()</code>. The field <code>runtime</code> contains the total time taken for each estimator. The field <code>df</code> is a long-form <code>DataFrame</code> with columns:</p><ul><li><code>estimator</code>: the name of the estimator</li><li><code>parameter</code>: the name of the parameter</li><li><code>truth</code>:     the true value of the parameter</li><li><code>estimate</code>:  the estimated value of the parameter</li><li><code>m</code>:         the sample size (number of iid replicates) for the given data set</li><li><code>k</code>:         the index of the parameter vector</li><li><code>j</code>:         the index of the data set (in the case that multiple data sets are associated with each parameter vector)</li></ul><p>If <code>estimator</code> is an <code>IntervalEstimator</code>, the column <code>estimate</code> will be replaced by the columns <code>lower</code> and <code>upper</code>, containing the lower and upper bounds of the interval, respectively.</p><p>If <code>estimator</code> is a <code>QuantileEstimator</code>, the <code>df</code> will also contain a column <code>prob</code> indicating the probability level of the corresponding quantile estimate.</p><p>Multiple <code>Assessment</code> objects can be combined with <code>merge()</code> (used for combining assessments from multiple point estimators) or <code>join()</code> (used for combining assessments from a point estimator and an interval estimator).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.risk" href="#NeuralEstimators.risk"><code>NeuralEstimators.risk</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">risk(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s Bayes risk,</p><p class="math-container">\[r(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K L(\boldsymbol{\theta}^{(k)}, \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)})),\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>loss = (x, y) -&gt; abs(x - y)</code>: a binary operator defining the loss function (default absolute-error loss).</li><li><code>average_over_parameters::Bool = false</code>: if true, the loss is averaged over all parameters; otherwise (default), the loss is averaged over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the loss is averaged over all sample sizes <span>$m$</span>; otherwise, the loss is averaged over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L76-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bias" href="#NeuralEstimators.bias"><code>NeuralEstimators.bias</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bias(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s bias,</p><p class="math-container">\[{\rm{bias}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L114-L129">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.rmse" href="#NeuralEstimators.rmse"><code>NeuralEstimators.rmse</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">rmse(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s root-mean-squared error,</p><p class="math-container">\[{\rm{rmse}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\sqrt{\frac{1}{K} \sum_{k=1}^K (\hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)})^2},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L141-L156">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.coverage" href="#NeuralEstimators.coverage"><code>NeuralEstimators.coverage</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">coverage(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an interval estimator&#39;s expected coverage, as defined in <a href="https://arxiv.org/abs/2110.06581">Hermans et al. (2022, Definition 2.1)</a>, and the proportion of parameters below and above the lower and upper bounds, respectively.</p><p><strong>Keyword arguments</strong></p><ul><li><code>average_over_parameters::Bool = false</code>: if true, the coverage is averaged over all parameters; otherwise (default), it is computed over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the coverage is averaged over all sample sizes <span>$m$</span>; otherwise, it is computed over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/assess.jl#L169-L179">source</a></section></article><h2 id="Inference-with-observed-data"><a class="docs-heading-anchor" href="#Inference-with-observed-data">Inference with observed data</a><a id="Inference-with-observed-data-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-with-observed-data" title="Permalink"></a></h2><h3 id="Inference-using-point-estimators"><a class="docs-heading-anchor" href="#Inference-using-point-estimators">Inference using point estimators</a><a id="Inference-using-point-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-using-point-estimators" title="Permalink"></a></h3><p>Inference with a neural Bayes (point) estimator proceeds simply by applying the estimator <code>θ̂</code> to the observed data <code>Z</code> (possibly containing multiple data sets) in a call of the form <code>θ̂(Z)</code>. To leverage a GPU, simply move the estimator and the data to the GPU using <a href="https://fluxml.ai/Flux.jl/stable/models/functors/#Flux.gpu-Tuple{Any}"><code>gpu()</code></a>; see also <a href="../utility/#NeuralEstimators.estimateinbatches"><code>estimateinbatches()</code></a> to apply the estimator over batches of data, which can alleviate memory issues when working with a large number of data sets.</p><p>Uncertainty quantification often proceeds through the bootstrap distribution, which is essentially available &quot;for free&quot; when bootstrap data sets can be quickly generated; this is facilitated by <a href="#NeuralEstimators.bootstrap"><code>bootstrap()</code></a> and <a href="#NeuralEstimators.interval"><code>interval()</code></a>. Alternatively, one may approximate a set of low and high marginal posterior quantiles using a specially constructed neural Bayes estimator, which can then be used to construct credible intervals: see <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a>, <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a>, and <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>.  </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bootstrap" href="#NeuralEstimators.bootstrap"><code>NeuralEstimators.bootstrap</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bootstrap(θ̂, parameters::P, Z) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(θ̂, parameters::P, simulator, m::Integer; B = 400) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(θ̂, Z; B = 400, blocks = nothing)</code></pre><p>Generates <code>B</code> bootstrap estimates from an estimator <code>θ̂</code>.</p><p>Parametric bootstrapping is facilitated by passing a single parameter configuration, <code>parameters</code>, and corresponding simulated data, <code>Z</code>, whose length implicitly defines <code>B</code>. Alternatively, one may provide a <code>simulator</code> and the desired sample size, in which case the data will be simulated using <code>simulator(parameters, m)</code>.</p><p>Non-parametric bootstrapping is facilitated by passing a single data set, <code>Z</code>. The argument <code>blocks</code> caters for block bootstrapping, and it should be a vector of integers specifying the block for each replicate. For example, with 5 replicates, the first two corresponding to block 1 and the remaining three corresponding to block 2, <code>blocks</code> should be <code>[1, 1, 2, 2, 2]</code>. The resampling algorithm aims to produce resampled data sets that are of a similar size to <code>Z</code>, but this can only be achieved exactly if all blocks are equal in length.</p><p>The keyword argument <code>use_gpu</code> is a flag determining whether to use the GPU, if it is available (default <code>true</code>).</p><p>The return type is a p × <code>B</code> matrix, where p is the number of parameters in the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/inference.jl#L244-L269">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.interval" href="#NeuralEstimators.interval"><code>NeuralEstimators.interval</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">interval(θ::Matrix; probs = [0.05, 0.95], parameter_names = nothing)
interval(estimator::IntervalEstimator, Z; parameter_names = nothing, use_gpu = true)</code></pre><p>Compute a confidence interval based either on a <span>$p$</span> × <span>$B$</span> matrix <code>θ</code> of parameters (typically containing bootstrap estimates or posterior draws) with <span>$p$</span> the number of parameters in the model, or from an <code>IntervalEstimator</code> and data <code>Z</code>.</p><p>When given <code>θ</code>, the intervals are constructed by compute quantiles with probability levels controlled by the keyword argument <code>probs</code>.</p><p>The return type is a <span>$p$</span> × 2 matrix, whose first and second columns respectively contain the lower and upper bounds of the interval. The rows of this matrix can be named by passing a vector of strings to the keyword argument <code>parameter_names</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
p = 3
B = 50
θ = rand(p, B)
interval(θ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/inference.jl#L156-L180">source</a></section></article><h3 id="Inference-using-likelihood-and-likelihood-to-evidence-ratio-estimators"><a class="docs-heading-anchor" href="#Inference-using-likelihood-and-likelihood-to-evidence-ratio-estimators">Inference using likelihood and likelihood-to-evidence-ratio estimators</a><a id="Inference-using-likelihood-and-likelihood-to-evidence-ratio-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-using-likelihood-and-likelihood-to-evidence-ratio-estimators" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.mlestimate" href="#NeuralEstimators.mlestimate"><code>NeuralEstimators.mlestimate</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">mlestimate(estimator::RatioEstimator, Z; θ₀ = nothing, θ_grid = nothing, penalty::Function = θ -&gt; 1, use_gpu = true)</code></pre><p>Computes the (approximate) maximum likelihood estimate given data <span>$\boldsymbol{Z}$</span>,</p><p class="math-container">\[\argmax_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z})\]</p><p>where <span>$\ell(\cdot ; \cdot)$</span> denotes the approximate log-likelihood function derived from <code>estimator</code>.</p><p>If a vector <code>θ₀</code> of initial parameter estimates is given, the approximate likelihood is maximised by gradient descent (requires <code>Optim.jl</code> to be loaded). Otherwise, if a matrix of parameters <code>θ_grid</code> is given, the approximate likelihood is maximised by grid search.</p><p>A maximum penalised likelihood estimate,</p><p class="math-container">\[\argmax_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z}) + \log p(\boldsymbol{\theta}),\]</p><p>can be obtained by specifying the keyword argument <code>penalty</code> that defines the penalty term <span>$p(\boldsymbol{\theta})$</span>.</p><p>See also <a href="#NeuralEstimators.mapestimate"><code>mapestimate()</code></a> for computing (approximate) maximum a posteriori estimates.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/inference.jl#L62-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.mapestimate" href="#NeuralEstimators.mapestimate"><code>NeuralEstimators.mapestimate</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">mapestimate(estimator::RatioEstimator, Z; θ₀ = nothing, θ_grid = nothing, prior::Function = θ -&gt; 1, use_gpu = true)</code></pre><p>Computes the (approximate) maximum a posteriori estimate given data <span>$\boldsymbol{Z}$</span>,</p><p class="math-container">\[\argmax_{\boldsymbol{\theta}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z}) + \log p(\boldsymbol{\theta})\]</p><p>where <span>$\ell(\cdot ; \cdot)$</span> denotes the approximate log-likelihood function derived from <code>estimator</code>, and <span>$p(\boldsymbol{\theta})$</span> denotes the prior density function controlled through the keyword argument <code>prior</code> (by default, a uniform prior is used).</p><p>If a vector <code>θ₀</code> of initial parameter estimates is given, the approximate posterior density is maximised by gradient descent (requires <code>Optim.jl</code> to be loaded). Otherwise, if a matrix of parameters <code>θ_grid</code> is given, the approximate posterior density is maximised by grid search.</p><p>See also <a href="#NeuralEstimators.mlestimate"><code>mlestimate()</code></a> for computing (approximate) maximum likelihood estimates.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/inference.jl#L88-L104">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.sampleposterior" href="#NeuralEstimators.sampleposterior"><code>NeuralEstimators.sampleposterior</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sampleposterior(estimator::RatioEstimator, Z, N::Integer = 1000; θ_grid, prior::Function = θ -&gt; 1f0)</code></pre><p>Samples from the approximate posterior distribution <span>$p(\boldsymbol{\theta} \mid \boldsymbol{Z})$</span> implied by <code>estimator</code>.</p><p>The positional argument <code>N</code> controls the size of the posterior sample.</p><p>Currently, the sampling algorithm is based on a fine-gridding of the parameter space, specified through the keyword argument <code>θ_grid</code> (or <code>theta_grid</code>).  The approximate posterior density is evaluated over this grid, which is then used to draw samples. This is very effective when making inference with a small number of parameters. For models with a large number of parameters, other sampling algorithms may be needed (please feel free to contact the package maintainer for discussion).</p><p>The prior distribution <span>$p(\boldsymbol{\theta})$</span> is controlled through the keyword argument <code>prior</code> (by default, a uniform prior is used).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/f1f8769c9cb1e3ae97d09fa21daff4255f1c8c80/src/inference.jl#L7-L24">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../workflow/advancedusage/">« Advanced usage</a><a class="docs-footer-nextpage" href="../architectures/">Architectures »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 10 September 2024 23:36">Tuesday 10 September 2024</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
