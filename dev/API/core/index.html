<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Core ¬∑ NeuralEstimators.jl</title><meta name="title" content="Core ¬∑ NeuralEstimators.jl"/><meta property="og:title" content="Core ¬∑ NeuralEstimators.jl"/><meta property="twitter:title" content="Core ¬∑ NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../methodology/">Methodology</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Core</a><ul class="internal"><li><a class="tocitem" href="#Sampling-parameters"><span>Sampling parameters</span></a></li><li><a class="tocitem" href="#Simulating-data"><span>Simulating data</span></a></li><li><a class="tocitem" href="#Estimators"><span>Estimators</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#Assessment/calibration"><span>Assessment/calibration</span></a></li><li><a class="tocitem" href="#Inference-with-observed-data"><span>Inference with observed data</span></a></li></ul></li><li><a class="tocitem" href="../architectures/">Architectures</a></li><li><a class="tocitem" href="../approximatedistributions/">Approximate distributions</a></li><li><a class="tocitem" href="../loss/">Loss functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../utility/">Miscellaneous</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Core</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Core</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/core.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Core"><a class="docs-heading-anchor" href="#Core">Core</a><a id="Core-1"></a><a class="docs-heading-anchor-permalink" href="#Core" title="Permalink"></a></h1><p>This page documents the classes and functions that are central to the workflow of <code>NeuralEstimators</code>. Its organisation reflects the order in which these classes and functions appear in a standard implementation: from sampling parameters from the prior distribution, to making inference with observed data.</p><h2 id="Sampling-parameters"><a class="docs-heading-anchor" href="#Sampling-parameters">Sampling parameters</a><a id="Sampling-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-parameters" title="Permalink"></a></h2><p>Parameters sampled from the prior distribution are stored as a <span>$d \times K$</span> matrix, where <span>$d$</span> is the dimension of the parameter vector to make inference on and <span>$K$</span> is the number of sampled parameter vectors. </p><p>It can sometimes be helpful to wrap the parameter matrix in a user-defined type that also stores expensive intermediate objects needed for data simulated (e.g., Cholesky factors). The user-defined type should be a subtype of <a href="#NeuralEstimators.ParameterConfigurations"><code>ParameterConfigurations</code></a>, whose only requirement is a field <code>Œ∏</code> that stores the matrix of parameters. See <a href="../../workflow/advancedusage/#Storing-expensive-intermediate-objects-for-data-simulation">Storing expensive intermediate objects for data simulation</a> for further discussion.   </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.ParameterConfigurations" href="#NeuralEstimators.ParameterConfigurations"><code>NeuralEstimators.ParameterConfigurations</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ParameterConfigurations</code></pre><p>An abstract supertype for user-defined types that store parameters and any intermediate objects needed for data simulation.</p><p>The user-defined type must have a field <code>Œ∏</code> that stores the <span>$d$</span> √ó <span>$K$</span> matrix of parameters, where <span>$d$</span> is the dimension of the parameter vector to make  inference on and <span>$K$</span> is the number of sampled parameter vectors. There are no other requirements.</p><p>See <a href="../utility/#NeuralEstimators.subsetparameters"><code>subsetparameters()</code></a> for the generic function for subsetting these objects. </p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">struct P &lt;: ParameterConfigurations
	Œ∏
	# other expensive intermediate objects...
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Parameters.jl#L1-L22">source</a></section></article><h2 id="Simulating-data"><a class="docs-heading-anchor" href="#Simulating-data">Simulating data</a><a id="Simulating-data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-data" title="Permalink"></a></h2><p>The package accommodates any model for which simulation is feasible by allowing users to define their model implicitly through simulated data.</p><p>The data are stored as a <code>Vector{A}</code>, where each element of the vector is associated with one parameter vector, and the subtype <code>A</code> depends on the multivariate structure of the data. Common formats include:</p><ul><li><strong>Unstructured data</strong>: <code>A</code> is typically an <span>$n \times m$</span> matrix, where:<ul><li><span>$n$</span> is the dimension of each replicate (e.g., <span>$n=1$</span> for univariate data, <span>$n=2$</span> for bivariate data).  </li><li><span>$m$</span> is the number of independent replicates in each data set (<span>$m$</span> is allowed to vary between data sets). </li></ul></li><li><strong>Data collected over a regular grid</strong>: <code>A</code> is typically an (<span>$N + 2$</span>)-dimensional array, where: <ul><li>The first <span>$N$</span> dimensions correspond to the dimensions of the grid (e.g., <span>$N = 1$</span> for time series, <span>$N = 2$</span> for two-dimensional spatial grids). </li><li>The penultimate dimension stores the so-called &quot;channels&quot; (e.g., singleton for univariate processes, two for bivariate processes). </li><li>The final dimension stores the <span>$m$</span> independent replicates. </li></ul></li><li><strong>Spatial data collected over irregular locations</strong>: <code>A</code> is typically a <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/dev/api/gnngraph/#GraphNeuralNetworks.GNNGraphs.GNNGraph"><code>GNNGraph</code></a>, where independent replicates (possibly with differing spatial locations) are stored as subgraphs. See the helper function <a href="../utility/#NeuralEstimators.spatialgraph"><code>spatialgraph()</code></a> for constructing these graphs. </li></ul><p>While the formats above cover many applications, the package is flexible: the data structure simply needs to align with the chosen neural-network architecture. </p><h2 id="Estimators"><a class="docs-heading-anchor" href="#Estimators">Estimators</a><a id="Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Estimators" title="Permalink"></a></h2><p>The package provides several classes of neural estimators, organised within a type hierarchy. At the top-level of the hierarchy is <a href="#NeuralEstimators.NeuralEstimator"><code>NeuralEstimator</code></a>, an abstract supertype for all neural estimators in the package. </p><p>Neural Bayes estimators are implemented as subtypes of the abstract supertype <a href="#NeuralEstimators.BayesEstimator"><code>BayesEstimator</code></a>. The simple type <a href="#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a> is used for constructing neural Bayes estimators under general, user-defined loss functions. Several specialised types cater for the estimation of posterior quantiles based on the quantile loss function: see <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> and its generalisation <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a> for estimating posterior quantiles for a fixed set of probability levels; and see <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a> for estimating posterior quantiles based on a continuous probability level provided as input to the neural network.</p><p>The type <a href="#NeuralEstimators.PosteriorEstimator"><code>PosteriorEstimator</code></a> can be used to approximate the posterior distribution, and <a href="#NeuralEstimators.RatioEstimator"><code>RatioEstimator</code></a> can be used to approximate the likelihood-to-evidence ratio.</p><p>Several types serve as wrappers around the aforementioned estimators, enhancing their functionality. <a href="#NeuralEstimators.PiecewiseEstimator"><code>PiecewiseEstimator</code></a> applies different estimators based on the sample size of the data (see the discussion on <a href="../../workflow/advancedusage/#Variable-sample-sizes">Variable sample sizes</a>). <a href="#NeuralEstimators.Ensemble"><code>Ensemble</code></a> combines multiple estimators, aggregating their estimates to improve accuracy.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.NeuralEstimator" href="#NeuralEstimators.NeuralEstimator"><code>NeuralEstimators.NeuralEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NeuralEstimator</code></pre><p>An abstract supertype for all neural estimators in <code>NeuralEstimators.jl</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.BayesEstimator" href="#NeuralEstimators.BayesEstimator"><code>NeuralEstimators.BayesEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BayesEstimator &lt;: NeuralEstimator</code></pre><p>An abstract supertype for neural Bayes estimators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L8-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PointEstimator" href="#NeuralEstimators.PointEstimator"><code>NeuralEstimators.PointEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PointEstimator &lt;: BayesEstimator
PointEstimator(network)
(estimator::PointEstimator)(Z)</code></pre><p>A point estimator, where the neural <code>network</code> is a mapping from the sample space to the parameter space.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L15-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PosteriorEstimator" href="#NeuralEstimators.PosteriorEstimator"><code>NeuralEstimators.PosteriorEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PosteriorEstimator &lt;: NeuralEstimator
PosteriorEstimator(q::ApproximateDistribution, network)
sampleposterior(estimator::PosteriorEstimator, Z, N::Integer)
posteriormean(estimator::PosteriorEstimator, Z, N::Integer)</code></pre><p>A neural estimator that approximates the posterior distribution <span>$p(\boldsymbol{\theta} \mid \boldsymbol{Z})$</span>. </p><p>The neural <code>network</code> is a mapping from the sample space to a space that depends on the chosen approximate distribution <code>q</code> (see the available in-built <a href="../approximatedistributions/#Approximate-distributions">Approximate distributions</a>).  Often, the output space of the neural network is the space <span>$\mathcal{K}$</span> of approximate-distribution parameters <span>$\boldsymbol{\kappa}$</span>.   However, for certain approximate distributions (notably, <a href="../approximatedistributions/#NeuralEstimators.NormalisingFlow"><code>NormalisingFlow</code></a>), the neural network should output summary statistics of some suitable dimension (e.g., the dimension <span>$d$</span> of the parameter vector). </p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ U(0, 1) and œÉ ~ U(0, 1)
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 30    # number of independent replicates in each data set
sample(K) = rand32(d, K)
simulate(Œ∏, m) = [œë[1] .+ œë[2] .* randn32(n, m) for œë in eachcol(Œ∏)]

# Distribution used to approximate the posterior 
q = NormalisingFlow(d, d) 

# Neural network (outputs d summary statistics)
w = 128   
œà = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, d))
network = DeepSet(œà, œï)

## Alternatively, to use a Gaussian approximate distribution: 
# q = GaussianDistribution(d) 
# w = 128
# œà = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
# œï = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, numdistributionalparams(q)))
# network = DeepSet(œà, œï)

# Initialise the estimator
estimator = PosteriorEstimator(q, network)

# Train the estimator
estimator = train(estimator, sample, simulate, m = m)

# Inference with observed data 
Œ∏ = [0.8f0; 0.1f0]
Z = simulate(Œ∏, m)
sampleposterior(estimator, Z) # posterior draws 
posteriormean(estimator, Z)   # point estimate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L459-L509">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.RatioEstimator" href="#NeuralEstimators.RatioEstimator"><code>NeuralEstimators.RatioEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RatioEstimator &lt;: NeuralEstimator
RatioEstimator(network)
(estimator::RatioEstimator)(Z, Œ∏)
sampleposterior(estimator::RatioEstimator, Z, N::Integer)
posteriormean(estimator::RatioEstimator, Z, N::Integer)</code></pre><p>A neural estimator that estimates the likelihood-to-evidence ratio,</p><p class="math-container">\[r(\boldsymbol{Z}, \boldsymbol{\theta}) \equiv p(\boldsymbol{Z} \mid \boldsymbol{\theta})/p(\boldsymbol{Z}),\]</p><p>where <span>$p(\boldsymbol{Z} \mid \boldsymbol{\theta})$</span> is the likelihood and <span>$p(\boldsymbol{Z})$</span> is the marginal likelihood, also known as the model evidence.</p><p>For numerical stability, training is done on the log-scale using the relation  <span>$\log r(\boldsymbol{Z}, \boldsymbol{\theta}) = \text{logit}(c^*(\boldsymbol{Z}, \boldsymbol{\theta}))$</span>,  where <span>$c^*(\cdot, \cdot)$</span> denotes the Bayes classifier as described in the <a href="../../methodology/#Methodology">Methodology</a> section.  Hence, the neural <code>network</code> should be a mapping from <span>$\mathcal{Z} \times \Theta$</span> to <span>$\mathbb{R}$</span>, where <span>$\mathcal{Z}$</span> and <span>$\Theta$</span> denote the sample and parameter spaces, respectively. </p><p>When the neural network is a <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a>, two requirements must be met. First, the number of input neurons in the first layer of the outer network must equal <span>$d$</span> plus the number of output neurons in the final layer of the inner network.  Second, the number of output neurons in the final layer of the outer network must be one.</p><p>When applying the estimator to data <code>Z</code>, by default the likelihood-to-evidence ratio <span>$r(\boldsymbol{Z}, \boldsymbol{\theta})$</span> is returned (setting the keyword argument <code>classifier = true</code> will yield class probability estimates). The estimated ratio can then be used in various Bayesian (e.g., <a href="https://proceedings.mlr.press/v119/hermans20a.html">Hermans et al., 2020</a>) or frequentist (e.g., <a href="https://doi.org/10.1016/j.spasta.2024.100848">Walchessen et al., 2024</a>) inferential algorithms.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ U(0, 1) and œÉ ~ U(0, 1)
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 30    # number of independent replicates in each data set
sample(K) = rand32(d, K)
simulate(Œ∏, m) = [œë[1] .+ œë[2] .* randn32(n, m) for œë in eachcol(Œ∏)]

# Neural network
w = 128 
œà = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w + d, w, relu), Dense(w, w, relu), Dense(w, 1))
network = DeepSet(œà, œï)

# Initialise the estimator
rÃÇ = RatioEstimator(network)

# Train the estimator
rÃÇ = train(rÃÇ, sample, simulate, m = m)

# Inference with &quot;observed&quot; data (grid-based optimisation and sampling)
Œ∏ = sample(1)
z = simulate(Œ∏, m)[1]
Œ∏_grid = f32(expandgrid(0:0.01:1, 0:0.01:1))&#39;  # fine gridding of the parameter space
rÃÇ(z, Œ∏_grid)                                   # likelihood-to-evidence ratios over grid
mlestimate(rÃÇ, z; Œ∏_grid = Œ∏_grid)              # maximum-likelihood estimate
posteriormode(rÃÇ, z; Œ∏_grid = Œ∏_grid)           # posterior mode 
sampleposterior(rÃÇ, z; Œ∏_grid = Œ∏_grid)         # posterior samples

# Inference with &quot;observed&quot; data (gradient-based optimisation using Optim.jl)
using Optim
Œ∏‚ÇÄ = [0.5, 0.5]                                # initial estimate
mlestimate(rÃÇ, z; Œ∏‚ÇÄ = Œ∏‚ÇÄ)                      # maximum-likelihood estimate
posteriormode(rÃÇ, z; Œ∏‚ÇÄ = Œ∏‚ÇÄ)                   # posterior mode </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L520-L589">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.IntervalEstimator" href="#NeuralEstimators.IntervalEstimator"><code>NeuralEstimators.IntervalEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">IntervalEstimator &lt;: BayesEstimator
IntervalEstimator(u, v = u, c::Union{Function, Compress} = identity; probs = [0.025, 0.975], g = exp)
IntervalEstimator(u, c::Union{Function, Compress}; probs = [0.025, 0.975], g = exp)
(estimator::IntervalEstimator)(Z)</code></pre><p>A neural estimator that jointly estimates marginal posterior credible intervals based on the probability levels <code>probs</code> (by default, 95% central credible intervals).</p><p>The estimator employs a representation that prevents quantile crossing. Specifically, given data <span>$\boldsymbol{Z}$</span>,  it constructs intervals for each parameter <span>$\theta_i$</span>, <span>$i = 1, \dots, d,$</span>  of the form,</p><p class="math-container">\[[c_i(u_i(\boldsymbol{Z})), \;\; c_i(u_i(\boldsymbol{Z})) + g(v_i(\boldsymbol{Z})))],\]</p><p>where  <span>$\boldsymbol{u}(‚ãÖ) \equiv (u_1(\cdot), \dots, u_d(\cdot))&#39;$</span> and <span>$\boldsymbol{v}(‚ãÖ) \equiv (v_1(\cdot), \dots, v_d(\cdot))&#39;$</span> are neural networks that map from the sample space to <span>$\mathbb{R}^d$</span>; <span>$g(\cdot)$</span> is a monotonically increasing function (e.g., exponential or softplus); and each <span>$c_i(‚ãÖ)$</span> is a monotonically increasing function that maps its input to the prior support of <span>$\theta_i$</span>.</p><p>The functions <span>$c_i(‚ãÖ)$</span> may be collectively defined by a <span>$d$</span>-dimensional object of type <a href="../architectures/#NeuralEstimators.Compress"><code>Compress</code></a>. If these functions are unspecified, they will be set to the identity function so that the range of the intervals will be unrestricted.  If only a single neural-network architecture is provided, it will be used for both <span>$\boldsymbol{u}(‚ãÖ)$</span> and <span>$\boldsymbol{v}(‚ãÖ)$</span>.</p><p>The return value when applied to data using <a href="#NeuralEstimators.estimate"><code>estimate</code>()</a> is a matrix with <span>$2d$</span> rows, where the first and second <span>$d$</span> rows correspond to the lower and upper bounds, respectively. The function <a href="#NeuralEstimators.interval"><code>interval()</code></a> can be used to format this output in a readable <span>$d$</span> √ó 2 matrix.  </p><p>See also <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a> and <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ U(0, 1) and œÉ ~ U(0, 1)
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 100   # number of independent replicates
sample(K) = rand32(d, K)
simulate(Œ∏, m) = [œë[1] .+ œë[2] .* randn(n, m) for œë in eachcol(Œ∏)]

# Neural network
w = 128   # width of each hidden layer
œà = Chain(Dense(n, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w, w, relu), Dense(w, d))
u = DeepSet(œà, œï)

# Initialise the estimator
estimator = IntervalEstimator(u)

# Train the estimator
estimator = train(estimator, sample, simulate, m = m)

# Inference with &quot;observed&quot; data 
Œ∏ = [0.8f0; 0.1f0]
Z = simulate(Œ∏, m)
estimate(estimator, Z) 
interval(estimator, Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L27-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.QuantileEstimatorDiscrete" href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>NeuralEstimators.QuantileEstimatorDiscrete</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">QuantileEstimatorDiscrete &lt;: BayesEstimator
QuantileEstimatorDiscrete(v; probs = [0.025, 0.5, 0.975], g = Flux.softplus, i = nothing)
(estimator::QuantileEstimatorDiscrete)(Z)
(estimator::QuantileEstimatorDiscrete)(Z, Œ∏‚Çã·µ¢)</code></pre><p>A neural estimator that jointly estimates a fixed set of marginal posterior quantiles, with probability levels <span>$\{\tau_1, \dots, \tau_T\}$</span> controlled by the keyword argument <code>probs</code>. This generalises <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> to support an arbitrary number of probability levels. </p><p>Given data <span>$\boldsymbol{Z}$</span>, by default the estimator approximates quantiles of the distributions of </p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \quad i = 1, \dots, d, \]</p><p>for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_d)&#39;$</span>. Alternatively, if initialised with <code>i</code> set to a positive integer, the estimator approximates quantiles of the full conditional distribution of  </p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \boldsymbol{\theta}_{-i},\]</p><p>where <span>$\boldsymbol{\theta}_{-i}$</span> denotes the parameter vector with its <span>$i$</span>th element removed. </p><p>The estimator employs a representation that prevents quantile crossing, namely,</p><p class="math-container">\[\begin{aligned}
\boldsymbol{q}^{(\tau_1)}(\boldsymbol{Z}) &amp;= \boldsymbol{v}^{(\tau_1)}(\boldsymbol{Z}),\\
\boldsymbol{q}^{(\tau_t)}(\boldsymbol{Z}) &amp;= \boldsymbol{v}^{(\tau_1)}(\boldsymbol{Z}) + \sum_{j=2}^t g(\boldsymbol{v}^{(\tau_j)}(\boldsymbol{Z})), \quad t = 2, \dots, T,
\end{aligned}\]</p><p>where <span>$\boldsymbol{q}^{(\tau)}(\boldsymbol{Z})$</span> denotes the vector of <span>$\tau$</span>-quantiles  for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_d)&#39;$</span>;  <span>$\boldsymbol{v}^{(\tau_t)}(\cdot)$</span>, <span>$t = 1, \dots, T$</span>, are neural networks that map from the sample space to <span>$\mathbb{R}^d$</span>; and <span>$g(\cdot)$</span> is a monotonically increasing function (e.g., exponential or softplus) applied elementwise to its arguments. If <code>g = nothing</code>, the quantiles are estimated independently through the representation</p><p class="math-container">\[\boldsymbol{q}^{(\tau_t)}(\boldsymbol{Z}) = \boldsymbol{v}^{(\tau_t)}(\boldsymbol{Z}), \quad t = 1, \dots, T.\]</p><p>When the neural networks are <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a> objects, two requirements must be met.  First, the number of input neurons in the first layer of the outer network must equal the number of neurons in the final layer of the inner network plus <span>$\text{dim}(\boldsymbol{\theta}_{-i})$</span>, where we define  <span>$\text{dim}(\boldsymbol{\theta}_{-i}) \equiv 0$</span> when targetting marginal posteriors of the form <span>$\theta_i \mid \boldsymbol{Z}$</span> (the default behaviour).  Second, the number of output neurons in the final layer of the outer network must equal <span>$d - \text{dim}(\boldsymbol{\theta}_{-i})$</span>. </p><p>The return value is a matrix with <span>$\{d - \text{dim}(\boldsymbol{\theta}_{-i})\} \times T$</span> rows, where the first <span>$T$</span> rows correspond to the estimated quantiles for the first parameter, the second <span>$T$</span> rows corresponds to the estimated quantiles for the second parameter, and so on.</p><p>See also <a href="#NeuralEstimators.QuantileEstimatorContinuous"><code>QuantileEstimatorContinuous</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ U(0, 1) and œÉ ~ U(0, 1)
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 30    # number of independent replicates in each data set
sample(K) = rand32(d, K)
simulate(Œ∏, m) = [œë[1] .+ œë[2] .* randn32(n, m) for œë in eachcol(Œ∏)]

# ---- Quantiles of Œ∏·µ¢ ‚à£ ùêô, i = 1, ‚Ä¶, d ----

# Neural network
w = 64   # width of each hidden layer
œà = Chain(Dense(n, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w, w, relu), Dense(w, d))
v = DeepSet(œà, œï)

# Initialise the estimator
estimator = QuantileEstimatorDiscrete(v)

# Train the estimator
estimator = train(estimator, sample, simulate, m = m)

# Inference with &quot;observed&quot; data 
Œ∏ = [0.8f0; 0.1f0]
Z = simulate(Œ∏, m)
estimate(estimator, Z) 

# ---- Quantiles of Œ∏·µ¢ ‚à£ ùêô, Œ∏‚Çã·µ¢ ----

# Neural network
w = 64  # width of each hidden layer
œà = Chain(Dense(n, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w + 1, w, relu), Dense(w, d - 1))
v = DeepSet(œà, œï)

# Initialise estimators respectively targetting quantiles of Œº‚à£Z,œÉ and œÉ‚à£Z,Œº
q‚ÇÅ = QuantileEstimatorDiscrete(v; i = 1)
q‚ÇÇ = QuantileEstimatorDiscrete(v; i = 2)

# Train the estimators
q‚ÇÅ = train(q‚ÇÅ, sample, simulate, m = m)
q‚ÇÇ = train(q‚ÇÇ, sample, simulate, m = m)

# Estimate quantiles of Œº‚à£Z,œÉ with œÉ = 0.5 and for many data sets
Œ∏‚Çã·µ¢ = 0.5f0
q‚ÇÅ(Z, Œ∏‚Çã·µ¢)

# Estimate quantiles of Œº‚à£Z,œÉ with œÉ = 0.5 for a single data set
q‚ÇÅ(Z[1], Œ∏‚Çã·µ¢)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L110-L214">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.QuantileEstimatorContinuous" href="#NeuralEstimators.QuantileEstimatorContinuous"><code>NeuralEstimators.QuantileEstimatorContinuous</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">QuantileEstimatorContinuous &lt;: BayesEstimator
QuantileEstimatorContinuous(network; i = nothing, num_training_probs::Integer = 1)
(estimator::QuantileEstimatorContinuous)(Z, œÑ)
(estimator::QuantileEstimatorContinuous)(Z, Œ∏‚Çã·µ¢, œÑ)</code></pre><p>A neural estimator that estimates marginal posterior quantiles, with the probability level <code>œÑ</code> given as input to the neural network.</p><p>Given data <span>$\boldsymbol{Z}$</span> and the desired probability level  <span>$\tau ‚àà (0, 1)$</span>, by default the estimator approximates the <span>$\tau$</span>-quantile of the distributions of </p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \quad i = 1, \dots, d, \]</p><p>for parameters <span>$\boldsymbol{\theta} \equiv (\theta_1, \dots, \theta_d)&#39;$</span>. Alternatively, if initialised with <code>i</code> set to a positive integer, the estimator approximates the <span>$\tau$</span>-quantile of the full conditional distribution of </p><p class="math-container">\[\theta_i \mid \boldsymbol{Z}, \boldsymbol{\theta}_{-i},\]</p><p>where <span>$\boldsymbol{\theta}_{-i}$</span> denotes the parameter vector with its <span>$i$</span>th element removed. </p><p>Although not a requirement, one may employ a (partially) monotonic neural network to prevent quantile crossing (i.e., to ensure that the <span>$\tau_1$</span>-quantile does not exceed the <span>$\tau_2$</span>-quantile for any <span>$\tau_2 &gt; \tau_1$</span>). There are several ways to construct such a neural network: one simple yet effective approach is to ensure that all weights associated with <span>$\tau$</span> are strictly positive (see, e.g., <a href="https://link.springer.com/article/10.1007/s00477-018-1573-6">Cannon, 2018</a>), and this can be done using the <a href="../architectures/#NeuralEstimators.DensePositive"><code>DensePositive</code></a> layer as shown in the example below.</p><p>When the neural network is a <a href="../architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a>, two requirements must be met. First, the number of input neurons in the first layer of the outer network must equal the number of neurons in the final layer of the inner network plus <span>$1 + \text{dim}(\boldsymbol{\theta}_{-i})$</span>, where we define  <span>$\text{dim}(\boldsymbol{\theta}_{-i}) \equiv 0$</span> when targetting marginal posteriors of the form <span>$\theta_i \mid \boldsymbol{Z}$</span> (the default behaviour).  Second, the number of output neurons in the final layer of the outer network must equal <span>$d - \text{dim}(\boldsymbol{\theta}_{-i})$</span>. </p><p>The return value is a matrix with <span>$d - \text{dim}(\boldsymbol{\theta}_{-i})$</span> rows, corresponding to the estimated quantile for each parameter not in <span>$\boldsymbol{\theta}_{-i}$</span>.</p><p>See also <a href="#NeuralEstimators.QuantileEstimatorDiscrete"><code>QuantileEstimatorDiscrete</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ U(0, 1) and œÉ ~ U(0, 1)
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 30    # number of independent replicates in each data set
sample(K) = rand32(d, K)
simulateZ(Œ∏, m) = [œë[1] .+ œë[2] .* randn32(n, m) for œë in eachcol(Œ∏)]
simulateœÑ(K)    = [rand32(10) for k in 1:K]
simulate(Œ∏, m)  = simulateZ(Œ∏, m), simulateœÑ(size(Œ∏, 2))

# ---- Quantiles of Œ∏·µ¢ ‚à£ ùêô, i = 1, ‚Ä¶, d ----

# Neural network: partially monotonic network to preclude quantile crossing
w = 64  # width of each hidden layer
œà = Chain(
	Dense(n, w, relu),
	Dense(w, w, relu),
	Dense(w, w, relu)
	)
œï = Chain(
	DensePositive(Dense(w + 1, w, relu); last_only = true),
	DensePositive(Dense(w, w, relu)),
	DensePositive(Dense(w, d))
	)
network = DeepSet(œà, œï)

# Initialise the estimator
qÃÇ = QuantileEstimatorContinuous(network)

# Train the estimator
qÃÇ = train(qÃÇ, sample, simulate, m = m)

# Test data 
Œ∏ = sample(1000)
Z = simulateZ(Œ∏, m)

# Estimate 0.1-quantile for each parameter and for many data sets
œÑ = 0.1f0
qÃÇ(Z, œÑ)

# Estimate multiple quantiles for each parameter and for many data sets
# (note that œÑ is given as a row vector)
œÑ = f32([0.1, 0.25, 0.5, 0.75, 0.9])&#39;
qÃÇ(Z, œÑ)

# Estimate multiple quantiles for a single data set 
qÃÇ(Z[1], œÑ)

# ---- Quantiles of Œ∏·µ¢ ‚à£ ùêô, Œ∏‚Çã·µ¢ ----

# Neural network: partially monotonic network to preclude quantile crossing
w = 64  # width of each hidden layer
œà = Chain(
	Dense(n, w, relu),
	Dense(w, w, relu),
	Dense(w, w, relu)
	)
œï = Chain(
	DensePositive(Dense(w + 2, w, relu); last_only = true),
	DensePositive(Dense(w, w, relu)),
	DensePositive(Dense(w, d - 1))
	)
network = DeepSet(œà, œï)

# Initialise the estimator targetting Œº‚à£Z,œÉ
i = 1
qÃÇ·µ¢ = QuantileEstimatorContinuous(network; i = i)

# Train the estimator
qÃÇ·µ¢ = train(qÃÇ·µ¢, prior, simulate, m = m)

# Test data 
Œ∏ = sample(1000)
Z = simulateZ(Œ∏, m)

# Estimate quantiles of Œº‚à£Z,œÉ with œÉ = 0.5 and for many data sets
# (can use Œ∏[InvertedIndices.Not(i), :] to determine the order in which the conditioned parameters should be given)
Œ∏‚Çã·µ¢ = 0.5f0
œÑ = f32([0.1, 0.25, 0.5, 0.75, 0.9])
qÃÇ·µ¢(Z, Œ∏‚Çã·µ¢, œÑ)

# Estimate quantiles of Œº‚à£Z,œÉ with œÉ = 0.5 and for a single data set
qÃÇ·µ¢(Z[1], Œ∏‚Çã·µ¢, œÑ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L266-L393">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.PiecewiseEstimator" href="#NeuralEstimators.PiecewiseEstimator"><code>NeuralEstimators.PiecewiseEstimator</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PiecewiseEstimator &lt;: NeuralEstimator
PiecewiseEstimator(estimators, changepoints)</code></pre><p>Creates a piecewise estimator (<a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2023.2249522">Sainsbury-Dale et al., 2024</a>, Sec. 2.2.2) from a collection of <code>estimators</code> and sample-size <code>changepoints</code>.</p><p>Specifically, with <span>$l$</span> estimators and sample-size changepoints <span>$m_1 &lt; m_2 &lt; \dots &lt; m_{l-1}$</span>, the piecewise etimator takes the form,</p><p class="math-container">\[\hat{\boldsymbol{\theta}}(\boldsymbol{Z})
=
\begin{cases}
\hat{\boldsymbol{\theta}}_1(\boldsymbol{Z}) &amp; m \leq m_1,\\
\hat{\boldsymbol{\theta}}_2(\boldsymbol{Z}) &amp; m_1 &lt; m \leq m_2,\\
\quad \vdots \\
\hat{\boldsymbol{\theta}}_l(\boldsymbol{Z}) &amp; m &gt; m_{l-1}.
\end{cases}\]</p><p>For example, given an estimator <span>$\hat{\boldsymbol{\theta}}_1(\cdot)$</span> trained for small sample sizes (e.g., <span>$m \leq 30$</span>) and an estimator <span>$\hat{\boldsymbol{\theta}}_2(\cdot)$</span> trained for moderate-to-large sample sizes (e.g., <span>$m &gt; 30$</span>), one may construct a <code>PiecewiseEstimator</code> that dispatches <span>$\hat{\boldsymbol{\theta}}_1(\cdot)$</span> if <span>$m \leq 30$</span> and <span>$\hat{\boldsymbol{\theta}}_2(\cdot)$</span> otherwise.</p><p>See also <a href="#NeuralEstimators.trainx"><code>trainx()</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

n = 2    # bivariate data
d = 3    # dimension of parameter vector 
w = 128  # width of each hidden layer

# Small-sample estimator
œà‚ÇÅ = Chain(Dense(n, w, relu), Dense(w, w, relu));
œï‚ÇÅ = Chain(Dense(w, w, relu), Dense(w, d));
Œ∏ÃÇ‚ÇÅ = PointEstimator(DeepSet(œà‚ÇÅ, œï‚ÇÅ))

# Large-sample estimator
œà‚ÇÇ = Chain(Dense(n, w, relu), Dense(w, w, relu));
œï‚ÇÇ = Chain(Dense(w, w, relu), Dense(w, d));
Œ∏ÃÇ‚ÇÇ = PointEstimator(DeepSet(œà‚ÇÇ, œï‚ÇÇ))

# Piecewise estimator with changepoint m=30
Œ∏ÃÇ = PiecewiseEstimator([Œ∏ÃÇ‚ÇÅ, Œ∏ÃÇ‚ÇÇ], 30)

# Apply the (untrained) piecewise estimator to data
Z = [rand(n, m) for m ‚àà (10, 50)]
estimate(Œ∏ÃÇ, Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L620-L672">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Ensemble" href="#NeuralEstimators.Ensemble"><code>NeuralEstimators.Ensemble</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Ensemble &lt;: NeuralEstimator
Ensemble(estimators)
Ensemble(architecture::Function, J::Integer)
(ensemble::Ensemble)(Z; aggr = median)</code></pre><p>Defines an ensemble¬†based on a collection of <code>estimators</code> which, when applied to data <code>Z</code>, returns the median (or another summary defined by <code>aggr</code>) of the estimates.</p><p>The ensemble can be initialised with a collection of trained <code>estimators</code> and then applied immediately to observed data. Alternatively, the ensemble can be initialised with a collection of untrained <code>estimators</code> (or a function defining the architecture of each estimator, and the number of estimators in the ensemble), trained with <code>train()</code>, and then applied to observed data. In the latter case, where the ensemble is trained directly, if <code>savepath</code> is specified both the ensemble and component estimators will be saved.</p><p>Note that <code>train()</code> currently acts sequentially on the component estimators.</p><p>The ensemble components can be accessed by indexing the ensemble; the number of component estimators can be obtained using <code>length()</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œ∏ ~ N(Œ∏, 1) with Œ∏ ~ N(0, 1)
d = 1     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
m = 30    # number of independent replicates in each data set
sampler(K) = randn32(d, K)
simulator(Œ∏, m) = [Œº .+ randn32(n, m) for Œº ‚àà eachcol(Œ∏)]

# Neural-network architecture of each ensemble component
function architecture()
	œà = Chain(Dense(n, 64, relu), Dense(64, 64, relu))
	œï = Chain(Dense(64, 64, relu), Dense(64, d))
	network = DeepSet(œà, œï)
	PointEstimator(network)
end

# Initialise ensemble with three component estimators 
ensemble = Ensemble(architecture, 3)
ensemble[1]      # access component estimators by indexing
ensemble[1:2]    # indexing with an iterable collection returns the corresponding ensemble 
length(ensemble) # number of component estimators

# Training
ensemble = train(ensemble, sampler, simulator, m = m, epochs = 5)

# Assessment
Œ∏ = sampler(1000)
Z = simulator(Œ∏, m)
assessment = assess(ensemble, Œ∏, Z)
rmse(assessment)

# Apply to data
ensemble(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/Estimators.jl#L704-L762">source</a></section></article><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><p>The function <a href="#NeuralEstimators.train"><code>train</code></a> is used to train a single neural estimator, while the wrapper function <a href="#NeuralEstimators.trainx"><code>trainx</code></a> is useful for training multiple neural estimators over a range of sample sizes, making using of the technique known as pre-training.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.train" href="#NeuralEstimators.train"><code>NeuralEstimators.train</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">train(estimator, sampler::Function, simulator::Function; ...)
train(estimator, Œ∏_train::P, Œ∏_val::P, simulator::Function; ...) where {P &lt;: Union{AbstractMatrix, ParameterConfigurations}}
train(estimator, Œ∏_train::P, Œ∏_val::P, Z_train::T, Z_val::T; ...) where {T, P &lt;: Union{AbstractMatrix, ParameterConfigurations}}</code></pre><p>Trains a neural <code>estimator</code>.</p><p>The methods cater for different variants of &quot;on-the-fly&quot; simulation. Specifically, a <code>sampler</code> can be provided to continuously sample new parameter vectors from the prior, and a <code>simulator</code> can be provided to continuously simulate new data conditional on the parameters. If provided with specific sets of parameters (<code>Œ∏_train</code> and <code>Œ∏_val</code>) and/or data (<code>Z_train</code> and <code>Z_val</code>), they will be held fixed during training.</p><p>In all methods, the validation parameters and data are held fixed to reduce noise when evaluating the validation risk.</p><p>The estimator is returned on the CPU so that it can be saved post training. </p><p><strong>Keyword arguments common to all methods:</strong></p><ul><li><code>loss = mae</code> (applicable only to <a href="#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a>): loss function used to train the neural network. In addition to the standard loss functions provided by <code>Flux</code> (e.g., <code>mae</code>, <code>mse</code>), see <a href="../loss/#Loss-functions">Loss functions</a> for further options. </li><li><code>epochs = 100</code>: number of epochs to train the neural network. An epoch is one complete pass through the entire training data set when doing stochastic gradient descent.</li><li><code>batchsize = 32</code>: the batchsize to use when performing stochastic gradient descent, that is, the number of training samples processed between each update of the neural-network parameters.</li><li><code>optimiser = Flux.setup(Adam(), estimator)</code>: any Optimisers.jl optimisation rule for updating the neural-network parameters. When the training data and/or parameters are held fixed, one may wish to employ regularisation to prevent overfitting; for example, <code>optimiser = Flux.setup(OptimiserChain(WeightDecay(1e-4), Adam()), estimator)</code>, which corresponds to L‚ÇÇ regularisation with penalty coefficient Œª=10‚Åª‚Å¥. </li><li><code>savepath::Union{String, Nothing} = nothing</code>: path to save the trained estimator and other information; if <code>nothing</code> (default), nothing is saved. Otherwise, the neural-network parameters (i.e., the weights and biases) will be saved during training as <code>bson</code> files; the risk function evaluated over the training and validation sets will also be saved, in the first and second columns of <code>loss_per_epoch.csv</code>, respectively; the best parameters (as measured by validation risk) will be saved as <code>best_network.bson</code>.</li><li><code>stopping_epochs = 5</code>: cease training if the risk doesn&#39;t improve in this number of epochs.</li><li><code>use_gpu = true</code>: flag indicating whether to use a GPU if one is available.</li><li><code>verbose = true</code>: flag indicating whether information, including empirical risk values and timings, should be printed to the console during training.</li></ul><p><strong>Keyword arguments common to <code>train(estimator, sampler, simulator)</code> and <code>train(estimator, Œ∏_train, Œ∏_val, simulator)</code>:</strong></p><ul><li><code>m = nothing</code>: arguments to the simulator (typically the number of replicates in each data set as an <code>Integer</code> or an <code>Integer</code> collection). The <code>simulator</code> is called as <code>simulator(Œ∏, m)</code> if <code>m</code> is given and as <code>simulator(Œ∏)</code> otherwise. </li><li><code>epochs_per_Z_refresh = 1</code>: the number of passes to make through the training set before the training data are refreshed.</li><li><code>simulate_just_in_time = false</code>: flag indicating whether we should simulate just-in-time, in the sense that only a <code>batchsize</code> number of parameter vectors and corresponding data are in memory at a given time.</li></ul><p><strong>Keyword arguments unique to <code>train(estimator, sampler, simulator)</code>:</strong></p><ul><li><code>K = 10000</code>: number of parameter vectors in the training set.</li><li><code>K_val = K √∑ 5</code> number of parameter vectors in the validation set.</li><li><code>Œæ = nothing</code>: an arbitrary collection of objects that, if provided, will be passed to the parameter sampler as <code>sampler(K, Œæ)</code>; otherwise, the parameter sampler will be called as <code>sampler(K)</code>. Can also be provided as <code>xi</code>.</li><li><code>epochs_per_Œ∏_refresh = 1</code>: the number of passes to make through the training set before the training parameters are refreshed. Must be a multiple of <code>epochs_per_Z_refresh</code>. Can also be provided as <code>epochs_per_theta_refresh</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators, Flux

# Data Z|Œº,œÉ ~ N(Œº, œÉ¬≤) with priors Œº ~ N(0, 1) and œÉ ~ U(0, 1)
function sampler(K)
	Œº = randn(K) # Gaussian prior
	œÉ = rand(K)  # Uniform prior
	Œ∏ = vcat(Œº&#39;, œÉ&#39;)
	return Œ∏
end
function simulator(Œ∏, m)
	[œë[1] .+ œë[2] * randn(1, m) for œë ‚àà eachcol(Œ∏)]
end

# Neural network 
d = 2     # dimension of the parameter vector Œ∏
n = 1     # dimension of each independent replicate of Z
w = 128   # width of each hidden layer 
œà = Chain(Dense(n, w, relu), Dense(w, w, relu))
œï = Chain(Dense(w, w, relu), Dense(w, d))
network = DeepSet(œà, œï)

# Initialise the estimator
estimator = PointEstimator(network)

# Number of independent replicates to use during training
m = 15

# Training: simulation on-the-fly
estimator  = train(estimator, sampler, simulator, m = m, epochs = 5)

# Training: simulation on-the-fly with fixed parameters
K = 10000
Œ∏_train = sampler(K)
Œ∏_val   = sampler(K)
estimator = train(estimator, Œ∏_train, Œ∏_val, simulator, m = m, epochs = 5)

# Training: fixed parameters and fixed data
Z_train   = simulator(Œ∏_train, m)
Z_val     = simulator(Œ∏_val, m)
estimator = train(estimator, Œ∏_train, Œ∏_val, Z_train, Z_val, epochs = 5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/train.jl#L1-L82">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.trainx" href="#NeuralEstimators.trainx"><code>NeuralEstimators.trainx</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">trainx(estimator, sampler::Function, simulator::Function, m::Vector{Integer}; ...)
trainx(estimator, Œ∏_train, Œ∏_val, simulator::Function, m::Vector{Integer}; ...)
trainx(estimator, Œ∏_train, Œ∏_val, Z_train, Z_val, m::Vector{Integer}; ...)
trainx(estimator, Œ∏_train, Œ∏_val, Z_train::V, Z_val::V; ...) where {V &lt;: AbstractVector{AbstractVector{Any}}}</code></pre><p>A wrapper around <code>train()</code> to construct neural estimators for different sample sizes.</p><p>The positional argument <code>m</code> specifies the desired sample sizes. Each estimator is pre-trained with the estimator for the previous sample size (see <a href="https://www.tandfonline.com/doi/full/10.1080/00031305.2023.2249522">Sainsbury-Dale at al., 2024</a>, Sec 2.3.3). For example, if <code>m = [m‚ÇÅ, m‚ÇÇ]</code>, the estimator for sample size <code>m‚ÇÇ</code> is pre-trained with the estimator for sample size <code>m‚ÇÅ</code>.</p><p>The method for <code>Z_train</code> and <code>Z_val</code> subsets the data using <code>subsetdata(Z, 1:m·µ¢)</code> for each <code>m·µ¢ ‚àà m</code>. The method for <code>Z_train::V</code> and <code>Z_val::V</code> trains an estimator for each element of <code>Z_train::V</code> and <code>Z_val::V</code> and, hence, it does not need to invoke <code>subsetdata()</code>, which can be slow or difficult to define in some cases (e.g., for graphical data). Note that, in this case, <code>m</code> is inferred from the data.</p><p>The keyword arguments inherit from <code>train()</code>. The keyword arguments <code>epochs</code>, <code>batchsize</code>, <code>stopping_epochs</code>, and <code>optimiser</code> can each be given as vectors. For example, if training two estimators, one may use a different number of epochs for each estimator by providing <code>epochs = [epoch‚ÇÅ, epoch‚ÇÇ]</code>.</p><p>See also <a href="#NeuralEstimators.PiecewiseEstimator">PiecewiseEstimator</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/train.jl#L673-L697">source</a></section></article><h2 id="Assessment/calibration"><a class="docs-heading-anchor" href="#Assessment/calibration">Assessment/calibration</a><a id="Assessment/calibration-1"></a><a class="docs-heading-anchor-permalink" href="#Assessment/calibration" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.assess" href="#NeuralEstimators.assess"><code>NeuralEstimators.assess</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">assess(estimator, Œ∏, Z)</code></pre><p>Using an <code>estimator</code> (or a collection of estimators), computes estimates from data <code>Z</code> simulated based on true parameter vectors stored in <code>Œ∏</code>.</p><p>The data <code>Z</code> should be a <code>Vector</code>, with each element corresponding to a single simulated data set. If <code>Z</code> contains more data sets than parameter vectors, the parameter matrix <code>Œ∏</code> will be recycled by horizontal concatenation via the call <code>Œ∏ = repeat(Œ∏, outer = (1, J))</code> where <code>J = length(Z) √∑ K</code> is the number of simulated data sets and <code>K = size(Œ∏, 2)</code> is the number of parameter vectors.</p><p>The return value is of type <a href="#NeuralEstimators.Assessment"><code>Assessment</code></a>. </p><p><strong>Keyword arguments</strong></p><ul><li><code>estimator_names::Vector{String}</code>: names of the estimators (sensible defaults provided).</li><li><code>parameter_names::Vector{String}</code>: names of the parameters (sensible defaults provided). If <code>Œæ</code> is provided with a field <code>parameter_names</code>, those names will be used.</li><li><code>Œæ = nothing</code>: an arbitrary collection of objects that are fixed (e.g., distance matrices). Can also be provided as <code>xi</code>.</li><li><code>use_Œæ = false</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators. Specifies whether or not the estimator uses <code>Œæ</code>: if it does, the estimator will be applied as <code>estimator(Z, Œæ)</code>. This argument is useful when multiple <code>estimators</code> are provided, only some of which need <code>Œæ</code>; hence, if only one estimator is provided and <code>Œæ</code> is not <code>nothing</code>, <code>use_Œæ</code> is automatically set to <code>true</code>. Can also be provided as <code>use_xi</code>.</li><li><code>use_gpu = true</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators.</li><li><code>probs = range(0.01, stop=0.99, length=100)</code>: (relevant only for <code>estimator::QuantileEstimatorContinuous</code>) a collection of probability levels in (0, 1).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L247-L268">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.Assessment" href="#NeuralEstimators.Assessment"><code>NeuralEstimators.Assessment</code></a> ‚Äî <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Assessment(df::DataFrame, runtime::DataFrame)</code></pre><p>A type for storing the output of <code>assess()</code>. The field <code>runtime</code> contains the total time taken for each estimator. The field <code>df</code> is a long-form <code>DataFrame</code> with columns:</p><ul><li><code>estimator</code>: the name of the estimator</li><li><code>parameter</code>: the name of the parameter</li><li><code>truth</code>:     the true value of the parameter</li><li><code>estimate</code>:  the estimated value of the parameter</li><li><code>m</code>:         the sample size (number of iid replicates) for the given data set</li><li><code>k</code>:         the index of the parameter vector</li><li><code>j</code>:         the index of the data set (in the case that multiple data sets are associated with each parameter vector)</li></ul><p>If <code>estimator</code> is an <code>IntervalEstimator</code>, the column <code>estimate</code> will be replaced by the columns <code>lower</code> and <code>upper</code>, containing the lower and upper bounds of the interval, respectively.</p><p>If <code>estimator</code> is a <code>QuantileEstimator</code>, the <code>df</code> will also contain a column <code>prob</code> indicating the probability level of the corresponding quantile estimate.</p><p>Use <code>merge()</code> to combine assessments from multiple estimators of the same type or <code>join()</code> to combine assessments from a <a href="#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a> and an <a href="#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.risk" href="#NeuralEstimators.risk"><code>NeuralEstimators.risk</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">risk(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s Bayes risk,</p><p class="math-container">\[r(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K L(\boldsymbol{\theta}^{(k)}, \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)})),\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>loss = (x, y) -&gt; abs(x - y)</code>: a binary operator defining the loss function (default absolute-error loss).</li><li><code>average_over_parameters::Bool = false</code>: if true, the loss is averaged over all parameters; otherwise (default), the loss is averaged over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the loss is averaged over all sample sizes <span>$m$</span>; otherwise, the loss is averaged over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L74-L92">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bias" href="#NeuralEstimators.bias"><code>NeuralEstimators.bias</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bias(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s bias,</p><p class="math-container">\[{\textrm{bias}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\frac{1}{K} \sum_{k=1}^K \hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L112-L127">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.rmse" href="#NeuralEstimators.rmse"><code>NeuralEstimators.rmse</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">rmse(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an estimator&#39;s root-mean-squared error,</p><p class="math-container">\[{\textrm{rmse}}(\hat{\boldsymbol{\theta}}(\cdot))
\approx
\sqrt{\frac{1}{K} \sum_{k=1}^K (\hat{\boldsymbol{\theta}}(\boldsymbol{Z}^{(k)}) - \boldsymbol{\theta}^{(k)})^2},\]</p><p>where <span>$\{\boldsymbol{\theta}^{(k)} : k = 1, \dots, K\}$</span> denotes a set of <span>$K$</span> parameter vectors sampled from the prior and, for each <span>$k$</span>, data <span>$\boldsymbol{Z}^{(k)}$</span> are simulated from the statistical model conditional on <span>$\boldsymbol{\theta}^{(k)}$</span>.</p><p>This function inherits the keyword arguments of <a href="#NeuralEstimators.risk"><code>risk</code></a> (excluding the argument <code>loss</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L139-L154">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.coverage" href="#NeuralEstimators.coverage"><code>NeuralEstimators.coverage</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">coverage(assessment::Assessment; ...)</code></pre><p>Computes a Monte Carlo approximation of an interval estimator&#39;s expected coverage, as defined in <a href="https://arxiv.org/abs/2110.06581">Hermans et al. (2022, Definition 2.1)</a>, and the proportion of parameters below and above the lower and upper bounds, respectively.</p><p><strong>Keyword arguments</strong></p><ul><li><code>average_over_parameters::Bool = false</code>: if true, the coverage is averaged over all parameters; otherwise (default), it is computed over each parameter separately.</li><li><code>average_over_sample_sizes::Bool = true</code>: if true (default), the coverage is averaged over all sample sizes <span>$m$</span>; otherwise, it is computed over each sample size separately.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/assess.jl#L167-L177">source</a></section></article><h2 id="Inference-with-observed-data"><a class="docs-heading-anchor" href="#Inference-with-observed-data">Inference with observed data</a><a id="Inference-with-observed-data-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-with-observed-data" title="Permalink"></a></h2><p>The following functions are intended to facilitate the use of a trained neural estimator with observed data. </p><p>Note that most <a href="../../#NeuralEstimators"><code>NeuralEstimators</code></a> are callable and can be applied to data <code>Z</code> (possibly containing multiple data sets) in a call of the form <code>estimator(Z)</code> or similar. In these cases, one may leverage a GPU by simply moving the estimator and the data to the GPU using <a href="https://fluxml.ai/Flux.jl/stable/models/functors/#Flux.gpu-Tuple{Any}"><code>gpu()</code></a>. See also <a href="#NeuralEstimators.estimate"><code>estimate()</code></a> to apply the estimator over batches of data, which can alleviate memory issues when working with large data sets (the methods below typically use this memory-safe approach where possible). </p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.estimate" href="#NeuralEstimators.estimate"><code>NeuralEstimators.estimate</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">estimate(estimator, Z, T = nothing; batchsize::Integer = 32, use_gpu::Bool = true, kwargs...)</code></pre><p>Applies <code>estimator</code> to batches of <code>Z</code> (and optionally other set-level information <code>T</code>) of size <code>batchsize</code>.</p><p>This can prevent memory issues that can occur with large data sets, particularly on the GPU.</p><p>Batching will only be done if there are multiple data sets in <code>Z</code>, which will be inferred by <code>Z</code> being a vector, or a tuple whose first element is a vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.bootstrap" href="#NeuralEstimators.bootstrap"><code>NeuralEstimators.bootstrap</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bootstrap(estimator::PointEstimator, parameters::P, Z; use_gpu = true) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(estimator::PointEstimator, parameters::P, simulator, m::Integer; B = 400, use_gpu = true) where P &lt;: Union{AbstractMatrix, ParameterConfigurations}
bootstrap(estimator::PointEstimator, Z; B = 400, blocks = nothing, trim = true, use_gpu = true)</code></pre><p>Generates <code>B</code> bootstrap estimates using <code>estimator</code>.</p><p>Parametric bootstrapping is facilitated by passing a single parameter configuration, <code>parameters</code>, and corresponding simulated data, <code>Z</code>, whose length implicitly defines <code>B</code>. Alternatively, one may provide a <code>simulator</code> and the desired sample size, in which case the data will be simulated using <code>simulator(parameters, m)</code>.</p><p>Non-parametric bootstrapping is facilitated by passing a single data set, <code>Z</code>. The argument <code>blocks</code> caters for block bootstrapping, and it should be a vector of integers specifying the block for each replicate. For example, with 5 replicates, the first two corresponding to block 1 and the remaining three corresponding to block 2, <code>blocks</code> should be <code>[1, 1, 2, 2, 2]</code>. The resampling algorithm generates resampled data sets by sampling blocks with replacement. If <code>trim = true</code>, the final block is trimmed as needed to ensure that the resampled data set matches the original size of <code>Z</code>. </p><p>The return type is a <span>$d$</span> √ó <code>B</code> matrix, where <span>$d$</span> is the dimension of the parameter vector. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L312-L331">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.interval" href="#NeuralEstimators.interval"><code>NeuralEstimators.interval</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">interval(Œ∏::Matrix; probs = [0.05, 0.95], parameter_names = nothing)
interval(estimator::IntervalEstimator, Z; parameter_names = nothing, use_gpu = true)</code></pre><p>Computes a confidence/credible interval based either on a <span>$d$</span> √ó <span>$B$</span> matrix <code>Œ∏</code> of parameters (typically containing bootstrap estimates or posterior draws), where <span>$d$</span> denotes the number of parameters to make inference on, or from an <code>IntervalEstimator</code> and data <code>Z</code>.</p><p>When given <code>Œ∏</code>, the intervals are constructed by computing quantiles with probability levels controlled by the keyword argument <code>probs</code>.</p><p>The return type is a <span>$d$</span> √ó 2 matrix, whose first and second columns respectively contain the lower and upper bounds of the interval. The rows of this matrix can be named by passing a vector of strings to the keyword argument <code>parameter_names</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L234-L248">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.sampleposterior" href="#NeuralEstimators.sampleposterior"><code>NeuralEstimators.sampleposterior</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sampleposterior(estimator::PosteriorEstimator, Z, N::Integer = 1000)
sampleposterior(estimator::RatioEstimator, Z, N::Integer = 1000; Œ∏_grid, prior::Function = Œ∏ -&gt; 1f0)</code></pre><p>Samples from the approximate posterior distribution implied by <code>estimator</code>.</p><p>The positional argument <code>N</code> controls the size of the posterior sample.</p><p>When sampling based on a <code>RatioEstimator</code>, the sampling algorithm is based on a fine-gridding of the parameter space, specified through the keyword argument <code>Œ∏_grid</code> (or <code>theta_grid</code>).  The approximate posterior density is evaluated over this grid, which is then used to draw samples. This is very effective when making inference with a small number of parameters. For models with a large number of parameters, other sampling algorithms may be needed (please feel free to contact the package maintainer for discussion). The prior distribution <span>$p(\boldsymbol{\theta})$</span> is controlled through the keyword argument <code>prior</code> (by default, a uniform prior is used).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L98-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.posteriormean" href="#NeuralEstimators.posteriormean"><code>NeuralEstimators.posteriormean</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posteriormean(Œ∏::AbstractMatrix)	
posteriormean(estimator::Union{PosteriorEstimator, RatioEstimator}, Z, N::Integer = 1000; kwargs...)</code></pre><p>Computes the posterior mean based either on a <span>$d$</span> √ó <span>$N$</span> matrix <code>Œ∏</code> of posterior draws, where <span>$d$</span> denotes the number of parameters to make inference on, or directly from an estimator that allows for posterior sampling via <a href="#NeuralEstimators.sampleposterior"><code>sampleposterior()</code></a>.</p><p>See also <a href="#NeuralEstimators.posteriormedian"><code>posteriormedian()</code></a>, <a href="#NeuralEstimators.posteriormode"><code>posteriormode()</code></a>, and <a href="#NeuralEstimators.mlestimate"><code>mlestimate()</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L59-L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.posteriormedian" href="#NeuralEstimators.posteriormedian"><code>NeuralEstimators.posteriormedian</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posteriormedian(Œ∏::AbstractMatrix)	
posteriormedian(estimator::Union{PosteriorEstimator, RatioEstimator}, Z, N::Integer = 1000; kwargs...)</code></pre><p>Computes the vector of marginal posterior medians based either on a <span>$d$</span> √ó <span>$N$</span> matrix <code>Œ∏</code> of posterior draws, where <span>$d$</span> denotes the number of parameters to make inference on, or directly from an estimator that allows for posterior sampling via <a href="#NeuralEstimators.sampleposterior"><code>sampleposterior()</code></a>.</p><p>See also <a href="#NeuralEstimators.posteriormean"><code>posteriormean()</code></a>, <a href="#NeuralEstimators.posteriorquantile"><code>posteriorquantile()</code></a>, and <a href="#NeuralEstimators.mlestimate"><code>mlestimate()</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L69-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.posteriorquantile" href="#NeuralEstimators.posteriorquantile"><code>NeuralEstimators.posteriorquantile</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posteriorquantile(Œ∏::AbstractMatrix, probs)	
posteriormedian(estimator::Union{PosteriorEstimator, RatioEstimator}, Z, probs, N::Integer = 1000; kwargs...)</code></pre><p>Computes the vector of marginal posterior quantiles with (a collection of) probability levels <code>probs</code>, based either on a <span>$d$</span> √ó <span>$N$</span> matrix <code>Œ∏</code> of posterior draws, where <span>$d$</span> denotes the number of parameters to make inference on, or directly from an estimator that allows for posterior sampling via <a href="#NeuralEstimators.sampleposterior"><code>sampleposterior()</code></a>.</p><p>The return value is a <span>$d$</span> √ó <code>length(probs)</code> matrix. </p><p>See also <a href="#NeuralEstimators.posteriormedian"><code>posteriormedian()</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L79-L87">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.posteriormode" href="#NeuralEstimators.posteriormode"><code>NeuralEstimators.posteriormode</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">posteriormode(estimator::RatioEstimator, Z; Œ∏‚ÇÄ = nothing, Œ∏_grid = nothing, prior::Function = Œ∏ -&gt; 1, use_gpu = true)</code></pre><p>Computes the (approximate) posterior mode (maximum a posteriori estimate) given data <span>$\boldsymbol{Z}$</span>,</p><p class="math-container">\[\underset{\boldsymbol{\theta}}{\mathrm{arg\,max\;}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z}) + \log p(\boldsymbol{\theta}),\]</p><p>where <span>$\ell(\cdot ; \cdot)$</span> denotes the approximate log-likelihood function implied by <code>estimator</code>, and <span>$p(\boldsymbol{\theta})$</span> denotes the prior density function controlled through the keyword argument <code>prior</code>.</p><p>If a vector <code>Œ∏‚ÇÄ</code> of initial parameter estimates is given, the approximate posterior density is maximised by gradient descent (requires <code>Optim.jl</code> to be loaded). Otherwise, if a matrix of parameters <code>Œ∏_grid</code> is given, the approximate posterior density is maximised by grid search.</p><p>See also <a href="#NeuralEstimators.mlestimate"><code>mlestimate()</code></a>, <a href="#NeuralEstimators.posteriormedian"><code>posteriormedian()</code></a>, and <a href="#NeuralEstimators.posteriormean"><code>posteriormean()</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L169-L182">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NeuralEstimators.mlestimate" href="#NeuralEstimators.mlestimate"><code>NeuralEstimators.mlestimate</code></a> ‚Äî <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">mlestimate(estimator::RatioEstimator, Z; Œ∏‚ÇÄ = nothing, Œ∏_grid = nothing, penalty::Function = Œ∏ -&gt; 1, use_gpu = true)</code></pre><p>Computes the (approximate) maximum likelihood estimate given data <span>$\boldsymbol{Z}$</span>,</p><p class="math-container">\[\underset{\boldsymbol{\theta}}{\mathrm{arg\,max\;}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z}),\]</p><p>where <span>$\ell(\cdot ; \cdot)$</span> denotes the approximate log-likelihood function implied by <code>estimator</code>.</p><p>If a vector <code>Œ∏‚ÇÄ</code> of initial parameter estimates is given, the approximate likelihood is maximised by gradient descent (requires <code>Optim.jl</code> to be loaded). Otherwise, if a matrix of parameters <code>Œ∏_grid</code> is given, the approximate likelihood is maximised by grid search.</p><p>A maximum penalised likelihood estimate,</p><p class="math-container">\[\underset{\boldsymbol{\theta}}{\mathrm{arg\,max\;}} \ell(\boldsymbol{\theta} ; \boldsymbol{Z}) + \log p(\boldsymbol{\theta}),\]</p><p>can be obtained by specifying the keyword argument <code>penalty</code> that defines the penalty term <span>$p(\boldsymbol{\theta})$</span>.</p><p>See also <a href="#NeuralEstimators.posteriormean"><code>posteriormean()</code></a>, <a href="#NeuralEstimators.posteriormedian"><code>posteriormedian()</code></a>, and <a href="#NeuralEstimators.posteriormode"><code>posteriormode()</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/32e0138b9a13716b1c0c7d54d2d582317976543f/src/inference.jl#L146-L165">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../workflow/advancedusage/">¬´ Advanced usage</a><a class="docs-footer-nextpage" href="../architectures/">Architectures ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 5 February 2025 14:49">Wednesday 5 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
