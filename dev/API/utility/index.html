<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Miscellaneous · NeuralEstimators.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Theoretical framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/examples/">Examples</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../core/">Core functions</a></li><li><a class="tocitem" href="../simulation/">Model-specific functions</a></li><li class="is-active"><a class="tocitem" href>Miscellaneous</a><ul class="internal"><li><a class="tocitem" href="#Core"><span>Core</span></a></li><li><a class="tocitem" href="#Activation-functions"><span>Activation functions</span></a></li><li><a class="tocitem" href="#Utility-functions"><span>Utility functions</span></a></li></ul></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Miscellaneous</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Miscellaneous</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/utility.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Miscellaneous"><a class="docs-heading-anchor" href="#Miscellaneous">Miscellaneous</a><a id="Miscellaneous-1"></a><a class="docs-heading-anchor-permalink" href="#Miscellaneous" title="Permalink"></a></h1><h2 id="Core"><a class="docs-heading-anchor" href="#Core">Core</a><a id="Core-1"></a><a class="docs-heading-anchor-permalink" href="#Core" title="Permalink"></a></h2><p>These functions can appear during the core workflow, and may need to be overloaded in some applications.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.subsetparameters" href="#NeuralEstimators.subsetparameters"><code>NeuralEstimators.subsetparameters</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">subsetparameters(parameters::M, indices) where {M &lt;: AbstractMatrix}
subsetparameters(parameters::P, indices) where {P &lt;: ParameterConfigurations}</code></pre><p>Subset <code>parameters</code> using a collection of <code>indices</code>.</p><p>Arrays in <code>parameters::P</code> with last dimension equal in size to the number of parameter configurations, K, are also subsetted (over their last dimension) using <code>indices</code>. All other fields are left unchanged. To modify this default behaviour, overload <code>subsetparameters</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Parameters.jl#L35-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.numberreplicates" href="#NeuralEstimators.numberreplicates"><code>NeuralEstimators.numberreplicates</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">numberofreplicates(Z)</code></pre><p>Generic function that returns the number of replicates in a given object. Default implementations are provided for commonly used data formats, namely, data stored as an <code>Array</code> or as a <code>GNNGraph</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L122-L128">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.subsetdata" href="#NeuralEstimators.subsetdata"><code>NeuralEstimators.subsetdata</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Generic function for subsetting replicates from a data set. Default methods are:</p><pre><code class="nohighlight hljs">subsetdata(Z::A, m) where {A &lt;: AbstractArray{T, N}} where {T, N}
subsetdata(Z::G, m) where {G &lt;: AbstractGraph}</code></pre><p>Note that <code>subsetdata</code> is slow for graphical data, and one should consider using a method of <code>train</code> that does not require the data to be subsetted. Use <code>numberreplicates</code> to check that the training and validation data sets are equally replicated, which prevents the invocation of <code>subsetdata</code>. Note also that <code>subsetdata</code> only applies to vectors of batched graphs.</p><p>If the user is working with data that is not covered by the default methods, simply overload <code>subsetdata</code> with the appropriate type for <code>Z</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using GraphNeuralNetworks
using Flux: batch

n = 5  # number of observations in each realisation
m = 6  # number of replicates for each parameter vector
d = 1  # dimension of the response variable
K = 2  # number of parameter vectors

# Array data
Z = [rand(n, d, m) for k ∈ 1:K]
subsetdata(Z, 1:3) # extract first 3 replicates for each parameter vector

# Graphical data
e = 8 # number of edges
Z = [batch([rand_graph(n, e, ndata = rand(d, n)) for _ ∈ 1:m]) for k ∈ 1:K]
subsetdata(Z, 1:3) # extract first 3 replicates for each parameter vector</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L152-L187">source</a></section></article><h2 id="Activation-functions"><a class="docs-heading-anchor" href="#Activation-functions">Activation functions</a><a id="Activation-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-functions" title="Permalink"></a></h2><p>These layers can be used at the end of an architecture to ensure that the neural estimator provides valid parameters.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.Compress" href="#NeuralEstimators.Compress"><code>NeuralEstimators.Compress</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Compress(a, b)</code></pre><p>Layer to compress the output to be within <code>a</code> and <code>b</code>, where each element of <code>a</code> is less than the corresponding element of <code>b</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux

p = 3
a = [0.1, -1, 2]
b = [0.9, 1, 3]
n = 20
K = 10
θ̂ = Chain(Dense(n, p), Compress(a, b))
Z = rand(n, K)
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Architectures.jl#L649-L669">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CholeskyCovariance" href="#NeuralEstimators.CholeskyCovariance"><code>NeuralEstimators.CholeskyCovariance</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CholeskyCovariance(d)</code></pre><p>Layer for constructing the parameters of the lower Cholesky factor associated with an unconstrained <code>d</code>×<code>d</code> covariance matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>+1)÷2 rows into a <code>Matrix</code> of the same dimension, but with <code>d</code> rows constrained to be positive (corresponding to the diagonal elements of the Cholesky factor) and the remaining rows unconstrained.</p><p>The ordering of the transformed <code>Matrix</code> aligns with Julia&#39;s column-major ordering. For example, when modelling the Cholesky factor,</p><p class="math-container">\[\begin{bmatrix}
L₁₁ &amp;     &amp;     \\
L₂₁ &amp; L₂₂ &amp;     \\
L₃₁ &amp; L₃₂ &amp; L₃₃ \\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CholeskyCovariance</code> layer will be ordered as</p><p class="math-container">\[L₁₁, L₂₁, L₃₁, L₂₂, L₃₂, L₃₃,\]</p><p>which means that the output can easily be transformed into the implied Cholesky factors using <a href="#NeuralEstimators.vectotril"><code>vectotril</code></a>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators

d = 4
p = d*(d+1)÷2
θ = randn(p, 50)
l = CholeskyCovariance(d)
θ = l(θ)                              # returns matrix (used for Flux networks)
L = [vectotril(y) for y ∈ eachcol(θ)] # convert matrix to Cholesky factors</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Architectures.jl#L824-L866">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CovarianceMatrix" href="#NeuralEstimators.CovarianceMatrix"><code>NeuralEstimators.CovarianceMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CovarianceMatrix(d)</code></pre><p>Layer for constructing the parameters of an unconstrained <code>d</code>×<code>d</code> covariance matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>+1)÷2 rows into a <code>Matrix</code> of the same dimension.</p><p>Internally, it uses a <code>CholeskyCovariance</code> layer to construct a valid Cholesky factor 𝐋, and then extracts the lower triangle from the positive-definite covariance matrix 𝚺 = 𝐋𝐋&#39;. The lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering. For example, when modelling the covariance matrix,</p><p class="math-container">\[\begin{bmatrix}
Σ₁₁ &amp; Σ₁₂ &amp; Σ₁₃ \\
Σ₂₁ &amp; Σ₂₂ &amp; Σ₂₃ \\
Σ₃₁ &amp; Σ₃₂ &amp; Σ₃₃ \\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CovarianceMatrix</code> layer will be ordered as</p><p class="math-container">\[Σ₁₁, Σ₂₁, Σ₃₁, Σ₂₂, Σ₃₂, Σ₃₃,\]</p><p>which means that the output can easily be transformed into the implied covariance matrices using <a href="#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using LinearAlgebra

d = 4
p = d*(d+1)÷2
θ = randn(p, 50)

l = CovarianceMatrix(d)
θ = l(θ)
Σ = [Symmetric(cpu(vectotril(y)), :L) for y ∈ eachcol(θ)]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Architectures.jl#L884-L928">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.CorrelationMatrix" href="#NeuralEstimators.CorrelationMatrix"><code>NeuralEstimators.CorrelationMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CorrelationMatrix(d)</code></pre><p>Layer for constructing the parameters of an unconstrained <code>d</code>×<code>d</code> correlation matrix.</p><p>The layer transforms a <code>Matrix</code> with <code>d</code>(<code>d</code>-1)÷2 rows into a <code>Matrix</code> with the same dimension.</p><p>Internally, the layers uses the algorithm described <a href="https://mc-stan.org/docs/reference-manual/cholesky-factors-of-correlation-matrices-1.html#cholesky-factor-of-correlation-matrix-inverse-transform">here</a> and <a href="https://mc-stan.org/docs/reference-manual/correlation-matrix-transform.html#correlation-matrix-transform.section">here</a> to construct a valid Cholesky factor 𝐋, and then extracts the strict lower triangle from the positive-definite correlation matrix 𝐑 = 𝐋𝐋&#39;. The strict lower triangle is extracted and vectorised in line with Julia&#39;s column-major ordering. For example, when modelling the correlation matrix,</p><p class="math-container">\[\begin{bmatrix}
1   &amp; R₁₂ &amp;  R₁₃ \\
R₂₁ &amp; 1   &amp;  R₂₃\\
R₃₁ &amp; R₃₂ &amp; 1\\
\end{bmatrix},\]</p><p>the rows of the matrix returned by a <code>CorrelationMatrix</code> layer will be ordered as</p><p class="math-container">\[R₂₁, R₃₁, R₃₂,\]</p><p>which means that the output can easily be transformed into the implied correlation matrices using the strict variant of <a href="#NeuralEstimators.vectotril"><code>vectotril</code></a> and <code>Symmetric</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators
using LinearAlgebra

d = 4
p = d*(d-1)÷2
l = CorrelationMatrix(d)
θ = randn(p, 50)

# returns a matrix of parameters
θ = l(θ)

# convert matrix of parameters to implied correlation matrices
R = map(eachcol(θ)) do y
	R = Symmetric(cpu(vectotril(y, strict = true)), :L)
	R[diagind(R)] .= 1
	R
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Architectures.jl#L727-L780">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.SplitApply" href="#NeuralEstimators.SplitApply"><code>NeuralEstimators.SplitApply</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SplitApply(layers, indices)</code></pre><p>Splits an array into multiple sub-arrays by subsetting the rows using the collection of <code>indices</code>, and then applies each layer in <code>layers</code> to the corresponding sub-array.</p><p>Specifically, for each <code>i</code> = 1, …, <span>$n$</span>, with <span>$n$</span> the number of <code>layers</code>, <code>SplitApply(x)</code> performs <code>layers[i](x[indices[i], :])</code>, and then vertically concatenates the resulting transformed arrays.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators

d = 4
K = 50
p₁ = 2          # number of non-covariance matrix parameters
p₂ = d*(d+1)÷2  # number of covariance matrix parameters
p = p₁ + p₂

a = [0.1, 4]
b = [0.9, 9]
l₁ = Compress(a, b)
l₂ = CovarianceMatrix(d)
l = SplitApply([l₁, l₂], [1:p₁, p₁+1:p])

θ = randn(p, K)
l(θ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/Architectures.jl#L684-L713">source</a></section></article><h2 id="Utility-functions"><a class="docs-heading-anchor" href="#Utility-functions">Utility functions</a><a id="Utility-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.vectotril" href="#NeuralEstimators.vectotril"><code>NeuralEstimators.vectotril</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">vectotril(v; strict = false)
vectotriu(v; strict = false)</code></pre><p>Converts a vector <code>v</code> of length <span>$d(d+1)÷2$</span> (a triangular number) into a <span>$d × d$</span> lower or upper triangular matrix.</p><p>If <code>strict = true</code>, the matrix will be <em>strictly</em> lower or upper triangular, that is, a <span>$(d+1) × (d+1)$</span> triangular matrix with zero diagonal.</p><p>Note that the triangular matrix is constructed on the CPU, but the returned matrix will be a GPU array if <code>v</code> is a GPU array. Note also that the return type is not of type <code>Triangular</code> matrix (i.e., the zeros are materialised) since <code>Traingular</code> matrices are not always compatible with other GPU operations.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using NeuralEstimators

d = 4
n = d*(d+1)÷2
v = collect(range(1, n))
vectotril(v)
vectotriu(v)
vectotril(v; strict = true)
vectotriu(v; strict = true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L40-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.containertype" href="#NeuralEstimators.containertype"><code>NeuralEstimators.containertype</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">containertype(A::Type)
containertype(::Type{A}) where A &lt;: SubArray
containertype(a::A) where A</code></pre><p>Returns the container type of its argument.</p><p>If given a <code>SubArray</code>, returns the container type of the parent array.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">a = rand(3, 4)
containertype(a)
containertype(typeof(a))
[containertype(x) for x ∈ eachcol(a)]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L101-L116">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.loadbestweights" href="#NeuralEstimators.loadbestweights"><code>NeuralEstimators.loadbestweights</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">loadbestweights(path::String)</code></pre><p>Given a <code>path</code> to a training run containing neural networks saved with names <code>&quot;network_epochx.bson&quot;</code> and an object saved as <code>&quot;loss_per_epoch.bson&quot;</code>,  returns the weights of the best network (measured by validation loss).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L274-L278">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.stackarrays" href="#NeuralEstimators.stackarrays"><code>NeuralEstimators.stackarrays</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">stackarrays(v::V; merge = true) where {V &lt;: AbstractVector{A}} where {A &lt;: AbstractArray{T, N}} where {T, N}</code></pre><p>Stack a vector of arrays <code>v</code> along the last dimension of each array, optionally merging the final dimension of the stacked array.</p><p>The arrays must be of the same size for the first <code>N-1</code> dimensions. However, if <code>merge = true</code>, the size of the final dimension can vary.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Vector containing arrays of the same size:
Z = [rand(2, 3, m) for m ∈ (1, 1)];
stackarrays(Z)
stackarrays(Z, merge = false)

# Vector containing arrays with differing final dimension size:
Z = [rand(2, 3, m) for m ∈ (1, 2)];
stackarrays(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L388-L407">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.expandgrid" href="#NeuralEstimators.expandgrid"><code>NeuralEstimators.expandgrid</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">expandgrid(xs, ys)</code></pre><p>Same as <code>expand.grid()</code> in <code>R</code>, but currently caters for two dimensions only.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/318064e2fb49fff99d84f767aad273890fe6d21f/src/utility.jl#L329-L333">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../simulation/">« Model-specific functions</a><a class="docs-footer-nextpage" href="../">Index »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 30 April 2023 09:37">Sunday 30 April 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
