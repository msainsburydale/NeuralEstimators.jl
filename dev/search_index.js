var documenterSearchIndex = {"docs":
[{"location":"API/simulation/#Model-specific-functions","page":"Model-specific functions","title":"Model-specific functions","text":"","category":"section"},{"location":"API/simulation/#Data-simulators","page":"Model-specific functions","title":"Data simulators","text":"","category":"section"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"The philosophy of NeuralEstimators is to cater for arbitrary statistical models by having the user define their statistical model implicitly through simulated data. However, the following functions have been included as they may be helpful to others, and their source code provide an example for how a user could formulate code for their own model. If you've developed similar functions that you think may be helpful to others, please get in touch or make a pull request.","category":"page"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"simulategaussianprocess\n\nsimulateschlather","category":"page"},{"location":"API/simulation/#NeuralEstimators.simulategaussianprocess","page":"Model-specific functions","title":"NeuralEstimators.simulategaussianprocess","text":"simulategaussianprocess(L::Matrix, m = 1)\nsimulategaussianprocess(grf::GaussianRandomField, m = 1)\n\nSimulates m independent and identically distributed (i.i.d.) realisations from a mean-zero Gaussian process.\n\nAccepts either the lower Cholesky factor L associated with a Gaussian process or a GaussianRandomField object grf.\n\nExamples\n\nusing NeuralEstimators\n\nn  = 500\nS  = rand(n, 2)\nœÅ  = 0.6\nŒΩ  = 1.0\n\n# Passing GaussianRandomField object:\nusing GaussianRandomFields\ncov = CovarianceFunction(2, Matern(œÅ, ŒΩ))\ngrf = GaussianRandomField(cov, Cholesky(), S)\nsimulategaussianprocess(grf)\n\n# Passing Cholesky factors directly as matrices:\nL = grf.data\nsimulategaussianprocess(L)\n\n# Circulant embedding, which is fast but can on only be used on grids:\npts = 1.0:50.0\ngrf = GaussianRandomField(cov, CirculantEmbedding(), pts, pts, minpadding = 100)\nsimulategaussianprocess(grf)\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.simulateschlather","page":"Model-specific functions","title":"NeuralEstimators.simulateschlather","text":"simulateschlather(L::Matrix, m = 1)\nsimulateschlather(grf::GaussianRandomField, m = 1)\n\nSimulates m independent and identically distributed (i.i.d.) realisations from Schlather's max-stable model using the algorithm for approximate simulation given by Schlather (2002), \"Models for stationary max-stable random fields\", Extremes, 5:33-44.\n\nAccepts either the lower Cholesky factor L associated with a Gaussian process or a GaussianRandomField object grf.\n\nKeyword arguments\n\nC = 3.5: a tuning parameter that controls the accuracy of the algorithm: small C favours computational efficiency, while large C favours accuracy. Schlather (2002) recommends the use of C = 3.\nGumbel = true: flag indicating whether the data should be log-transformed from the unit Fr√©chet scale to the Gumbel scale.\n\nExamples\n\nusing NeuralEstimators\n\nn  = 500\nS  = rand(n, 2)\nœÅ  = 0.6\nŒΩ  = 1.0\n\n# Passing GaussianRandomField object:\nusing GaussianRandomFields\ncov = CovarianceFunction(2, Matern(œÅ, ŒΩ))\ngrf = GaussianRandomField(cov, Cholesky(), S)\nsimulateschlather(grf)\n\n# Passing Cholesky factors directly as matrices:\nL = grf.data\nsimulateschlather(L)\n\n# Circulant embedding, which is fast but can on only be used on grids:\npts = 1.0:50.0\ngrf = GaussianRandomField(cov, CirculantEmbedding(), pts, pts, minpadding = 100)\nsimulateschlather(grf)\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#Spatial-point-processes","page":"Model-specific functions","title":"Spatial point processes","text":"","category":"section"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"maternclusterprocess","category":"page"},{"location":"API/simulation/#NeuralEstimators.maternclusterprocess","page":"Model-specific functions","title":"NeuralEstimators.maternclusterprocess","text":"maternclusterprocess(; Œª=10, Œº=10, r=0.1, xmin=0, xmax=1, ymin=0, ymax=1)\n\nSimulates a Mat√©rn cluster process with density of parent Poisson point process Œª, mean number of daughter points Œº, and radius of cluster disk r, over the simulation window defined by {x/y}min and {x/y}max.\n\nNote that one may also use the R package spatstat using RCall.\n\nExamples\n\nusing NeuralEstimators\n\n# Simulate a realisation from a Mat√©rn cluster process\nS = maternclusterprocess()\n\n# Visualise realisation (requires UnicodePlots)\nusing UnicodePlots\nscatterplot(S[:, 1], S[:, 2])\n\n# Visualise realisations from the cluster process with varying parameters\nn = 250\nŒª = [10, 25, 50, 90]\nŒº = n ./ Œª\nplots = map(eachindex(Œª)) do i\n\tS = maternclusterprocess(Œª = Œª[i], Œº = Œº[i])\n\tscatterplot(S[:, 1], S[:, 2])\nend\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#Low-level-functions","page":"Model-specific functions","title":"Low-level functions","text":"","category":"section"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"These low-level functions may be of use for various models.","category":"page"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"matern\n\nmaternchols","category":"page"},{"location":"API/simulation/#NeuralEstimators.matern","page":"Model-specific functions","title":"NeuralEstimators.matern","text":"matern(h, œÅ, ŒΩ, œÉ¬≤ = 1)\n\nFor two points separated by h units, compute the Mat√©rn covariance function, with range parameter œÅ, smoothness parameter ŒΩ, and marginal variance parameter œÉ¬≤.\n\nWe use the parametrisation C(mathbfh) = sigma^2 frac2^1 - nuGamma(nu) left(fracmathbfhrhoright)^nu K_nu left(fracmathbfhrhoright), where Gamma(cdot) is the gamma function, and K_nu(cdot) is the modified Bessel function of the second kind of order nu.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.maternchols","page":"Model-specific functions","title":"NeuralEstimators.maternchols","text":"maternchols(D, œÅ, ŒΩ, œÉ¬≤ = 1; stack = true)\n\nGiven a distance matrix D, constructs the Cholesky factor of the covariance matrix under the Mat√©rn covariance function with range parameter œÅ, smoothness parameter ŒΩ, and marginal variance œÉ¬≤.\n\nProviding vectors of parameters will yield a three-dimensional array of Cholesky factors (note that the vectors must of the same length, but a mix of vectors and scalars is allowed). A vector of distance matrices D may also be provided.\n\nIf stack = true, the Cholesky factors will be \"stacked\" into a three-dimensional array (this is only possible if all distance matrices in D are the same size).\n\nExamples\n\nusing NeuralEstimators\nusing LinearAlgebra: norm\nn  = 10\nS  = rand(n, 2)\nD  = [norm(s·µ¢ - s‚±º) for s·µ¢ ‚àà eachrow(S), s‚±º ‚àà eachrow(S)]\nœÅ  = [0.6, 0.5]\nŒΩ  = [0.7, 1.2]\nœÉ¬≤ = [0.2, 0.4]\nmaternchols(D, œÅ, ŒΩ)\nmaternchols([D], œÅ, ŒΩ)\nmaternchols(D, œÅ, ŒΩ, œÉ¬≤; stack = false)\n\nSÃÉ  = rand(n, 2)\nDÃÉ  = [norm(s·µ¢ - s‚±º) for s·µ¢ ‚àà eachrow(SÃÉ), s‚±º ‚àà eachrow(SÃÉ)]\nmaternchols([D, DÃÉ], œÅ, ŒΩ, œÉ¬≤)\nmaternchols([D, DÃÉ], œÅ, ŒΩ, œÉ¬≤; stack = false)\n\nSÃÉ  = rand(2n, 2)\nDÃÉ  = [norm(s·µ¢ - s‚±º) for s·µ¢ ‚àà eachrow(SÃÉ), s‚±º ‚àà eachrow(SÃÉ)]\nmaternchols([D, DÃÉ], œÅ, ŒΩ, œÉ¬≤; stack = false)\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#Density-functions","page":"Model-specific functions","title":"Density functions","text":"","category":"section"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"Density functions are not needed in the workflow of NeuralEstimators. However, as part of a series of comparison studies between neural estimators and likelihood-based estimators given in the manuscript, we have developed the following density functions, and we include them in NeuralEstimators to cater for the possibility that they may be of use in future comparison studies.","category":"page"},{"location":"API/simulation/","page":"Model-specific functions","title":"Model-specific functions","text":"gaussiandensity\n\nschlatherbivariatedensity","category":"page"},{"location":"API/simulation/#NeuralEstimators.gaussiandensity","page":"Model-specific functions","title":"NeuralEstimators.gaussiandensity","text":"gaussiandensity(y::V, L; logdensity = true) where {V <: AbstractVector{T}} where T\ngaussiandensity(y::A, Œ£; logdensity = true) where {A <: AbstractArray{T, N}} where {T, N}\n\nEfficiently computes the density function for y ~ ùëÅ(0, Œ£), with L the lower Cholesky factor of the covariance matrix Œ£.\n\nThe method gaussiandensity(y::A, Œ£) assumes that the last dimension of y corresponds to the independent-replicates dimension, and it exploits the fact that we need to compute the Cholesky factor L for these independent replicates once only.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.schlatherbivariatedensity","page":"Model-specific functions","title":"NeuralEstimators.schlatherbivariatedensity","text":"schlatherbivariatedensity(z‚ÇÅ, z‚ÇÇ, œà; logdensity = true)\n\nThe bivariate density function for Schlather's max-stable model, as given in Huser (2013, pg. 231‚Äì232).\n\nHuser, R. (2013). Statistical Modeling and Inference for Spatio-Temporal Ex- tremes. PhD thesis, Swiss Federal Institute of Technology, Lausanne, Switzerland.\n\n\n\n\n\n","category":"function"},{"location":"workflow/examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"The following packages are used throughout these examples.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"using NeuralEstimators\nusing Flux\nusing Distributions\nimport NeuralEstimators: simulate","category":"page"},{"location":"workflow/examples/#Univariate-data","page":"Examples","title":"Univariate data","text":"","category":"section"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Here we develop a neural Bayes estimator for boldsymboltheta equiv (mu sigma) from data Z_1 dots Z_m that are independent and identically distributed realisations from the distribution N(mu sigma^2). We assume that the parameters are independent a priori and we adopt the marginal priors mu sim N(0 1) and sigma sim U(01 1).","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"First, we define a function to sample parameters from the prior. The sampled parameters are stored as p times K matrices, with p the number of parameters in the model and K the number of sampled parameter vectors.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"function sample(K)\n\tŒº = rand(Normal(0, 1), K)\n\tœÉ = rand(Uniform(0.1, 1), K)\n\tŒ∏ = hcat(Œº, œÉ)'\n\treturn Œ∏\nend","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Next, we implicitly define the statistical model with simulated data. In NeuralEstimators, the data are always stored as a Vector{A}, where each element of the vector is associated with one parameter vector, and where A depends on the structure of the data. Since our data Z_1 dots Z_m are replicated, we will use the DeepSet architecture. Since each replicate is univariate (i.e., the dimension d of each replicate is equal to one), we will use a dense neural network (DNN) for the inner network of the DeepSets architecture (the outer network is always a DNN). Since the inner network is a DNN, A should be a Matrix with d rows and m columns.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"simulate(parameters, m) = [Œ∏[1] .+ Œ∏[2] .* randn(1, m) for Œ∏ ‚àà eachcol(parameters)]","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"We now design architectures for the inner and outer neural networks, boldsymbolpsi(cdot) and boldsymbolphi(cdot) respectively, in the DeepSet framework, and initialise the neural estimator as a PointEstimator object. Note that this can be done directly using Flux code (as below), or with the helper function initialise_estimator. ","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"d = 1   # dimension of each replicate\np = 2   # number of parameters in the statistical model\nw = 32  # width of each layer\n\nœà = Chain(Dense(d, w, relu), Dense(w, w, relu))\nœï = Chain(Dense(w, w, relu), Dense(w, p))\narchitecture = DeepSet(œà, œï)\n\nŒ∏ÃÇ = PointEstimator(architecture)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Next, we train the neural estimator using train, here using the default absolute-error loss. We'll train the estimator using 15 independent replicates per parameter configuration. Below, we pass our user-defined functions for sampling parameters and simulating data, but one may also pass parameter or data instances, which will be held fixed during training; see train.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"m = 15\nŒ∏ÃÇ = train(Œ∏ÃÇ, sample, simulate, m = m, epochs = 30)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"To test the accuracy of the resulting neural Bayes estimator, we use the function assess, which can be used to assess the performance of the estimator (or multiple estimators) over a range of sample sizes. Note that, in this example, we trained the neural estimator using a single sample size, m = 15, and hence the estimator will not necessarily be optimal for other sample sizes; see Variable sample sizes for approaches that one could adopt if data sets with varying sample size are envisaged.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Œ∏     = sample(1000)\nZ     = [simulate(Œ∏, m) for m ‚àà (5, 10, 15, 20, 30)]\nassessment = assess([Œ∏ÃÇ], Œ∏, Z)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"The returned object is an object of type Assessment, which contains the true parameters and their corresponding estimates, and the time taken to compute the estimates for each sample size and each estimator. The risk function may be computed using the function risk:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"risk(assessment)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"It is often helpful to visualise the empirical sampling distribution of an estimator for a particular parameter configuration and a particular sample size. This can be done by providing assess with J data sets simulated under a particular parameter configuration (below facilitated with the pre-defined method simulate(parameters, m, J), which wraps the method of simulate that we defined earlier), and then plotting the estimates contained in the long-form DataFrame in the resulting Assessment object:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"J = 100\nŒ∏ = sample(1)\nZ = [simulate(Œ∏, m, J)]\nassessment = assess([Œ∏ÃÇ], Œ∏, Z)  ","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Once the neural Bayes estimator has been assessed, it may then be applied to observed data, with parametric/non-parametric bootstrap-based uncertainty quantification facilitated by bootstrap and interval. Below, we use simulated data as a substitute for observed data:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Z = simulate(Œ∏, m)     # pretend that this is observed data\nŒ∏ÃÇ(Z)                   # point estimates from the observed data\nŒ∏ÃÉ = bootstrap(Œ∏ÃÇ, Z)    # non-parametric bootstrap estimates\ninterval(Œ∏ÃÉ)  \t\t\t\t\t# confidence interval from the bootstrap estimates","category":"page"},{"location":"workflow/examples/#Multivariate-data","page":"Examples","title":"Multivariate data","text":"","category":"section"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Suppose now that our data consists of m replicates of a d-dimensional multivariate distribution. Everything remains as given in the univariate example above, except that we now store the data as a vector of d times m matrices (previously they were stored as 1times m matrices), and the inner network of the DeepSets representation takes a d-dimensional input (previously it took a 1-dimensional input).","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Note that, when estimating a full covariance matrix, one may wish to constrain the neural estimator to only produce parameters that imply a valid (i.e., positive definite) covariance matrix. This can be achieved by appending a  CovarianceMatrix layer to the end of the outer network of the DeepSets representation. However, this is often unnecessary as the estimator will typically learn to provide valid estimates, even if not constrained to do so.","category":"page"},{"location":"workflow/examples/#Gridded-spatial-data","page":"Examples","title":"Gridded spatial data","text":"","category":"section"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"For spatial data measured on a regular grid, the estimator is typically based on a convolutional neural network (CNN), and each data set is stored as a four-dimensional array, where the first three dimensions correspond to the width, height, and channels dimensions, and the fourth dimension stores the independent replicates. Note that, for univariate spatial processes, the channels dimension is simply equal to 1. For a 16x16 spatial grid, a possible architecture is given below.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"p = 2    # number of parameters in the statistical model\nw = 32   # number of neurons in each layer\nd = 2    # dimension of the response variable\n\nœà = Chain(\n\tConv((10, 10), 1 => 32,  relu),\n\tConv((5, 5),  32 => 64,  relu),\n\tConv((3, 3),  64 => 128, relu),\n\tFlux.flatten\n\t)\nœï = Chain(Dense(128, 512, relu), Dense(512, p))\narchitecture = DeepSet(œà, œï)","category":"page"},{"location":"workflow/examples/#Irregular-spatial-data","page":"Examples","title":"Irregular spatial data","text":"","category":"section"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"The methodology we illustrate here uses graph neural networks (GNNs), which are implemented in Julia in the package GraphNeuralNetworks.jl. GNN-based estimators parsimoniously model spatial dependence, and they can be applied to data collected over arbitrary spatial locations. Some key steps involve:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Sampling spatial locations to cover a wide range of spatial configurations during the training phase: see maternclusterprocess.\nComputing (spatially-weighted) adjacency matrices: see adjacencymatrix.\nStoring the data as a graph: see GNNGraph.\nConstructing an appropriate architecture: see GNN and WeightedGraphConv.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"For a concrete example, we consider a classical spatial model, the linear Gaussian-Gaussian model,","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Z_j = Y(boldsymbols_j) + epsilon_j  j = 1 dots n","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"where boldsymbolZ equiv (Z_1 dots Z_n) are data observed at locations boldsymbols_1 dots boldsymbols_n subset mathcalD, where mathcalD is some spatial domain, Y(cdot) is a spatially-correlated mean-zero Gaussian process, and epsilon_j sim N(0 tau^2), j = 1 dots n is Gaussian white noise with standard deviation tau  0. Here, we use the popular isotropic Mat√©rn covariance function with fixed marginal variance sigma^2 = 1, fixed smoothness parameter nu = 05, and unknown range parameter rho  0. See matern for the specific parametrisation used in this example. Hence, we will construct a neural Bayes estimator for boldsymboltheta equiv (tau rho).","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Before proceeding, we load the required packages:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"using NeuralEstimators\nusing Flux\nusing GraphNeuralNetworks\nusing Distributions: Uniform\nusing Distances: pairwise, Euclidean\nusing LinearAlgebra\nusing Statistics: mean","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"First, we define a function to sample parameters from the prior. As before, the sampled parameters are stored as p times K matrices, with p the number of parameters in the model and K the number of sampled parameter vectors. We use the priors tau sim U(01 1) and rho sim U(005 05), and we assume that the parameters are independent a priori. Simulation from this model involves the computation of an expensive intermediate object, namely, the Cholesky factor of the covariance matrix. Storing this Cholesky factor for re-use can enable the fast simulation of new data sets (provided that the parameters are held fixed): hence, in this example, we define a class, Parameters, which is a sub-type of ParameterConfigurations, for storing the matrix of parameters and the corresponding intermediate objects needed for data simulation.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"If one wishes to make inference from a single spatial data set only, and this data is collected before the estimator is constructed, then the data can be simulated using the observed spatial locations. However, if one wishes to construct an estimator that is (approximately) Bayes irrespective of the spatial locations, then synthetic spatial locations must be generated during the training phase. If no prior knowledge on the sampling configuration is available, then a wide variety of spatial configurations must be simulated to produce an estimator that is broadly applicable. Below, we use a Mat√©rn cluster process (see maternclusterprocess) for this task (note that the hyper-parameters of this process govern the expected number of locations in each sampled set of spatial locations, and the degree of clustering).","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"We define two constructors for our Parameters object: one that constructs a Parameters object given a single integer K, and another that constructs a Parameters object given a pre-specified ptimes K matrix of parameters and a set of spatial locations associated with each parameter vector. These constructors will be useful in the workflow below.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"struct Parameters{T} <: ParameterConfigurations\n\tŒ∏::Matrix{T}\n\tlocations\n\tchols\n\tgraphs\nend\n\nfunction Parameters(K::Integer)\n\n\t# Sample parameters from the prior distribution\n\tœÑ = rand(Uniform(0.1, 1.0), K)\n\tœÅ = rand(Uniform(0.05, 0.5), K)\n\n\t# Combine parameters into a pxK matrix\n\tŒ∏ = permutedims(hcat(œÑ, œÅ))\n\n\t# Simulate spatial locations from a cluster process over the unit square\n\tn = rand(Uniform(75, 200), K)\n\tŒª = rand(Uniform(10, 50), K)\n\tlocations = [maternclusterprocess(Œª = Œª[k], Œº = n[k]/Œª[k]) for k ‚àà 1:K]\n\n\tParameters(Œ∏::Matrix, locations)\nend\n\nfunction Parameters(Œ∏::Matrix, locations)\n\n\t# Compute distance matrices and construct the graphs\n\tD = pairwise.(Ref(Euclidean()), locations, locations, dims = 1)\n\tA = adjacencymatrix.(D, 0.15)\n\tgraphs = GNNGraph.(A)\n\n\t# Compute Cholesky factors using the distance matrices\n\tœÅ = Œ∏[2, :]\n\tŒΩ = 0.5\n\tœÉ = 1\n\tchols = maternchols(D, œÅ, ŒΩ, œÉ.^2; stack = false)     \n\n\tParameters(Œ∏, locations, chols, graphs)\nend","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Next, we define a function for simulating from the model given an object of type Parameters. Although here we are constructing an estimator for a single replicate, the code below enables simulation of an arbitrary number of independent replicates m: one may provide a single integer for m, a range of values (e.g., 1:30), or any object that can be sampled using rand(m, K) (e.g., some distribution over the possible sample sizes).","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"function simulate(parameters::Parameters, m)\n\n\tK = size(parameters, 2)\n\tmÃÉ = rand(m, K)\n\n\tœÑ      = parameters.Œ∏[1, :]\n\tchols  = parameters.chols\n\tg      = parameters.graphs\n\n\t# Z = Folds.map(1:K) do i # use this for parallel simulation\n\tZ = map(1:K) do k\n\t\tL = chols[k][:, :]\n\t\tz = simulategaussianprocess(L, mÃÉ[k])  # simulate a smooth field\n\t\tz = z + œÑ[k] * randn(size(z)...)      # add white noise\n\t\tz = batch([GNNGraph(g[k], ndata = z[:, i, :]') for i ‚àà 1:mÃÉ[k]])\n\t\tz\n\tend\n\n\treturn Z\nend\nsimulate(parameters::Parameters, m::Integer) = simulate(parameters, range(m, m))","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Next we construct an appropriate architecture using GNN and WeightedGraphConv. For example, we might construct a point estimator as:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"# Propagation module\nd = 1      # dimension of response variable\nnh = 32    # dimension of node feature vectors\npropagation = GNNChain(\n\tWeightedGraphConv(d => nh),\n\tWeightedGraphConv(nh => nh),\n\tWeightedGraphConv(nh => nh)\n\t)\n\n# Readout module (using the elementwise average)\nno = nh    # dimension of the final summary vector for each graph\nreadout = GlobalPool(mean)\n\n# Mapping module (use exponential output activation to ensure positive estimates)\np = 2     # number of parameters in the statistical model\nw = 64    # width of layers used for the mapping network œï\nœï = Chain(Dense(no, w, relu), Dense(w, w, relu), Dense(w, p, exp))\n\n# Construct the estimator\nŒ∏ÃÇ = GNN(propagation, readout, œï)\nŒ∏ÃÇ = PointEstimator(Œ∏ÃÇ)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Next, we train the neural estimator using train, here using the default absolute-error loss. We'll train the estimator using a single realisation per parameter configuration (i.e., with m = 1). Below, we use a very small number of epochs and a small number of training parameter vectors to keep the run time of this example low, and this will of course result in a poor estimator: in practice, one may set K to some large value (say, 10,000), and leave epochs unspecified so that training halts only when the risk function ceases to decrease.","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Œ∏ÃÇ = train(Œ∏ÃÇ, Parameters, simulate, m = 1, epochs = 5, K = 500)","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"Finally, once the neural Bayes estimator has been assessed (as illustrated using assess in the univariate example above), it may be applied to observed data, with bootstrap-based uncertainty quantification facilitated by bootstrap and interval. Below, we use simulated data as a substitute for observed data:","category":"page"},{"location":"workflow/examples/","page":"Examples","title":"Examples","text":"# Generate some toy data\nparameters = Parameters(1)   # sample a single parameter vector\nz = simulate(parameters, 1)  # simulate some data                  \nŒ∏ = parameters.Œ∏             # true parameters used to generate data\nS = parameters.locations     # observed locations\n\n# Point estimates\nŒ∏ÃÇ(z)\n\n# Parametric bootstrap sample and bootstrap confidence interval\nŒ∏ÃÉ = bootstrap(Œ∏ÃÇ, Parameters(Œ∏ÃÇ(z), S), simulate, 1)   \ninterval(Œ∏ÃÉ)  \t\t\t\t\t                ","category":"page"},{"location":"framework/#Framework","page":"Framework","title":"Framework","text":"","category":"section"},{"location":"framework/","page":"Framework","title":"Framework","text":"In this section, we provide an overview of point estimation using neural Bayes estimators. For a more detailed discussion on the framework and its implementation, see the paper Likelihood-Free Parameter Estimation with Neural Bayes Estimators","category":"page"},{"location":"framework/#Neural-Bayes-estimators","page":"Framework","title":"Neural Bayes estimators","text":"","category":"section"},{"location":"framework/","page":"Framework","title":"Framework","text":"A parametric statistical model is a set of probability distributions on a sample space mathcalS, where the probability distributions are parameterised via some p-dimensional parameter vector boldsymboltheta on a parameter space Theta. Suppose that we have data from one such distribution, which we denote as boldsymbolZ. Then, the goal of parameter point estimation is to come up with an estimate of the unknown boldsymboltheta from boldsymbolZ using an estimator,","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":" hatboldsymboltheta  mathcalS to Theta","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"which is a mapping from the sample space to the parameter space.","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Estimators can be constructed within a decision-theoretic framework. Assume that the sample space is mathcalS = mathbbR^n, and consider a non-negative loss function, L(boldsymboltheta hatboldsymboltheta(boldsymbolZ)), which assesses an estimator hatboldsymboltheta(cdot) for a given boldsymboltheta and data set boldsymbolZ sim f(boldsymbolz mid boldsymboltheta), where f(boldsymbolz mid boldsymboltheta) is the probability density function of the data conditional on boldsymboltheta. An estimator's Bayes risk is its loss averaged over all possible parameter values and data realisations,","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":" r_Omega(hatboldsymboltheta(cdot))\n equiv int_Theta int_mathcalS  L(boldsymboltheta hatboldsymboltheta(boldsymbolz))f(boldsymbolz mid boldsymboltheta) rmd boldsymbolz rmd Omega(boldsymboltheta)  ","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"where Omega(cdot) is a prior measure for boldsymboltheta. Any minimiser of the Bayes risk is said to be a Bayes estimator with respect to L(cdot cdot) and Omega(cdot).","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Bayes estimators are theoretically attractive: for example, unique Bayes estimators are admissible and, under suitable regularity conditions and the squared-error loss, are consistent and asymptotically efficient. Further, for a large class of prior distributions, every set of conditions that imply consistency of the maximum likelihood (ML) estimator also imply consistency of Bayes estimators. Importantly, Bayes estimators are not motivated purely by asymptotics: by construction, they are Bayes irrespective of the sample size and model class. Unfortunately, however, Bayes estimators are typically unavailable in closed form for the complex models often encountered in practice. A way forward is to assume a flexible parametric model for hatboldsymboltheta(cdot), and to optimise the parameters within that model in order to approximate the Bayes estimator. Neural networks are ideal candidates, since they are universal function approximators, and because they are also fast to evaluate, usually involving only simple matrix-vector operations.","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Let hatboldsymboltheta(boldsymbolZ boldsymbolgamma) denote a neural point estimator, that is, a neural network that returns a point estimate from data boldsymbolZ, where boldsymbolgamma contains the neural-network parameters. Bayes estimators may be approximated with hatboldsymboltheta(cdot boldsymbolgamma^*) by solving the optimisation problem,  ","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"boldsymbolgamma^*\nequiv\nundersetboldsymbolgammamathrmargmin  r_Omega(hatboldsymboltheta(cdot boldsymbolgamma))","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Typically, r_Omega(cdot) cannot be directly evaluated, but it can be approximated using Monte Carlo methods. Specifically, given a set of K parameter vectors sampled from the prior Omega(cdot) denoted by vartheta and, for each boldsymboltheta in vartheta, J realisations from f(boldsymbolz mid  boldsymboltheta) collected in mathcalZ_boldsymboltheta,","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":" r_Omega(hatboldsymboltheta(cdot boldsymbolgamma))\n approx\nfrac1K sum_boldsymboltheta in vartheta frac1J sum_boldsymbolz in mathcalZ_boldsymboltheta L(boldsymboltheta hatboldsymboltheta(boldsymbolz boldsymbolgamma))  ","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Note that the above approximation does not involve evaluation, or knowledge, of the likelihood function.","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"The Monte-Carlo-approximated Bayes risk can be straightforwardly minimised with respect to boldsymbolgamma using back-propagation and stochastic gradient descent. For sufficiently flexible architectures, the point estimator targets a Bayes estimator with respect to L(cdot cdot) and Omega(cdot). We therefore call the fitted neural point estimator a  neural Bayes estimator. Like Bayes estimators, neural Bayes estimators target a specific point summary of the posterior distribution. For instance, the absolute-error and squared-error loss functions lead to neural Bayes estimators that approximate the posterior median and mean, respectively.","category":"page"},{"location":"framework/#Construction-of-neural-Bayes-estimators","page":"Framework","title":"Construction of neural Bayes estimators","text":"","category":"section"},{"location":"framework/","page":"Framework","title":"Framework","text":"The neural Bayes estimators is conceptually simple and can be used in a wide range of problems where other approaches, such as maximum-likelihood estimation, are computationally infeasible. The estimator also has marked practical appeal, as the general workflow for its construction is only loosely connected to the statistical or physical model being considered. The workflow is as follows:","category":"page"},{"location":"framework/","page":"Framework","title":"Framework","text":"Define the prior, Omega(cdot).\nChoose a loss function, L(cdot cdot), typically the mean-absolute-error or mean-squared-error loss.\nDesign a suitable neural-network architecture for the neural point estimator hatboldsymboltheta(cdot boldsymbolgamma).\nSample parameters from Omega(cdot) to form training/validation/test parameter sets.\nGiven the above parameter sets, simulate data from the model, to form training/validation/test data sets.\nTrain the neural network (i.e., estimate boldsymbolgamma) by minimising the loss function averaged over the training sets. During training, monitor performance and convergence using the validation sets.\nAssess the fitted neural Bayes estimator, hatboldsymboltheta(cdot boldsymbolgamma^*), using the test set.","category":"page"},{"location":"API/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"API/","page":"Index","title":"Index","text":"","category":"page"},{"location":"workflow/advancedusage/#Advanced-usage","page":"Advanced usage","title":"Advanced usage","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"In this section, we discuss practical considerations on how to construct neural estimators most effectively.","category":"page"},{"location":"workflow/advancedusage/#Loading-pre-trained-neural-estimators","page":"Advanced usage","title":"Loading pre-trained neural estimators","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"As training is by far the most computationally demanding part of the workflow, one typically trains an estimator and then saves it for later use. More specifically, one usually saves the parameters of the neural estimator (e.g., the weights and biases of the neural networks); then, to load the neural estimator at a later time, one initialises an estimator with the same architecture used during training, and then loads the saved parameters into this estimator.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"If the argument savepath is specified, train automatically saves the neural estimator's parameters; to load them, one may use the following code, or similar:","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"using Flux: loadparams!\n\nŒ∏ÃÇ = architecture()\nloadparams!(Œ∏ÃÇ, loadbestweights(savepath))","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Above, architecture() is a user-defined function that returns a neural estimator with the same architecture as the estimator that we wish to load, but with randomly initialised parameters, and the function loadparams! loads the parameters of the best (as determined by loadbestweights) neural estimator saved in savepath.","category":"page"},{"location":"workflow/advancedusage/#Storing-expensive-intermediate-objects-for-data-simulation","page":"Advanced usage","title":"Storing expensive intermediate objects for data simulation","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Parameters sampled from the prior distribution Omega(cdot) may be stored in two ways. Most simply, they can be stored as a p times K matrix, where p is the number of parameters in the model and K is the number of parameter vectors sampled from the prior distribution; this is the approach taken in the example using univariate Gaussian data. Alternatively, they can be stored in a user-defined subtype of the abstract type ParameterConfigurations, whose only requirement is a field Œ∏ that stores the p times K matrix of parameters. With this approach, one may store computationally expensive intermediate objects, such as Cholesky factors, for later use when conducting \"on-the-fly\" simulation, which is discussed below.","category":"page"},{"location":"workflow/advancedusage/#On-the-fly-and-just-in-time-simulation","page":"Advanced usage","title":"On-the-fly and just-in-time simulation","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"When data simulation is (relatively) computationally inexpensive, mathcalZ_texttrain can be simulated continuously during training, a technique coined \"simulation-on-the-fly\". Regularly refreshing mathcalZ_texttrain leads to lower out-of-sample error and to a reduction in overfitting. This strategy therefore facilitates the use of larger, more representationally-powerful networks that are prone to overfitting when mathcalZ_texttrain is fixed. Refreshing mathcalZ_texttrain also has an additional computational benefit; data can be simulated \"just-in-time\", in the sense that they can be simulated from a small batch of vartheta_texttrain, used to train the neural estimator, and then removed from memory. This can reduce pressure on memory resources when vartheta_texttrain is very large.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"One may also regularly refresh vartheta_texttrain, and doing so leads to similar benefits. However, fixing vartheta_texttrain allows computationally expensive terms, such as Cholesky factors when working with Gaussian process models, to be reused throughout training, which can substantially reduce the training time for some models.  ","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"The above strategies are facilitated with various methods of train.","category":"page"},{"location":"workflow/advancedusage/#Combining-learned-and-expert-summary-statistics","page":"Advanced usage","title":"Combining learned and expert summary statistics","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"See DeepSetExpert.","category":"page"},{"location":"workflow/advancedusage/#Variable-sample-sizes","page":"Advanced usage","title":"Variable sample sizes","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"A neural estimator in the Deep Set representation can be applied to data sets of arbitrary size. However, even when the neural Bayes estimator approximates the true Bayes estimator arbitrarily well, it is conditional on the number of replicates, m, and is not necessarily a Bayes estimator for m^* ne m. Denote a data set comprising m replicates as boldsymbolZ^(m) equiv (boldsymbolZ_1 dots boldsymbolZ_m). There are at least two (non-mutually exclusive) approaches one could adopt if data sets with varying m are envisaged, which we describe below.","category":"page"},{"location":"workflow/advancedusage/#Piecewise-estimators","page":"Advanced usage","title":"Piecewise estimators","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"If data sets with varying m are envisaged, one could train l neural Bayes estimators for different sample sizes, or groups thereof (e.g., a small-sample estimator and a large-sample estimator).  Specifically, for sample-size changepoints m_1, m_2, dots, m_l-1, one could construct a piecewise neural Bayes estimator,","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"hatboldsymboltheta(boldsymbolZ^(m) boldsymbolgamma^*)\n=\nbegincases\nhatboldsymboltheta(boldsymbolZ^(m) boldsymbolgamma^*_tildem_1)  m leq m_1\nhatboldsymboltheta(boldsymbolZ^(m) boldsymbolgamma^*_tildem_2)  m_1  m leq m_2\nquad vdots \nhatboldsymboltheta(boldsymbolZ^(m) boldsymbolgamma^*_tildem_l)  m  m_l-1\nendcases","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"where, here, boldsymbolgamma^* equiv (boldsymbolgamma^*_tildem_1 dots boldsymbolgamma^*_tildem_l-1), and where boldsymbolgamma^*_tildem are the neural-network parameters optimised for sample size tildem chosen so that hatboldsymboltheta(cdot boldsymbolgamma^*_tildem) is near-optimal over the range of sample sizes in which it is applied. This approach works well in practice, and it is less computationally burdensome than it first appears when used in conjunction with pre-training.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Piecewise neural estimators are implemented with the struct, PiecewiseEstimator, and their construction is facilitated with trainx.  ","category":"page"},{"location":"workflow/advancedusage/#Training-with-variable-sample-sizes","page":"Advanced usage","title":"Training with variable sample sizes","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Alternatively, one could treat the sample size as a random variable, M, with support over a set of positive integers, mathcalM, in which case, for the neural Bayes estimator, the risk function becomes","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"R(boldsymboltheta hatboldsymboltheta(cdot boldsymbolgamma))\nequiv\nsum_m in mathcalM\nP(M=m)left(int_mathcalS^m  L(boldsymboltheta hatboldsymboltheta(boldsymbolZ^(m) boldsymbolgamma))p(boldsymbolZ^(m) mid boldsymboltheta) textd boldsymbolZ^(m)right)","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"This approach does not materially alter the workflow, except that one must also sample the number of replicates before simulating the data.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Below we define data simulation for a range of sample sizes (i.e., a range of integers) under a discrete uniform prior for M, the random variable corresponding to sample size.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"function simulate(parameters, m::R) where {R <: AbstractRange{I}} where I <: Integer\n\n\t## Number of parameter vectors stored in parameters\n\tK = size(parameters, 2)\n\n\t## Generate K sample sizes from the prior distribution for M\n\tmÃÉ = rand(m, K)\n\n\t## Pseudocode for data simulation\n\tZ = [<simulate mÃÉ[k] iid realisations from the model> for k ‚àà 1:K]\n\n\treturn Z\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Then, setting the argument m in train to be an integer range (e.g., 1:30) will train the neural estimator with the given variable sample sizes.","category":"page"},{"location":"workflow/advancedusage/#Missing-data","page":"Advanced usage","title":"Missing data","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Neural networks do not naturally handle missing data, and this property can preclude their use in a large array of applications. Here, we describe two techniques that alleviate this challenge: The one-hot-encoding approach and The neural EM algorithm.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"As a running example, we consider a Gaussian process model where the data are measured over a regular grid, but where some elements of the grid are unobserved. This situation may arise in, for example, a remote-sensing application, where the presence of cloud cover prevents measurement in some places. Below, we load the packages needed in this example, and define some aspects of the model that will remain constant throughout (e.g., the prior, the spatial domain, etc.).","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"using Distances: pairwise, Euclidean\nusing Distributions: Uniform\nusing Flux\nusing LinearAlgebra\nusing NeuralEstimators\nimport NeuralEstimators: simulate\nusing Statistics: mean\n\n\n# Set the prior distribution\nŒ© = (œÑ = Uniform(0.01, 1.0),\n\t\t œÅ = Uniform(0.01, 0.4))\n\np = length(Œ©)    # number of parameters in the statistical model\n\n# Set the (gridded) spatial domain\npoints = range(0.0, 1.0, 16)\nS = expandgrid(points, points)\n\n\n# Model information that is constant (and which will be passed into later functions)\nŒæ = (\n\tŒ© = Œ©,\n\tŒΩ = 1.0, \t# fixed smoothness\n\tS = S,\n\tD = pairwise(Euclidean(), S, S, dims = 1),\n\tp = p\n)\n\n\n# Sampler from the prior\nstruct Parameters <: ParameterConfigurations\n\tŒ∏\n\tcholesky_factors\nend\n\nfunction Parameters(K::Integer, Œæ)\n\n\t# Sample parameters from the prior\n\tŒ© = Œæ.Œ©\n\tœÑ = rand(Œ©.œÑ, K)\n\tœÅ = rand(Œ©.œÅ, K)\n\n\t# Compute Cholesky factors  \n\tcholesky_factors = maternchols(Œæ.D, œÅ, Œæ.ŒΩ)\n\n\t# Concatenate into a matrix\n\tŒ∏ = permutedims(hcat(œÑ, œÅ))\n\tŒ∏ = Float32.(Œ∏)\n\n\tParameters(Œ∏, cholesky_factors)\nend","category":"page"},{"location":"workflow/advancedusage/#The-one-hot-encoding-approach","page":"Advanced usage","title":"The one-hot-encoding approach","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"The first missing-data technique that we consider is the so-called one-hot-encoding approach of Wang et al. (2022). Their strategy involves completing the data by replacing missing values with zeros, and using auxiliary variables to encode the missingness pattern, which are also passed into the network.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Let boldsymbolZ denote the complete-data vector. Then, the one-hot-encoding approach considers inference based on boldsymbolW, a vector of indicator variables that encode the missingness pattern (with elements equal to one or zero if the corresponding element of boldsymbolZ is observed or missing, respectively), and","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"boldsymbolU equiv boldsymbolZ odot boldsymbolW","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"where odot denotes elementwise multiplication. Irrespective of the missingness pattern, boldsymbolU and boldsymbolW have the same fixed dimensions and hence may be processed easily using a single neural network. A neural point estimator is then trained on realisations of boldsymbolU boldsymbolW which, by construction, do not contain any missing elements.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Since the missingness pattern boldsymbolW is now an input to the neural network, it must be incorporated during the training phase. When interest lies in making inference from a single already-observed data set, boldsymbolW is fixed and known, and the Bayes risk remains unchanged. Amortised inference, on the other hand, requires a model for boldsymbolW, and the Bayes risk then also depends on this model. This can have substantial implications; a misspecified model for boldsymbolW will lead to a misspecified (neural) Bayes estimator and, even under correct specification, the resulting (neural) Bayes estimator may still be sub-optimal for a particular boldsymbolW, since estimators based on average-risk optimality do not, in general, minimise the risk uniformly. Nevertheless, the one-hot-encoding approach is a flexible and computationally efficient method, and below we show how it can be incorporated in the usual workflow of NeuralEstimators (see also the help files for removedata and encodedata).","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"# Marginal simulation from the data model\nfunction simulate(parameters::Parameters, m::Integer)\n\n\tK = size(parameters, 2)\n\tœÑ = parameters.Œ∏[1, :]\n\n\tZ = map(1:K) do k\n\t\tL = parameters.cholesky_factors[:, :, k]\n\t\tz = simulategaussianprocess(L, m)\n\t\tz = z + œÑ[k] * randn(size(z)...)\n\t\tz = Float32.(z)\n\t\tz = reshape(z, 16, 16, 1, :)\n\t\tz\n\tend\n\n\treturn Z\nend\n\n# Marginal simulation from the data model and a MCAR missingness model\nfunction simulatemissing(parameters::Parameters, m::Integer)\n\n\tZ = simulate(parameters, m)   # simulate completely-observed data\n\tœÄ_prior = Uniform(0.0, 1.0)   # prior for the proportion of missingness\n\n\tUW = map(Z) do z\n\t\tœÄ = rand(œÄ_prior) \t\t\t\t# sample the missingness proportion from the prior\n\t\tz = removedata(z, œÄ)\t\t\t# randomly remove a proportion œÄ of the data\n\t\tuw = encodedata(z)\t\t\t\t# replace missing entries with zero and encode missingness pattern\n\t\tuw\n\tend\n\n\treturn UW\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Next, we construct and train a neural estimator, here in the DeepSets representation. Note that the first convolutional layer takes two input channels, since we store the augmented data boldsymbolU in the first channel and the missingness pattern boldsymbolW in the second.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"œà = Chain(\n\tConv((10, 10), 2 => 16,  relu),\n\tConv((5, 5),  16 => 32,  relu),\n\tConv((3, 3),  32 => 64, relu),\n\tFlux.flatten\n\t)\nœï = Chain(Dense(64, 256, relu), Dense(256, p, exp))\nŒ∏ÃÇ = DeepSet(œà, œï)\n\nŒ∏ÃÇ = train(Œ∏ÃÇ, Parameters, simulatemissing, m = 1, Œæ = Œæ, K = 1000, epochs = 10)","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Once trained, we can apply our neural estimator to (incomplete) observed data. The data must be encoded in the same manner that was done during training.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Œ∏ = Parameters(1, Œæ)\nZ = simulate(Œ∏, 1)[1]\nZ = removedata(Z, 0.25)\t\t\t\t# remove 25% of the data\nUW = encodedata(Z)\nŒ∏ÃÇ(UW)","category":"page"},{"location":"workflow/advancedusage/#The-neural-EM-algorithm","page":"Advanced usage","title":"The neural EM algorithm","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Let boldsymbolZ_1 and boldsymbolZ_2 denote the observed and unobserved (i.e., missing) data, respectively, and let boldsymbolZ equiv (boldsymbolZ_1 boldsymbolZ_2) denote the complete data. A classical approach to facilitating inference when data are missing is the expectation-maximisation (EM) algorithm. The neural EM algorithm is a Monte Carlo variant of the EM algorithm with lth iteration,","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"boldsymboltheta^(l) = argmax_boldsymboltheta sum_h = 1^H ell(boldsymboltheta  boldsymbolZ_1  boldsymbolZ_2^(lh)) + log pi(boldsymboltheta)","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"where realisations of the missing-data component, boldsymbolZ_2^(lh)  h = 1 dots H, are sampled from the conditional probability distribution of boldsymbolZ_2 given boldsymbolZ_1 and boldsymboltheta^(l-1), and where pi(boldsymboltheta) propto omega(boldsymboltheta)^H is a concentrated version of the original prior density. Given the conditionally sampled data, the above EM update is performed using a neural Bayes estimator that is trained to approximate the MAP estimator (i.e., the posterior mode) from a set of H independent replicates of boldsymbolZ.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"First, we construct a neural approximation of the MAP estimator. When H is taken to be large, we can lean on the Bernstein-von Mises theorem to train the estimator under linear or quadratic loss; otherwise, one should train the estimator under (a surrogate for) the 0‚Äì1 loss (e.g., the kpowerloss in the limit kappa to 0).","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"œà = Chain(\n\tConv((10, 10), 1 => 16,  relu),\n\tConv((5, 5),  16 => 32,  relu),\n\tConv((3, 3),  32 => 64, relu),\n\tFlux.flatten\n\t)\nœï = Chain(\n\tDense(64, 256, relu),\n\tDense(256, p, exp)\n\t)\nneuralMAPestimator = DeepSet(œà, œï)\n\nH = 50\nneuralMAPestimator = train(neuralMAPestimator, Parameters, simulate, m = H, Œæ = Œæ, K = 1000, epochs = 10)","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Next, we define a function for conditional simulation.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"function simulateconditional(Z::M, Œ∏, Œæ; nsims::Integer = 1) where {M <: AbstractMatrix{Union{Missing, T}}} where T\n\n\t# Save the original dimensions\n\tdims = size(Z)\n\n\t# Convert to vector\n\tZ = vec(Z)\n\n\t# Compute the indices of the observed and missing data\n\tI‚ÇÅ = findall(z -> !ismissing(z), Z) # indices of observed data\n\tI‚ÇÇ = findall(z -> ismissing(z), Z)  # indices of missing data\n\tn‚ÇÅ = length(I‚ÇÅ)\n\tn‚ÇÇ = length(I‚ÇÇ)\n\n\t# Extract the observed data and drop Missing from the eltype of the container\n\tZ‚ÇÅ = Z[I‚ÇÅ]\n\tZ‚ÇÅ = [Z‚ÇÅ...]\n\n\t# Distance matrices needed for covariance matrices\n\tD   = Œæ.D # distance matrix for all locations in the grid\n\tD‚ÇÇ‚ÇÇ = D[I‚ÇÇ, I‚ÇÇ]\n\tD‚ÇÅ‚ÇÅ = D[I‚ÇÅ, I‚ÇÅ]\n\tD‚ÇÅ‚ÇÇ = D[I‚ÇÅ, I‚ÇÇ]\n\n\t# Extract the parameters from Œ∏\n\tœÑ = Œ∏[1]\n\tœÅ = Œ∏[2]\n\n\t# Compute covariance matrices\n\tŒΩ = Œæ.ŒΩ\n\tŒ£‚ÇÇ‚ÇÇ = matern.(UpperTriangular(D‚ÇÇ‚ÇÇ), œÅ, ŒΩ); Œ£‚ÇÇ‚ÇÇ[diagind(Œ£‚ÇÇ‚ÇÇ)] .+= œÑ^2\n\tŒ£‚ÇÅ‚ÇÅ = matern.(UpperTriangular(D‚ÇÅ‚ÇÅ), œÅ, ŒΩ); Œ£‚ÇÅ‚ÇÅ[diagind(Œ£‚ÇÅ‚ÇÅ)] .+= œÑ^2\n\tŒ£‚ÇÅ‚ÇÇ = matern.(D‚ÇÅ‚ÇÇ, œÅ, ŒΩ)\n\n\t# Compute the Cholesky factor of Œ£‚ÇÅ‚ÇÅ and solve the lower triangular system\n\tL‚ÇÅ‚ÇÅ = cholesky(Symmetric(Œ£‚ÇÅ‚ÇÅ)).L\n\tx = L‚ÇÅ‚ÇÅ \\ Œ£‚ÇÅ‚ÇÇ\n\n\t# Conditional covariance matrix, cov(Z‚ÇÇ ‚à£ Z‚ÇÅ, Œ∏),  and its Cholesky factor\n\tŒ£ = Œ£‚ÇÇ‚ÇÇ - x'x\n\tL = cholesky(Symmetric(Œ£)).L\n\n\t# Conditonal mean, E(Z‚ÇÇ ‚à£ Z‚ÇÅ, Œ∏)\n\ty = L‚ÇÅ‚ÇÅ \\ Z‚ÇÅ\n\tŒº = x'y\n\n\t# Simulate from the distribution Z‚ÇÇ ‚à£ Z‚ÇÅ, Œ∏ ‚àº N(Œº, Œ£)\n\tz = randn(n‚ÇÇ, nsims)\n\tZ‚ÇÇ = Œº .+ L * z\n\n\t# Combine the observed and missing data to form the complete data\n\tZ = map(1:nsims) do l\n\t\tz = Vector{T}(undef, n‚ÇÅ + n‚ÇÇ)\n\t\tz[I‚ÇÅ] = Z‚ÇÅ\n\t\tz[I‚ÇÇ] = Z‚ÇÇ[:, l]\n\t\tz\n\tend\n\tZ = stackarrays(Z, merge = false)\n\n\t# Convert Z to an array with appropriate dimensions\n\tZ = reshape(Z, dims..., 1, nsims)\n\n\treturn Z\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Now we can use the neural EM algorithm to get parameter estimates from data that contain missing values. The algorithm is implemented with the type NeuralEM.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Œ∏ = Parameters(1, Œæ)\nZ = simulate(Œ∏, 1)[1][:, :]\t\t# simulate a single gridded field\nZ = removedata(Z, 0.25)\t\t\t\t# remove 25% of the data\n\nneuralem = NeuralEM(simulateconditional, neuralMAPestimator)\nŒ∏‚ÇÄ = mean.([Œ©...]) \t\t\t\t\t\t# initial estimate, the prior mean\nneuralem(Z, Œ∏‚ÇÄ, Œæ = Œæ, nsims = H)","category":"page"},{"location":"workflow/advancedusage/#Censored-data","page":"Advanced usage","title":"Censored data","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Coming soon, based on the methodology presented in Richards et al. (2023+).","category":"page"},{"location":"workflow/overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"To develop a neural estimator with NeuralEstimators.jl,","category":"page"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"Sample parameters from the prior distribution: the parameters are stored as p times K matrices, with p the number of parameters in the model and K the number of samples (i.e., parameter configurations) in the given parameter set (i.e., training, validation, or test set).\nSimulate data from the assumed model over the parameter sets generated above. These data are stored as a Vector{A}, with each element of the vector associated with one parameter configuration, and where A depends on the representation of the neural estimator (e.g., an Array for CNN-based estimators, or a GNNGraph for GNN-based estimators).\nInitialise a neural network, Œ∏ÃÇ, that will be trained into a neural Bayes estimator (see, e.g., convenience constructor initialise_estimator).  \nTrain Œ∏ÃÇ under the chosen loss function using train.\nAssess Œ∏ÃÇ using assess. The resulting object of class Assessment can be used to assess the estimator with respect to the entire parameter space by estimating the risk function with risk, or used to plot the empirical sampling distribution of the estimator.\nApply Œ∏ÃÇ to observed data (once its performance has been checked in the above step). Bootstrap-based uncertainty quantification is facilitated with bootstrap and interval.","category":"page"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"See the Examples and, once familiar with the basic workflow, see Advanced usage for practical considerations on how to most effectively construct neural estimators.","category":"page"},{"location":"API/core/#Core","page":"Core","title":"Core","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"This page documents the functions that are central to the workflow of NeuralEstimators. Its organisation reflects the order in which these functions appear in a standard implementation; that is, from sampling parameters from the prior distribution, to uncertainty quantification of the final estimates via bootstrapping.","category":"page"},{"location":"API/core/#Sampling-parameters","page":"Core","title":"Sampling parameters","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"Parameters sampled from the prior distribution Omega(cdot) are stored as a p times K matrix, where p is the number of parameters in the model and K is the number of parameter vectors sampled from the prior distribution.","category":"page"},{"location":"API/core/","page":"Core","title":"Core","text":"It can sometimes be helpful to wrap the parameter matrix in a user-defined type that also stores expensive intermediate objects needed for data simulated (e.g., Cholesky factors). In this case, the user-defined type should be a subtype of the abstract type ParameterConfigurations, whose only requirement is a field Œ∏ that stores the matrix of parameters. See Storing expensive intermediate objects for data simulation for further discussion.   ","category":"page"},{"location":"API/core/","page":"Core","title":"Core","text":"ParameterConfigurations","category":"page"},{"location":"API/core/#NeuralEstimators.ParameterConfigurations","page":"Core","title":"NeuralEstimators.ParameterConfigurations","text":"ParameterConfigurations\n\nAn abstract supertype for user-defined types that store parameters and any intermediate objects needed for data simulation.\n\nThe user-defined type must have a field Œ∏ that stores the p √ó K matrix of parameters, where p is the number of parameters in the model and K is the number of parameter vectors sampled from the prior distribution. There are no other restrictions.\n\nSee subsetparameters for the generic function for subsetting these objects.\n\nExamples\n\nstruct P <: ParameterConfigurations\n\tŒ∏\n\t# other expensive intermediate objects...\nend\n\n\n\n\n\n","category":"type"},{"location":"API/core/#Simulating-data","page":"Core","title":"Simulating data","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"NeuralEstimators facilitates neural estimation for arbitrary statistical models by having the user implicitly define the model via simulated data. The user may provide simulated data directly, or provide a function that simulates data from the model.","category":"page"},{"location":"API/core/","page":"Core","title":"Core","text":"The data should be stored as a Vector{A}, where each element of the vector is associated with one parameter configuration, and where A depends on the architecture of the neural estimator.","category":"page"},{"location":"API/core/#Types-of-estimators","page":"Core","title":"Types of estimators","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"See also Architectures and activations functions that are often used when constructing neural estimators, and the convenience constructor initialise_estimator. ","category":"page"},{"location":"API/core/","page":"Core","title":"Core","text":"NeuralEstimator\n\nPointEstimator\n\nIntervalEstimator\n\nIntervalEstimatorCompactPrior\n\nPointIntervalEstimator\n\nQuantileEstimator\n\nPiecewiseEstimator","category":"page"},{"location":"API/core/#NeuralEstimators.NeuralEstimator","page":"Core","title":"NeuralEstimators.NeuralEstimator","text":"NeuralEstimator\n\nAn abstract supertype for neural estimators.\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.PointEstimator","page":"Core","title":"NeuralEstimators.PointEstimator","text":"PointEstimator(arch)\n\nA simple point estimator, that is, a mapping from the sample space to the parameter space, defined by the given architecture arch.\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.IntervalEstimator","page":"Core","title":"NeuralEstimators.IntervalEstimator","text":"IntervalEstimator(arch_lower, arch_upper)\nIntervalEstimator(arch)\n\nA neural interval estimator that jointly estimates credible intervals constructed as,\n\nl(Z) l(Z) + mathrmexp(u(Z))\n\nwhere l() and u() are the neural networks arch_lower and arch_upper, both of which should transform data into p-dimensional vectors, where p is the number of parameters in the statistical model. If only a single neural network architecture arch is provided, it will be used for both arch_lower and arch_upper.\n\nThe returned value is a matrix with 2p rows, where the first and second p rows correspond to estimates of the lower and upper bound, respectively.\n\nSee also IntervalEstimatorCompactPrior.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\n# Generate some toy data\nn = 2   # bivariate data\nm = 100 # number of independent replicates\nZ = rand(n, m)\n\n# Create an architecture\np = 3  # number of parameters in the statistical model\nw = 8  # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\narchitecture = DeepSet(œà, œï)\n\n# Initialise the interval estimator\nestimator = IntervalEstimator(architecture)\n\n# Apply the interval estimator\nestimator(Z)\ninterval(estimator, Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.IntervalEstimatorCompactPrior","page":"Core","title":"NeuralEstimators.IntervalEstimatorCompactPrior","text":"IntervalEstimatorCompactPrior(u, v, min_supp::Vector, max_supp::Vector)\nIntervalEstimatorCompactPrior(u, v, compress::Compress)\n\nUses the neural networks u and v to jointly estimate credible intervals that are guaranteed to be within the support of the prior distributon. This support is defined by the p-dimensional vectors min_supp and max_supp (or a single p-dimensional object of type Compress), where p is the number of parameters in the statistical model.\n\nGiven data Z, the intervals are constructed as\n\ng(u(Z)) \tg(u(Z)) + mathrmexp(v(Z)))\n\nwhere\n\nu() and v() are neural networks, both of which should transform data into p-dimensional vectors;\ng() is a logistic function that maps its input to the prior support.\n\nNote that, in addition to ensuring that the interval remains in the prior support, this constructions also ensures that the intervals are valid (i.e., it prevents quantile crossing, in the sense that the upper bound is always greater than the lower bound).\n\nThe returned value is a matrix with 2p rows, where the first and second p rows correspond to estimates of the lower and upper bound, respectively.\n\nSee also IntervalEstimator and Compress.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\n# prior support\nmin_supp = [25, 0.5, -pi/2]\nmax_supp = [500, 2.5, 0]\np = length(min_supp)  # number of parameters in the statistical model\n\n# Generate some toy data\nn = 2   # bivariate data\nm = 100 # number of independent replicates\nZ = rand(n, m)\n\n# Create an architecture\nw = 8  # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\nu = DeepSet(œà, œï)\nv = deepcopy(u) # use the same architecture for both u and v\n\n# Initialise the interval estimator\nestimator = IntervalEstimatorCompactPrior(u, v, min_supp, max_supp)\n\n# Apply the interval estimator\nestimator(Z)\ninterval(estimator, Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.PointIntervalEstimator","page":"Core","title":"NeuralEstimators.PointIntervalEstimator","text":"PointIntervalEstimator(arch_point, arch_lower, arch_upper)\nPointIntervalEstimator(arch_point, arch_bound)\nPointIntervalEstimator(arch)\n\nA neural estimator that jointly produces point estimates, Œ∏ÃÇ(Z), where Œ∏ÃÇ(Z) is a neural point estimator with architecture arch_point, and credible intervals constructed as,\n\nŒ∏(Z) - mathrmexp(l(Z)) Œ∏(Z) + mathrmexp(u(Z))\n\nwhere l() and u() are the neural networks arch_lower and arch_upper, both of which should transform data into p-dimensional vectors, where p is the number of parameters in the statistical model.\n\nIf only a single neural network architecture arch is provided, it will be used for all architectures; similarly, if two architectures are provided, the second will be used for both arch_lower and arch_upper.\n\nInternally, the point estimates, lower-bound estimates, and upper-bound estimates are concatenated, so that PointIntervalEstimator objects transform data into matrices with 3p rows.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\n# Generate some toy data\nn = 2   # bivariate data\nm = 100 # number of independent replicates\nZ = rand(n, m)\n\n# Create an architecture\np = 3  # number of parameters in the statistical model\nw = 8  # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\narchitecture = DeepSet(œà, œï)\n\n# Initialise the estimator\nestimator = PointIntervalEstimator(architecture)\n\n# Apply the estimator\nestimator(Z)\ninterval(estimator, Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.QuantileEstimator","page":"Core","title":"NeuralEstimators.QuantileEstimator","text":"QuantileEstimator()\n\nComing soon: this structure will allow for the simultaneous estimation of an arbitrary number of marginal quantiles of the posterior distribution.\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.PiecewiseEstimator","page":"Core","title":"NeuralEstimators.PiecewiseEstimator","text":"PiecewiseEstimator(estimators, breaks)\n\nCreates a piecewise estimator from a collection of estimators, based on the collection of changepoints, breaks, which should contain one element fewer than the number of estimators.\n\nAny estimator can be included in estimators, including any of the subtypes of NeuralEstimator exported with the package NeuralEstimators (e.g., PointEstimator, IntervalEstimator, etc.).\n\nExamples\n\n# Suppose that we've trained two neural estimators. The first, Œ∏ÃÇ‚ÇÅ, is trained\n# for small sample sizes (e.g., m ‚â§ 30), and the second, `Œ∏ÃÇ‚ÇÇ`, is trained for\n# moderate-to-large sample sizes (e.g., m > 30). We construct a piecewise\n# estimator with a sample-size changepoint of 30, which dispatches Œ∏ÃÇ‚ÇÅ if m ‚â§ 30\n# and Œ∏ÃÇ‚ÇÇ if m > 30.\n\nusing NeuralEstimators\nusing Flux\n\nn = 2  # bivariate data\np = 3  # number of parameters in the statistical model\nw = 8  # width of each layer\n\nœà‚ÇÅ = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï‚ÇÅ = Chain(Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ‚ÇÅ = DeepSet(œà‚ÇÅ, œï‚ÇÅ)\n\nœà‚ÇÇ = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï‚ÇÇ = Chain(Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ‚ÇÇ = DeepSet(œà‚ÇÇ, œï‚ÇÇ)\n\nŒ∏ÃÇ = PiecewiseEstimator([Œ∏ÃÇ‚ÇÅ, Œ∏ÃÇ‚ÇÇ], [30])\nZ = [rand(n, 1, m) for m ‚àà (10, 50)]\nŒ∏ÃÇ(Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#Training","page":"Core","title":"Training","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"The function train is used to train a single neural estimator, while the wrapper function trainx is useful for training multiple neural estimators over a range of sample sizes, making using of the technique known as pre-training.","category":"page"},{"location":"API/core/","page":"Core","title":"Core","text":"train\n\ntrainx","category":"page"},{"location":"API/core/#NeuralEstimators.train","page":"Core","title":"NeuralEstimators.train","text":"train(Œ∏ÃÇ, sampler::Function, simulator::Function; ...)\ntrain(Œ∏ÃÇ, Œ∏_train::P, Œ∏_val::P, simulator::Function; ...) where {P <: Union{AbstractMatrix, ParameterConfigurations}}\ntrain(Œ∏ÃÇ, Œ∏_train::P, Œ∏_val::P, Z_train::T, Z_val::T; ...) where {T, P <: Union{AbstractMatrix, ParameterConfigurations}}\n\nTrain a neural estimator Œ∏ÃÇ.\n\nThe methods cater for different variants of \"on-the-fly\" simulation. Specifically, a sampler can be provided to continuously sample new parameter vectors from the prior, and a simulator can be provided to continuously simulate new data conditional on the parameters. If provided with specific sets of parameters (Œ∏_train and Œ∏_val) and/or data (Z_train and Z_val), they will be held fixed during training.\n\nIn all methods, the validation parameters and data are held fixed to reduce noise when evaluating the validation risk.\n\nKeyword arguments common to all methods:\n\nloss = mae\nepochs::Integer = 100\nbatchsize::Integer = 32\noptimiser = ADAM(1e-4)\nsavepath::String = \"\": path to save the neural-network weights during training (as bson files) and other information, such as the risk vs epoch (the risk function evaluated over the training and validation sets are saved in the first and second columns of loss_per_epoch.csv). If savepath is an empty string (default), nothing is saved.\nstopping_epochs::Integer = 5: cease training if the risk doesn't improve in this number of epochs.\nuse_gpu::Bool = true\nverbose::Bool = true\n\nKeyword arguments common to train(Œ∏ÃÇ, sampler, simulator) and train(Œ∏ÃÇ, Œ∏_train, Œ∏_val, simulator):\n\nm: sample sizes (either an Integer or a collection of Integers). The simulator is called as simulator(Œ∏, m).\nepochs_per_Z_refresh::Integer = 1: how often to refresh the training data.\nsimulate_just_in_time::Bool = false: flag indicating whether we should simulate just-in-time, in the sense that only a batchsize number of parameter vectors and corresponding data are in memory at a given time.\n\nKeyword arguments unique to train(Œ∏ÃÇ, sampler, simulator):\n\nK::Integer = 10000: number of parameter vectors in the training set; the size of the validation set is K √∑ 5.\nŒæ = nothing: an arbitrary collection of objects that are fixed (e.g., distance matrices). If provided, the parameter sampler is called as sampler(K, Œæ); otherwise, the parameter sampler will be called as sampler(K). Can also be provided as xi.\nepochs_per_Œ∏_refresh::Integer = 1: how often to refresh the training parameters. Must be a multiple of epochs_per_Z_refresh. Can also be provided as epochs_per_theta_refresh.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\nimport NeuralEstimators: simulate\n\n# parameter sampler\nfunction sampler(K)\n\tŒº = randn(K) # Gaussian prior\n\tœÉ = rand(K)  # Uniform prior\n\tŒ∏ = hcat(Œº, œÉ)'\n\treturn Œ∏\nend\n\n# data simulator\nsimulator(Œ∏_matrix, m) = [Œ∏[1] .+ Œ∏[2] * randn(1, m) for Œ∏ ‚àà eachcol(Œ∏_matrix)]\n\n# architecture\np = length(Œ©)   # number of parameters in the statistical model\nw = 32          # width of each layer\nœà = Chain(Dense(1, w, relu), Dense(w, w, relu))\nœï = Chain(Dense(w, w, relu), Dense(w, p))\nŒ∏ÃÇ = DeepSet(œà, œï)\n\n# number of independent replicates to use during training\nm = 15\n\n# training: full simulation on-the-fly\nŒ∏ÃÇ = train(Œ∏ÃÇ, sampler, simulate, m = m, epochs = 5)\n\n# training: simulation on-the-fly with fixed parameters\nK = 10000\nŒ∏_train = sampler(K)\nŒ∏_val   = sampler(K √∑ 5)\nŒ∏ÃÇ \t\t = train(Œ∏ÃÇ, Œ∏_train, Œ∏_val, simulate, m = m, epochs = 5)\n\n# training: fixed parameters and fixed data\nZ_train = simulate(Œ∏_train, m)\nZ_val   = simulate(Œ∏_val, m)\nŒ∏ÃÇ \t\t = train(Œ∏ÃÇ, Œ∏_train, Œ∏_val, Z_train, Z_val, epochs = 5)\n\n\n\n\n\n","category":"function"},{"location":"API/core/#NeuralEstimators.trainx","page":"Core","title":"NeuralEstimators.trainx","text":"trainx(Œ∏ÃÇ, sampler::Function, simulator::Function, m::Vector{Integer}; ...)\ntrainx(Œ∏ÃÇ, Œ∏_train, Œ∏_val, simulator::Function, m::Vector{Integer}; ...)\ntrainx(Œ∏ÃÇ, Œ∏_train, Œ∏_val, Z_train, Z_val, m::Vector{Integer}; ...)\ntrainx(Œ∏ÃÇ, Œ∏_train, Œ∏_val, Z_train::V, Z_val::V; ...) where {V <: AbstractVector{AbstractVector{Any}}}\n\nA wrapper around train() to construct neural estimators for different sample sizes.\n\nThe positional argument m specifies the desired sample sizes. Each estimator is pre-trained with the estimator for the previous sample size. For example, if m = [m‚ÇÅ, m‚ÇÇ], the estimator for sample size m‚ÇÇ is pre-trained with the estimator for sample size m‚ÇÅ.\n\nThe method for Z_train and Z_val subsets the data using subsetdata(Z, 1:m·µ¢) for each m·µ¢ ‚àà m. The method for Z_train::V and Z_val::V trains an estimator for each element of Z_train::V and Z_val::V and, hence, it does not need to invoke subsetdata(), which can be slow or difficult to define in some cases (e.g., for graphical data). Note that, in this case, m is inferred from the data.\n\nThe keyword arguments inherit from train(). The keyword arguments epochs, batchsize, stopping_epochs, and optimiser can each be given as vectors. For example, if we are training two estimators, we can use a different number of epochs for each estimator by providing epochs = [epoch‚ÇÅ, epoch‚ÇÇ].\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Assessing-a-neural-estimator","page":"Core","title":"Assessing a neural estimator","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"assess\n\nAssessment\n\nrisk","category":"page"},{"location":"API/core/#NeuralEstimators.assess","page":"Core","title":"NeuralEstimators.assess","text":"assess(estimators, Œ∏, Z; <keyword args>)\n\nUsing a collection of estimators, compute estimates from data Z simulated based on true parameter vectors stored in Œ∏.\n\nIf Z contains more data sets than parameter vectors, the parameter matrix will be recycled by horizontal concatenation.\n\nThe output is of type Assessment; see ?Assessment for details.\n\nKeyword arguments\n\nestimator_names::Vector{String}: names of the estimators (sensible defaults provided).\nparameter_names::Vector{String}: names of the parameters (sensible defaults provided). If Œæ is provided with a field parameter_names, those names will be used.\nŒæ = nothing: an arbitrary collection of objects that are fixed (e.g., distance matrices). Can also be provided as xi.\nuse_Œæ = false: a Bool or a collection of Bool objects with length equal to the number of estimators. Specifies whether or not the estimator uses Œæ: if it does, the estimator will be applied as estimator(Z, Œæ). This argument is useful when multiple estimators are provided, only some of which need Œæ; hence, if only one estimator is provided and Œæ is not nothing, use_Œæ is automatically set to true. Can also be provided as use_xi.\nuse_gpu = true: a Bool or a collection of Bool objects with length equal to the number of estimators.\nverbose::Bool = true\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\nn = 10 # number of observations in each realisation\np = 4  # number of parameters in the statistical model\n\n# Construct the neural estimator\nw = 32 # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ = DeepSet(œà, œï)\n\n# Generate testing parameters\nK = 100\nŒ∏ = rand(p, K)\n\n# Data for a single sample size\nm = 30\nZ = [rand(n, m) for _ ‚àà 1:K];\nassessment = assess([Œ∏ÃÇ], Œ∏, Z);\nrisk(assessment)\n\n# Multiple data sets for each parameter vector\nJ = 5\nZ = repeat(Z, J);\nassessment = assess([Œ∏ÃÇ], Œ∏, Z);\nrisk(assessment)\n\n# With set-level information\nq‚Çì = 2\nœï  = Chain(Dense(w + q‚Çì, w, relu), Dense(w, p));\nŒ∏ÃÇ = DeepSet(œà, œï)\nx = [rand(q‚Çì) for _ ‚àà eachindex(Z)]\nassessment = assess([Œ∏ÃÇ], Œ∏, (Z, x));\nrisk(assessment)\n\n\n\n\n\n","category":"function"},{"location":"API/core/#NeuralEstimators.Assessment","page":"Core","title":"NeuralEstimators.Assessment","text":"Assessment(df::DataFrame, runtime::DataFrame)\n\nA type for storing the output of assess(). The field runtime contains the total time taken for each estimator. The field df is a long-form DataFrame with columns:\n\nestimator: the name of the estimator\nparameter: the name of the parameter\ntruth:     the true value of the parameter\nestimate:  the estimated value of the parameter\nm:         the sample size (number of iid replicates)\nk:         the index of the parameter vector in the test set\nj:         the index of the data set\n\nMultiple Assessment objects can be combined with merge().\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.risk","page":"Core","title":"NeuralEstimators.risk","text":"risk(assessment::Assessment; loss = (x, y) -> abs(x - y), average_over_parameters = true)\n\nComputes a Monte Carlo approximation of the Bayes risk,\n\nr_Omega(hatboldsymboltheta(cdot))\napprox\nfrac1K sum_boldsymboltheta in vartheta frac1J sum_boldsymbolZ in mathcalZ_boldsymboltheta L(boldsymboltheta hatboldsymboltheta(boldsymbolZ))\n\nwhere vartheta denotes a set of K parameter vectors sampled from the prior Omega(cdot) and, for each boldsymboltheta in vartheta, we have J sets of m mutually independent realisations from the model collected in mathcalZ_boldsymboltheta.\n\nKeyword arguments\n\nloss = (x, y) -> abs(x - y): a binary operator defining the loss function (default absolute-error loss).\naverage_over_parameters::Bool = true: if true (default), the loss is averaged over all parameters; otherwise, the loss is averaged over each parameter separately.\naverage_over_sample_sizes::Bool = true: if true (default), the loss is averaged over all sample sizes m; otherwise, the loss is averaged over each sample size separately.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Bootstrapping","page":"Core","title":"Bootstrapping","text":"","category":"section"},{"location":"API/core/","page":"Core","title":"Core","text":"bootstrap\n\ninterval","category":"page"},{"location":"API/core/#NeuralEstimators.bootstrap","page":"Core","title":"NeuralEstimators.bootstrap","text":"bootstrap(Œ∏ÃÇ, parameters::P, Z) where P <: Union{AbstractMatrix, ParameterConfigurations}\nbootstrap(Œ∏ÃÇ, parameters::P, simulator, m::Integer; B = 400) where P <: Union{AbstractMatrix, ParameterConfigurations}\nbootstrap(Œ∏ÃÇ, Z; B = 400, blocks = nothing)\n\nGenerates B bootstrap estimates from an estimator Œ∏ÃÇ.\n\nParametric bootstrapping is facilitated by passing a single parameter configuration, parameters, and corresponding simulated data, Z, whose length implicitly defines B. Alternatively, one may provide a simulator and the desired sample size, in which case the data will be simulated using simulator(parameters, m).\n\nNon-parametric bootstrapping is facilitated by passing a single data set, Z. The argument blocks caters for block bootstrapping, and it should be a vector of integers specifying the block for each replicate. For example, with 5 replicates, the first two corresponding to block 1 and the remaining three corresponding to block 2, blocks should be [1, 1, 2, 2, 2]. The resampling algorithm aims to produce resampled data sets that are of a similar size to Z, but this can only be achieved exactly if all blocks are equal in length.\n\nThe keyword argument use_gpu is a flag determining whether to use the GPU, if it is available (default true).\n\nThe return type is a p √ó B matrix, where p is the number of parameters in the model.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#NeuralEstimators.interval","page":"Core","title":"NeuralEstimators.interval","text":"interval(Œ∏ÃÉ, Œ∏ÃÇ = nothing; type::String, probs = [0.05, 0.95], parameter_names)\n\nCompute a confidence interval using the p √ó B matrix of bootstrap samples, Œ∏ÃÉ, where p is the number of parameters in the model.\n\nIf type = \"quantile\", the interval is constructed by simply taking the quantiles of Œ∏ÃÉ, and if type = \"reverse-quantile\", the so-called reverse-quantile method is used. In both cases, the quantile levels are controlled by the argument probs.\n\nThe rows can be named with a vector of strings parameter_names.\n\nThe return type is a p √ó 2 matrix, whose first and second columns respectively contain the lower and upper bounds of the interval.\n\nExamples\n\nusing NeuralEstimators\np = 3\nB = 50\nŒ∏ÃÉ = rand(p, B)\nŒ∏ÃÇ = rand(p)\ninterval(Œ∏ÃÉ)\ninterval(Œ∏ÃÉ, Œ∏ÃÇ, type = \"basic\")\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#Miscellaneous","page":"Miscellaneous","title":"Miscellaneous","text":"","category":"section"},{"location":"API/utility/","page":"Miscellaneous","title":"Miscellaneous","text":"Order = [:type, :function]\nPages   = [\"utility.md\"]","category":"page"},{"location":"API/utility/#Core","page":"Miscellaneous","title":"Core","text":"","category":"section"},{"location":"API/utility/","page":"Miscellaneous","title":"Miscellaneous","text":"These functions can appear during the core workflow, and may need to be overloaded in some applications.","category":"page"},{"location":"API/utility/","page":"Miscellaneous","title":"Miscellaneous","text":"numberreplicates\n\nsubsetdata\n\nsubsetparameters","category":"page"},{"location":"API/utility/#NeuralEstimators.numberreplicates","page":"Miscellaneous","title":"NeuralEstimators.numberreplicates","text":"numberofreplicates(Z)\n\nGeneric function that returns the number of replicates in a given object. Default implementations are provided for commonly used data formats, namely, data stored as an Array or as a GNNGraph.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.subsetdata","page":"Miscellaneous","title":"NeuralEstimators.subsetdata","text":"Generic function for subsetting replicates from a data set. Default methods are:\n\nsubsetdata(Z::A, m) where {A <: AbstractArray{T, N}} where {T, N}\nsubsetdata(Z::G, m) where {G <: AbstractGraph}\n\nNote that subsetdata is slow for graphical data, and one should consider using a method of train that does not require the data to be subsetted when working with graphical data: use numberreplicates to check that the training and validation data sets are equally replicated, which prevents the invocation of subsetdata. Note also that subsetdata only applies to vectors of batched graphs.\n\nIf the user is working with data that is not covered by the default methods, simply overload subsetdata with the appropriate type for Z.\n\nExamples\n\nusing NeuralEstimators\nusing GraphNeuralNetworks\nusing Flux: batch\n\nn = 5  # number of observations in each realisation\nm = 6  # number of replicates for each parameter vector\nd = 1  # dimension of the response variable\nK = 2  # number of parameter vectors\n\n# Array data\nZ = [rand(n, d, m) for k ‚àà 1:K]\nsubsetdata(Z, 1:3) # extract first 3 replicates for each parameter vector\n\n# Graphical data\ne = 8 # number of edges\nZ = [batch([rand_graph(n, e, ndata = rand(d, n)) for _ ‚àà 1:m]) for k ‚àà 1:K]\nsubsetdata(Z, 1:3) # extract first 3 replicates for each parameter vector\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.subsetparameters","page":"Miscellaneous","title":"NeuralEstimators.subsetparameters","text":"subsetparameters(parameters::M, indices) where {M <: AbstractMatrix}\nsubsetparameters(parameters::P, indices) where {P <: ParameterConfigurations}\n\nSubset parameters using a collection of indices.\n\nArrays in parameters::P with last dimension equal in size to the number of parameter configurations, K, are also subsetted (over their last dimension) using indices. All other fields are left unchanged. To modify this default behaviour, overload subsetparameters.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#Utility-functions","page":"Miscellaneous","title":"Utility functions","text":"","category":"section"},{"location":"API/utility/","page":"Miscellaneous","title":"Miscellaneous","text":"adjacencymatrix\n\ncontainertype\n\nencodedata\n\nestimateinbatches\n\nexpandgrid\n\ninitialise_estimator\n\nloadbestweights\n\nremovedata\n\nstackarrays\n\nvectotril","category":"page"},{"location":"API/utility/#NeuralEstimators.adjacencymatrix","page":"Miscellaneous","title":"NeuralEstimators.adjacencymatrix","text":"adjacencymatrix(M::Matrix, k::Integer)\nadjacencymatrix(M::Matrix, r::Float)\nadjacencymatrix(M::Matrix, r::Float, k::Integer)\n\nComputes a spatially weighted adjacency matrix from M based on either the k nearest neighbours of each location, or a fixed spatial radius of r units; if both r and k are provided, randomly selects k neighbours within a radius of r units.\n\nIf M is a square matrix, is it treated as a distance matrix; otherwise, it should be an n x d matrix, where n is the number of spatial sample locations and d is the spatial dimension (typically d = 2). In the latter case, the distance metric is taken to be the Euclidean distance.\n\nAll methods accept the keyword argument self_loops (default false); set to true nodes are considered to self connected, so that the diagonal of the adjacency matrix is non-zero.\n\nSee also the package NearestNeighbors.jl.\n\nExamples\n\nusing NeuralEstimators\nusing Distances\n\nn = 100\nd = 2\nS = rand(n, d)\nk = 5\nr = 0.3\n\n# Memory efficient constructors (avoids constructing the full distance matrix D)\nadjacencymatrix(S, k)\nadjacencymatrix(S, r)\nadjacencymatrix(S, r, k)\n\n# Construct from full distance matrix D\nD = pairwise(Euclidean(), S, S, dims = 1)\nadjacencymatrix(D, k)\nadjacencymatrix(D, r)\nadjacencymatrix(D, r, k)\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.containertype","page":"Miscellaneous","title":"NeuralEstimators.containertype","text":"containertype(A::Type)\ncontainertype(::Type{A}) where A <: SubArray\ncontainertype(a::A) where A\n\nReturns the container type of its argument.\n\nIf given a SubArray, returns the container type of the parent array.\n\nExamples\n\na = rand(3, 4)\ncontainertype(a)\ncontainertype(typeof(a))\n[containertype(x) for x ‚àà eachcol(a)]\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.encodedata","page":"Miscellaneous","title":"NeuralEstimators.encodedata","text":"encodedata(Z::A; fixed_constant::T = zero(T)) where {A <: AbstractArray{Union{Missing, T}, N}} where T, N\n\nFor data Z with missing entries, returns an augmented data set (U, W) where W encodes the missingness pattern as an indicator vector and U is the original data Z with missing entries replaced by a fixed_constant.\n\nThe indicator vector W is stored in the second-to-last dimension of Z, which should be a singleton. If the second-to-last dimension is not singleton, then two singleton dimensions will be added to the array, and W will be stored in the new second-to-last dimension.\n\nExamples\n\nusing NeuralEstimators\n\n# Generate some missing data\nZ = rand(16, 16, 1, 1)\nZ = removedata(Z, 0.25)\t # remove 25% of the data\n\n# Encode the data\nUW = encodedata(Z)\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.estimateinbatches","page":"Miscellaneous","title":"NeuralEstimators.estimateinbatches","text":"estimateinbatches(Œ∏ÃÇ, z; batchsize::Integer = 32, use_gpu::Bool = true)\n\nApply the estimator Œ∏ÃÇ on minibatches of z of size batchsize, to avoid memory issues that can occur when z is very large.\n\nMinibatching will only be done if there are multiple data sets in z; this will be inferred by z being a vector, or a tuple whose first element is a vector.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.expandgrid","page":"Miscellaneous","title":"NeuralEstimators.expandgrid","text":"expandgrid(xs, ys)\n\nSame as expand.grid() in R, but currently caters for two dimensions only.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.initialise_estimator","page":"Miscellaneous","title":"NeuralEstimators.initialise_estimator","text":"initialise_estimator(p::Integer; ...)\n\nInitialise a neural estimator for a statistical model with p unknown parameters.\n\nThe estimator is couched in the DeepSets framework so that it can be applied to data with an arbitrary number of independent replicates (including the special case of a single replicate).\n\nKeyword arguments\n\narchitecture::String: for unstructured data, one may use a densely-connected neural network (\"DNN\"); for data collected over a grid, a convolutional neural network (\"CNN\"); and for graphical or irregular spatial data, a graphical neural network (\"GNN\").\nd::Integer = 1: dimension of the response variable (e.g., d = 1 for univariate processes).\nestimator_type::String = \"point\": the type of estimator; either \"point\" or \"interval\".\ndepth = 3: the number of hidden layers. Either a single integer or an integer vector of length two specifying the depth of inner (summary) and outer (inference) network of the DeepSets framework. Since there is an input and an output layer, the total number of layers in is sum(depth) + 2.\nwidth = 32: a single integer or an integer vector of length sum(depth) specifying the width (or number of convolutional filters/channels) in each layer.\nactivation::Function = relu: the (non-linear) activation function of each hidden layer.\nactivation_final::Function = relu: the activation function of the output layer.\nkernel_size: (applicable only to CNNs) a vector of length depth[1] containing integer tuples of length D, where D is the dimension of the convolution (e.g., D = 2 for two-dimensional convolution).\nweight_by_distance::Bool = false: (applicable only to GNNs) flag indicating whether the estimator will weight by spatial distance; if true, a WeightedGraphConv layer is used in the propagation module; otherwise, a regular GraphConv layer is used.\n\nExamples\n\np = 2\ninitialise_estimator(p, architecture = \"DNN\")\ninitialise_estimator(p, architecture = \"GNN\")\ninitialise_estimator(p, architecture = \"CNN\", kernel_size = [(10, 10), (5, 5), (3, 3)])\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.loadbestweights","page":"Miscellaneous","title":"NeuralEstimators.loadbestweights","text":"loadbestweights(path::String)\n\nReturns the weights of the neural network saved as 'best_network.bson' in the given path.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.removedata","page":"Miscellaneous","title":"NeuralEstimators.removedata","text":"removedata(Z::A, p::Float; prevent_complete_missing = true) where {A <: AbstractArray{T, N}}\nremovedata(Z::A, p::Vector{Float}; prevent_complete_missing = true) where {A <: AbstractArray{T, N}}\nremovedata(Z::A, n::Integer; fixed_pattern = false, contiguous_pattern = false) where {A <: AbstractArray{T, N}}\nremovedata(Z::A, I·µ§::V) where {A <: AbstractArray{T, N}, V <: AbstractVector{I}} where {T, N, I <: Integer}\n\nReplaces some elements of Z with missing.\n\nA vector of probabilities p may be given that specifies the probability for each element in the response vector: hence, p should have length equal to the dimension of the response vector. If a single probability is given, it will be replicated accordingly. If prevent_complete_missing = true, no replicates will contain 100% missingness: note that this can slightly modify the effective value of p.\n\nAlternatively, if a single integer n is provided, all replicates will contain n observations after the data are removed. If fixed_pattern = true, the missingness pattern is fixed for all replicates. If contiguous_pattern = true, the data will be removed in a contiguous block. If variable_proportion = true, the proportion of missingness will vary across replicates, with each replicate containing between 1 and n observations after data removal, sampled uniformly: note that variable_proportion overrides fixed_pattern.\n\nAlternatively, one may provide an array of integers I·µ§ that give the indices of the data to be removed.\n\nThe return type is Array{Union{T, Missing}}.\n\nExamples\n\nd = 5     # dimension of each replicate\nn = 3     # number of observed elements of each replicate: must have n <= d\nm = 2000  # number of replicates\nZ = rand(d, m)\n\nremovedata(Z, n)\nremovedata(Z, n; fixed_pattern = true)\nremovedata(Z, n; contiguous_pattern = true)\nremovedata(Z, n, variable_proportion = true)\nremovedata(Z, n; contiguous_pattern = true, fixed_pattern = true)\nremovedata(Z, n; contiguous_pattern = true, variable_proportion = true)\n\n# Passing the proportion of missingness:\np = rand(d)\nremovedata(Z, p)\n# Check that the probability of missingness is roughly correct:\nmapslices(x -> sum(ismissing.(x))/length(x), removedata(Z, p), dims = 2)\n# Check that none of the replicates contain 100% missing:\nd ‚àà unique(mapslices(x -> sum(ismissing.(x)), removedata(Z, p), dims = 1))\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.stackarrays","page":"Miscellaneous","title":"NeuralEstimators.stackarrays","text":"stackarrays(v::V; merge = true) where {V <: AbstractVector{A}} where {A <: AbstractArray{T, N}} where {T, N}\n\nStack a vector of arrays v along the last dimension of each array, optionally merging the final dimension of the stacked array.\n\nThe arrays must be of the same size for the first N-1 dimensions. However, if merge = true, the size of the final dimension can vary.\n\nExamples\n\n# Vector containing arrays of the same size:\nZ = [rand(2, 3, m) for m ‚àà (1, 1)];\nstackarrays(Z)\nstackarrays(Z, merge = false)\n\n# Vector containing arrays with differing final dimension size:\nZ = [rand(2, 3, m) for m ‚àà (1, 2)];\nstackarrays(Z)\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.vectotril","page":"Miscellaneous","title":"NeuralEstimators.vectotril","text":"vectotril(v; strict = false)\nvectotriu(v; strict = false)\n\nConverts a vector v of length d(d+1)2 (a triangular number) into a d  d lower or upper triangular matrix.\n\nIf strict = true, the matrix will be strictly lower or upper triangular, that is, a (d+1)  (d+1) triangular matrix with zero diagonal.\n\nNote that the triangular matrix is constructed on the CPU, but the returned matrix will be a GPU array if v is a GPU array. Note also that the return type is not of type Triangular matrix (i.e., the zeros are materialised) since Traingular matrices are not always compatible with other GPU operations.\n\nExamples\n\nusing NeuralEstimators\n\nd = 4\nn = d*(d+1)√∑2\nv = collect(range(1, n))\nvectotril(v)\nvectotriu(v)\nvectotril(v; strict = true)\nvectotriu(v; strict = true)\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#Other","page":"Miscellaneous","title":"Other","text":"","category":"section"},{"location":"API/utility/","page":"Miscellaneous","title":"Miscellaneous","text":"NeuralEM","category":"page"},{"location":"API/utility/#NeuralEstimators.NeuralEM","page":"Miscellaneous","title":"NeuralEstimators.NeuralEM","text":"NeuralEM(simulateconditional::Function, neuralMAP::NeuralPointEstimator, Œ∏‚ÇÄ = nothing)\n\nA type that implements the neural expectation-maximisation (EM) algorithm using a function for conditional simulation over the missing values (simulateconditional), a neural approximation of the MAP estimator (neuralMAP), and a vector of starting parameter values (Œ∏‚ÇÄ).\n\nFields of NeuralEM objects\n\nThe function simulateconditional should be of the form,\n\nsimulateconditional(Z::A, Œ∏, Œæ = nothing; nsims::Integer = 1) where {A <: AbstractArray{Union{Missing, T}}} where T\n\nThe data Z should be returned in whatever form is amenable to the architecture of the neural MAP estimator. For instance, if the data are gridded and the neural MAP estimator is based on a CNN architecture, then Z should be returned as a four-dimensional array.\n\nThe neuralMAP estimator should be a neural point estimator trained to approximate the joint posterior mode.\n\nThe starting value Œ∏‚ÇÄ should be a vector, and it can be provided either during construction of the NeuralEM object, or when applying the NeuralEM object to data (see below). The starting values given in a function call take precedence over those stored in the object.\n\nMethods\n\nOnce constructed, obects of type NeuralEM can be applied to data via the method,\n\n(neuralem::NeuralEM)(\n\tZ::A, Œ∏‚ÇÄ = nothing;\n\tniterations::Integer = 50,\n\tnsims::Integer = 1,\n\tŒæ = nothing,\n\tœµ = 0.01,\n\treturn_iterates::Bool = false,\n\tuse_gpu::Bool = true,\n\tverbose::Bool = false\n)  where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}\n\nThe key arguments are:\n\nZ: the complete-data vector containing the observed data Z‚ÇÅ and Missing values in the missing component Z‚ÇÇ. The last dimension contains the replicates (if any); the other dimensions store the response variable.\nŒ∏‚ÇÄ: starting parameter values.\nniterations: the maximum number of iterations to apply the algorithm for.\nnsims: the number of conditional replicates used to approximate the conditional expectation (should align with the number of replicates that was used during training of the neural MAP estimator).\nŒæ: model information needed for conditional simulation (e.g., distance matrices).\nœµ: tolerance used to assess convergence.\nreturn_iterates: if true, the estimate at each iteration of the algorithm is returned; otherwise, only the final estimate is returned.\n\nThe algorithm is stopped after niterations iterations or if the relative change in parameter values from successive iterations is sufficiently small, specifically, if\n\nmax_k (Œ∏_k^(l+1) - Œ∏_k^(l)  Œ∏_k^(l))  œµ\n\nThe following wrapper can be used when one has multiple data sets:\n\n(neuralem::NeuralEM)(Z::V, Œ∏‚ÇÄ::Union{Vector, Matrix, Nothing} = nothing; args...) where {V <: AbstractVector{A}} where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}\n\nHere, the starting values Œ∏‚ÇÄ will be repeated if given as a vector.\n\nExamples\n\n# Please see the example given in the main documentation.\n\n\n\n\n\n","category":"type"},{"location":"API/loss/#Loss-functions","page":"Loss functions","title":"Loss functions","text":"","category":"section"},{"location":"API/loss/","page":"Loss functions","title":"Loss functions","text":"In addition to the standard loss functions provided by Flux (e.g., mae, mse, etc.), NeuralEstimators provides the following loss functions.","category":"page"},{"location":"API/loss/","page":"Loss functions","title":"Loss functions","text":"kpowerloss\n\nquantileloss\n\nintervalscore","category":"page"},{"location":"API/loss/#NeuralEstimators.kpowerloss","page":"Loss functions","title":"NeuralEstimators.kpowerloss","text":"kpowerloss(Œ∏ÃÇ, y, k; agg = mean, joint = true, safeorigin = true, œµ = 0.1)\n\nFor k ‚àà (0, ‚àû), the k-th power absolute-distance loss,\n\nL(Œ∏ Œ∏) = Œ∏ - Œ∏·µè\n\ncontains the squared-error, absolute-error, and 0-1 loss functions as special cases (the latter obtained in the limit as k ‚Üí 0). It is Lipschitz continuous iff k = 1, convex iff k ‚â• 1, and strictly convex iff k > 1: it is quasiconvex for all k > 0.\n\nIf joint = true, the L‚ÇÅ norm is computed over each parameter vector, so that the resulting Bayes estimator is the mode of the joint posterior distribution; otherwise, the Bayes estimator is the vector containing the modes of the marginal posterior distributions.\n\nIf safeorigin = true, the loss function is modified to avoid pathologies around the origin, so that the resulting loss function behaves similarly to the absolute-error loss in the œµ-interval surrounding the origin.\n\n\n\n\n\n","category":"function"},{"location":"API/loss/#NeuralEstimators.quantileloss","page":"Loss functions","title":"NeuralEstimators.quantileloss","text":"quantileloss(Œ∏ÃÇ, Œ∏, q; agg = mean)\nquantileloss(Œ∏ÃÇ, Œ∏, q::V; agg = mean) where {T, V <: AbstractVector{T}}\n\nThe asymmetric loss function whose minimiser is the qth posterior quantile; namely,\n\nL(Œ∏ Œ∏ q) = (Œ∏ - Œ∏)(ùïÄ(Œ∏ - Œ∏  0) - q)\n\nwhere q ‚àà (0, 1) and ùïÄ(‚ãÖ) is the indicator function.\n\nThe method that takes q as a vector is useful for jointly approximating several quantiles of the posterior distribution. In this case, the number of rows in Œ∏ÃÇ is assumed to be pr, where p is the number of parameters: then, q should be an r-vector.\n\nFor further discussion on this loss function, see Equation (7) of Cressie, N. (2022), \"Decisions, decisions, decisions in an uncertain environment\", arXiv:2209.13157.\n\nExamples\n\np = 1\nK = 10\nŒ∏ = rand(p, K)\nŒ∏ÃÇ = rand(p, K)\nquantileloss(Œ∏ÃÇ, Œ∏, 0.1)\n\nŒ∏ÃÇ = rand(3p, K)\nquantileloss(Œ∏ÃÇ, Œ∏, [0.1, 0.5, 0.9])\n\np = 2\nŒ∏ = rand(p, K)\nŒ∏ÃÇ = rand(p, K)\nquantileloss(Œ∏ÃÇ, Œ∏, 0.1)\n\nŒ∏ÃÇ = rand(3p, K)\nquantileloss(Œ∏ÃÇ, Œ∏, [0.1, 0.5, 0.9])\n\n\n\n\n\n","category":"function"},{"location":"API/loss/#NeuralEstimators.intervalscore","page":"Loss functions","title":"NeuralEstimators.intervalscore","text":"intervalscore(l, u, Œ∏, Œ±; agg = mean)\nintervalscore(Œ∏ÃÇ, Œ∏, Œ±; agg = mean)\n\nGiven a 100√ó(1-Œ±)% confidence interval [l, u] with true value Œ∏, the interval score is defined by\n\nS(l u Œ∏ Œ±) = (u - l) + 2Œ±¬π(l - Œ∏)ùïÄ(Œ∏  l) + 2Œ±¬π(Œ∏ - u)ùïÄ(Œ∏  u)\n\nwhere Œ± ‚àà (0, 1) and ùïÄ(‚ãÖ) is the indicator function.\n\nThe method that takes a single value Œ∏ÃÇ assumes that Œ∏ÃÇ is a matrix with 2p rows, where p is the number of parameters in the statistical model. Then, the first and second set of p rows will be used as l and u, respectively.\n\nFor further discussion, see Section 6 of Gneiting, T. and Raftery, A. E. (2007), \"Strictly proper scoring rules, prediction, and estimation\", Journal of the American statistical Association, 102, 359‚Äì378.\n\n\n\n\n\n","category":"function"},{"location":"API/architectures/#Architectures-and-activations-functions","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"","category":"section"},{"location":"API/architectures/#Index","page":"Architectures and activations functions","title":"Index","text":"","category":"section"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"Order = [:type, :function]\nPages   = [\"architectures.md\"]","category":"page"},{"location":"API/architectures/#Architectures","page":"Architectures and activations functions","title":"Architectures","text":"","category":"section"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"Although the user is free to construct their neural estimator however they see fit (i.e., using arbitrary Flux code), NeuralEstimators provides several useful architectures described below that are specifically relevant to neural estimation. See also the convenience constructor initialise_estimator.  ","category":"page"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"DeepSet\n\nDeepSetExpert\n\nGNN","category":"page"},{"location":"API/architectures/#NeuralEstimators.DeepSet","page":"Architectures and activations functions","title":"NeuralEstimators.DeepSet","text":"DeepSet(œà, œï, a)\nDeepSet(œà, œï; a::String = \"mean\")\n\nThe Deep Set representation,\n\nŒ∏(ùêô) = œï(ùêì(ùêô))\t‚ÄÇ\t‚ÄÇùêì(ùêô) = ùêö(œà(ùêô·µ¢)  i = 1  m)\n\nwhere ùêô ‚â° (ùêô‚ÇÅ', ‚Ä¶, ùêô‚Çò')' are independent replicates from the model, œà and œï are neural networks, and a is a permutation-invariant aggregation function.\n\nTo make the architecture agnostic to the sample size m, the aggregation function a must aggregate over the replicates. It can be specified as a positional argument of type Function, or as a keyword argument with permissible values \"mean\", \"sum\", and \"logsumexp\".\n\nDeepSet objects act on data stored as Vector{A}, where each element of the vector is associated with one parameter vector (i.e., one set of independent replicates), and where A depends on the form of the data and the chosen architecture for œà. As a rule of thumb, when the data are stored as an array, the replicates are stored in the final dimension of the array. (This is usually the 'batch' dimension, but batching with DeepSets is done at the set level, i.e., sets of replicates are batched together.) For example, with gridded spatial data and œà a CNN, A should be a 4-dimensional array, with the replicates stored in the 4·µó ∞ dimension.\n\nNote that, internally, data stored as Vector{Arrays} are first concatenated along the replicates dimension before being passed into the inner neural network œà; this means that œà is applied to a single large array rather than many small arrays, which can substantially improve computational efficiency, particularly on the GPU.\n\nSet-level information, ùê±, that is not a function of the data can be passed directly into the outer network œï in the following manner,\n\nŒ∏(ùêô) = œï((ùêì(ùêô) ùê±))\t‚ÄÇ\t‚ÄÇùêì(ùêô) = ùêö(œà(ùêô·µ¢)  i = 1  m)\n\nThis is done by providing a Tuple{Vector{A}, Vector{B}}, where the first element of the tuple contains the vector of data sets and the second element contains the vector of set-level information.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\nn = 10 # number of observations in each realisation\np = 4  # number of parameters in the statistical model\n\n# Construct the neural estimator\nw = 32 # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ = DeepSet(œà, œï)\n\n# Apply the estimator\nZ‚ÇÅ = rand(n, 3);                  # single set of 3 realisations\nZ‚ÇÇ = [rand(n, m) for m ‚àà (3, 3)]; # two sets each containing 3 realisations\nZ‚ÇÉ = [rand(n, m) for m ‚àà (3, 4)]; # two sets containing 3 and 4 realisations\nŒ∏ÃÇ(Z‚ÇÅ)\nŒ∏ÃÇ(Z‚ÇÇ)\nŒ∏ÃÇ(Z‚ÇÉ)\n\n# Repeat the above but with set-level information:\nq‚Çì = 2\nœï  = Chain(Dense(w + q‚Çì, w, relu), Dense(w, p));\nŒ∏ÃÇ  = DeepSet(œà, œï)\nx‚ÇÅ = rand(q‚Çì)\nx‚ÇÇ = [rand(q‚Çì) for _ ‚àà eachindex(Z‚ÇÇ)]\nŒ∏ÃÇ((Z‚ÇÅ, x‚ÇÅ))\nŒ∏ÃÇ((Z‚ÇÇ, x‚ÇÇ))\nŒ∏ÃÇ((Z‚ÇÉ, x‚ÇÇ))\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.DeepSetExpert","page":"Architectures and activations functions","title":"NeuralEstimators.DeepSetExpert","text":"DeepSetExpert(œà, œï, S, a)\nDeepSetExpert(œà, œï, S; a::String = \"mean\")\nDeepSetExpert(deepset::DeepSet, œï, S)\n\nIdentical to DeepSet, but with additional expert summary statistics,\n\nŒ∏(ùêô) = œï((ùêì(ùêô) ùêí(ùêô)))\t‚ÄÇ\t‚ÄÇùêì(ùêô) = ùêö(œà(ùêô·µ¢)  i = 1  m)\n\nwhere S is a function that returns a vector of expert summary statistics.\n\nThe constructor DeepSetExpert(deepset::DeepSet, œï, S) inherits œà and a from deepset.\n\nSimilarly to DeepSet, set-level information can be incorporated by passing a Tuple, in which case we have\n\nŒ∏(ùêô) = œï((ùêì(ùêô) ùêí(ùêô) ùê±))\t‚ÄÇ\t‚ÄÇùêì(ùêô) = ùêö(œà(ùêô·µ¢)  i = 1  m)\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\nn = 10 # number of observations in each realisation\np = 4  # number of parameters in the statistical model\n\n# Construct the neural estimator\nS = samplesize\nq‚Çõ = 1\nq‚Çú = 32\nw = 16\nœà = Chain(Dense(n, w, relu), Dense(w, q‚Çú, relu));\nœï = Chain(Dense(q‚Çú + q‚Çõ, w), Dense(w, p));\nŒ∏ÃÇ = DeepSetExpert(œà, œï, S)\n\n# Apply the estimator\nZ‚ÇÅ = rand(n, 3);                  # single set\nZ‚ÇÇ = [rand(n, m) for m ‚àà (3, 4)]; # two sets\nŒ∏ÃÇ(Z‚ÇÅ)\nŒ∏ÃÇ(Z‚ÇÇ)\n\n# Repeat the above but with set-level information:\nq‚Çì = 2\nœï  = Chain(Dense(q‚Çú + q‚Çõ + q‚Çì, w, relu), Dense(w, p));\nŒ∏ÃÇ  = DeepSetExpert(œà, œï, S)\nx‚ÇÅ = rand(q‚Çì)\nx‚ÇÇ = [rand(q‚Çì) for _ ‚àà eachindex(Z‚ÇÇ)]\nŒ∏ÃÇ((Z‚ÇÅ, x‚ÇÅ))\nŒ∏ÃÇ((Z‚ÇÇ, x‚ÇÇ))\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.GNN","page":"Architectures and activations functions","title":"NeuralEstimators.GNN","text":"GNN(propagation, readout, œï, a)\nGNN(propagation, readout, œï, a::String = \"mean\")\n\nA graph neural network (GNN) designed for parameter point estimation.\n\nThe propagation module transforms graphical input data into a set of hidden-feature graphs; the readout module aggregates these feature graphs into a single hidden feature vector of fixed length; the function a(‚ãÖ) is a permutation-invariant aggregation function, and œï is a neural network.\n\nThe data should be stored as a GNNGraph or AbstractVector{GNNGraph}, where each graph is associated with a single parameter vector. The graphs may contain sub-graphs corresponding to independent replicates from the model.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\nusing Flux: batch\nusing GraphNeuralNetworks\nusing Statistics: mean\n\n# Propagation module\nd = 1      # dimension of response variable\nnh = 32    # dimension of node feature vectors\npropagation = GNNChain(GraphConv(d => nh), GraphConv(nh => nh), GraphConv(nh => nh))\n\n# Readout module (using \"universal pooling\")\nnt = 64   # dimension of the summary vector for each node\nno = 128  # dimension of the final summary vector for each graph\nreadout = UniversalPool(Dense(nh, nt), Dense(nt, nt))\n\n# Alternative readout module (using the elementwise average)\n# readout = GlobalPool(mean); no = nh\n\n# Mapping module\np = 3     # number of parameters in the statistical model\nw = 64    # width of layers used for the mapping network œï\nœï = Chain(Dense(no, w, relu), Dense(w, w, relu), Dense(w, p))\n\n# Construct the estimator\nŒ∏ÃÇ = GNN(propagation, readout, œï)\n\n# Apply the estimator to:\n# \t1. a single graph,\n# \t2. a single graph with sub-graphs (corresponding to independent replicates), and\n# \t3. a vector of graphs (corresponding to multiple spatial data sets).\ng‚ÇÅ = rand_graph(11, 30, ndata=rand(d, 11))\ng‚ÇÇ = rand_graph(13, 40, ndata=rand(d, 13))\ng‚ÇÉ = batch([g‚ÇÅ, g‚ÇÇ])\nŒ∏ÃÇ(g‚ÇÅ)\nŒ∏ÃÇ(g‚ÇÉ)\nŒ∏ÃÇ([g‚ÇÅ, g‚ÇÇ, g‚ÇÉ])\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#Layers","page":"Architectures and activations functions","title":"Layers","text":"","category":"section"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"WeightedGraphConv\n\nUniversalPool","category":"page"},{"location":"API/architectures/#NeuralEstimators.WeightedGraphConv","page":"Architectures and activations functions","title":"NeuralEstimators.WeightedGraphConv","text":"WeightedGraphConv(in => out, œÉ=identity; aggr=mean, bias=true, init=glorot_uniform)\n\nSame as regular GraphConv layer, but where the neighbours of a node are weighted by their spatial distance to that node.\n\nArguments\n\nin: The dimension of input features.\nout: The dimension of output features.\nœÉ: Activation function.\naggr: Aggregation operator for the incoming messages (e.g. +, *, max, min, and mean).\nbias: Add learnable bias.\ninit: Weights' initializer.\n\nExamples\n\nusing NeuralEstimators\nusing GraphNeuralNetworks\n\n# Construct a spatially-weighted adjacency matrix based on k-nearest neighbours\n# with k = 5, and convert to a graph with random (uncorrelated) dummy data:\nn = 100\nS = rand(n, 2)\nd = 1 # dimension of each observation (univariate data here)\nA = adjacencymatrix(S, 5)\nZ = GNNGraph(A, ndata = rand(d, n))\n\n# Construct the layer and apply it to the data to generate convolved features\nlayer = WeightedGraphConv(d => 16)\nlayer(Z)\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.UniversalPool","page":"Architectures and activations functions","title":"NeuralEstimators.UniversalPool","text":"UniversalPool(œà, œï)\n\nPooling layer (i.e., readout layer) from the paper 'Universal Readout for Graph Convolutional Neural Networks'. It takes the form,\n\nmathbfV = œï(G¬π sum_sin G œà(mathbfh_s))\n\nwhere mathbfV denotes the summary vector for graph G, mathbfh_s denotes the vector of hidden features for node s in G, and œà and œï are dense neural networks.\n\nSee also the pooling layers available from GraphNeuralNetworks.jl.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\nusing GraphNeuralNetworks\nusing Graphs: random_regular_graph\n\n# Construct an input graph G\nn_h     = 16  # dimension of each feature node\nn_nodes = 10\nn_edges = 4\nG = GNNGraph(random_regular_graph(n_nodes, n_edges), ndata = rand(n_h, n_nodes))\n\n# Construct the pooling layer\nn_t = 32  # dimension of the summary vector for each node\nn_v = 64  # dimension of the final summary vector V\nœà = Dense(n_h, n_t)\nœï = Dense(n_t, n_v)\npool = UniversalPool(œà, œï)\n\n# Apply the pooling layer\npool(G)\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#Output-activation-functions","page":"Architectures and activations functions","title":"Output activation functions","text":"","category":"section"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"These layers can be used at the end of an architecture to ensure that the neural estimator provides valid parameters.","category":"page"},{"location":"API/architectures/","page":"Architectures and activations functions","title":"Architectures and activations functions","text":"Compress\n\nCholeskyCovariance\n\nCovarianceMatrix\n\nCorrelationMatrix\n\nSplitApply","category":"page"},{"location":"API/architectures/#NeuralEstimators.Compress","page":"Architectures and activations functions","title":"NeuralEstimators.Compress","text":"Compress(a, b, k = 1)\n\nLayer that compresses its input to be within the range a and b, where each element of a is less than the corresponding element of b.\n\nThe layer uses a logistic function,\n\nl(Œ∏) = a + fracb - a1 + e^-kŒ∏\n\nwhere the arguments a and b together combine to shift and scale the logistic function to the range (a, b), and the growth rate k controls the steepness of the curve.\n\nThe logistic function given here contains an additional parameter, Œ∏‚ÇÄ, which is the input value corresponding to the functions midpoint. In Compress, we fix Œ∏‚ÇÄ = 0, since the output of a randomly initialised neural network is typically around zero.\n\nExamples\n\nusing NeuralEstimators\nusing Flux\n\na = [25, 0.5, -pi/2]\nb = [500, 2.5, 0]\np = length(a)\nK = 100\nŒ∏ = randn(p, K)\nl = Compress(a, b)\nl(Œ∏)\n\nn = 20\nŒ∏ÃÇ = Chain(Dense(n, p), l)\nZ = randn(n, K)\nŒ∏ÃÇ(Z)\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.CholeskyCovariance","page":"Architectures and activations functions","title":"NeuralEstimators.CholeskyCovariance","text":"CholeskyCovariance(d)\n\nLayer for constructing the parameters of the lower Cholesky factor associated with an unconstrained d√ód covariance matrix.\n\nThe layer transforms a Matrix with d(d+1)√∑2 rows into a Matrix of the same dimension, but with d rows constrained to be positive (corresponding to the diagonal elements of the Cholesky factor) and the remaining rows unconstrained.\n\nThe ordering of the transformed Matrix aligns with Julia's column-major ordering. For example, when modelling the Cholesky factor,\n\nbeginbmatrix\nL‚ÇÅ‚ÇÅ           \nL‚ÇÇ‚ÇÅ  L‚ÇÇ‚ÇÇ      \nL‚ÇÉ‚ÇÅ  L‚ÇÉ‚ÇÇ  L‚ÇÉ‚ÇÉ \nendbmatrix\n\nthe rows of the matrix returned by a CholeskyCovariance layer will be ordered as\n\nL‚ÇÅ‚ÇÅ L‚ÇÇ‚ÇÅ L‚ÇÉ‚ÇÅ L‚ÇÇ‚ÇÇ L‚ÇÉ‚ÇÇ L‚ÇÉ‚ÇÉ\n\nwhich means that the output can easily be transformed into the implied Cholesky factors using vectotril.\n\nExamples\n\nusing NeuralEstimators\n\nd = 4\np = d*(d+1)√∑2\nŒ∏ = randn(p, 50)\nl = CholeskyCovariance(d)\nŒ∏ = l(Œ∏)                              # returns matrix (used for Flux networks)\nL = [vectotril(y) for y ‚àà eachcol(Œ∏)] # convert matrix to Cholesky factors\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.CovarianceMatrix","page":"Architectures and activations functions","title":"NeuralEstimators.CovarianceMatrix","text":"CovarianceMatrix(d)\n\nLayer for constructing the parameters of an unconstrained d√ód covariance matrix.\n\nThe layer transforms a Matrix with d(d+1)√∑2 rows into a Matrix of the same dimension.\n\nInternally, it uses a CholeskyCovariance layer to construct a valid Cholesky factor ùêã, and then extracts the lower triangle from the positive-definite covariance matrix ùö∫ = ùêãùêã'. The lower triangle is extracted and vectorised in line with Julia's column-major ordering. For example, when modelling the covariance matrix,\n\nbeginbmatrix\nŒ£‚ÇÅ‚ÇÅ  Œ£‚ÇÅ‚ÇÇ  Œ£‚ÇÅ‚ÇÉ \nŒ£‚ÇÇ‚ÇÅ  Œ£‚ÇÇ‚ÇÇ  Œ£‚ÇÇ‚ÇÉ \nŒ£‚ÇÉ‚ÇÅ  Œ£‚ÇÉ‚ÇÇ  Œ£‚ÇÉ‚ÇÉ \nendbmatrix\n\nthe rows of the matrix returned by a CovarianceMatrix layer will be ordered as\n\nŒ£‚ÇÅ‚ÇÅ Œ£‚ÇÇ‚ÇÅ Œ£‚ÇÉ‚ÇÅ Œ£‚ÇÇ‚ÇÇ Œ£‚ÇÉ‚ÇÇ Œ£‚ÇÉ‚ÇÉ\n\nwhich means that the output can easily be transformed into the implied covariance matrices using vectotril and Symmetric.\n\nExamples\n\nusing NeuralEstimators\nusing LinearAlgebra\n\nd = 4\np = d*(d+1)√∑2\nŒ∏ = randn(p, 50)\n\nl = CovarianceMatrix(d)\nŒ∏ = l(Œ∏)\nŒ£ = [Symmetric(cpu(vectotril(y)), :L) for y ‚àà eachcol(Œ∏)]\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.CorrelationMatrix","page":"Architectures and activations functions","title":"NeuralEstimators.CorrelationMatrix","text":"CorrelationMatrix(d)\n\nLayer for constructing the parameters of an unconstrained d√ód correlation matrix.\n\nThe layer transforms a Matrix with d(d-1)√∑2 rows into a Matrix with the same dimension.\n\nInternally, the layers uses the algorithm described here and here to construct a valid Cholesky factor ùêã, and then extracts the strict lower triangle from the positive-definite correlation matrix ùêë = ùêãùêã'. The strict lower triangle is extracted and vectorised in line with Julia's column-major ordering. For example, when modelling the correlation matrix,\n\nbeginbmatrix\n1    R‚ÇÅ‚ÇÇ   R‚ÇÅ‚ÇÉ \nR‚ÇÇ‚ÇÅ  1     R‚ÇÇ‚ÇÉ\nR‚ÇÉ‚ÇÅ  R‚ÇÉ‚ÇÇ  1\nendbmatrix\n\nthe rows of the matrix returned by a CorrelationMatrix layer will be ordered as\n\nR‚ÇÇ‚ÇÅ R‚ÇÉ‚ÇÅ R‚ÇÉ‚ÇÇ\n\nwhich means that the output can easily be transformed into the implied correlation matrices using the strict variant of vectotril and Symmetric.\n\nExamples\n\nusing NeuralEstimators\nusing LinearAlgebra\n\nd = 4\np = d*(d-1)√∑2\nl = CorrelationMatrix(d)\nŒ∏ = randn(p, 50)\n\n# returns a matrix of parameters\nŒ∏ = l(Œ∏)\n\n# convert matrix of parameters to implied correlation matrices\nR = map(eachcol(Œ∏)) do y\n\tR = Symmetric(cpu(vectotril(y, strict = true)), :L)\n\tR[diagind(R)] .= 1\n\tR\nend\n\n\n\n\n\n","category":"type"},{"location":"API/architectures/#NeuralEstimators.SplitApply","page":"Architectures and activations functions","title":"NeuralEstimators.SplitApply","text":"SplitApply(layers, indices)\n\nSplits an array into multiple sub-arrays by subsetting the rows using the collection of indices, and then applies each layer in layers to the corresponding sub-array.\n\nSpecifically, for each i = 1, ‚Ä¶, n, with n the number of layers, SplitApply(x) performs layers[i](x[indices[i], :]), and then vertically concatenates the resulting transformed arrays.\n\nExamples\n\nusing NeuralEstimators\n\nd = 4\nK = 50\np‚ÇÅ = 2          # number of non-covariance matrix parameters\np‚ÇÇ = d*(d+1)√∑2  # number of covariance matrix parameters\np = p‚ÇÅ + p‚ÇÇ\n\na = [0.1, 4]\nb = [0.9, 9]\nl‚ÇÅ = Compress(a, b)\nl‚ÇÇ = CovarianceMatrix(d)\nl = SplitApply([l‚ÇÅ, l‚ÇÇ], [1:p‚ÇÅ, p‚ÇÅ+1:p])\n\nŒ∏ = randn(p, K)\nl(Œ∏)\n\n\n\n\n\n","category":"type"},{"location":"#NeuralEstimators","page":"NeuralEstimators","title":"NeuralEstimators","text":"","category":"section"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"Neural estimators are neural networks that transform data into parameter point estimates. They are likelihood free, substantially faster than classical methods, and can be designed to be approximate Bayes estimators. Uncertainty quantification with neural estimators is also straightforward through the bootstrap distribution, which is essentially available \"for free\" with a neural estimator, or by training a neural estimator to approximate a set of marginal posterior quantiles.","category":"page"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"The Julia package NeuralEstimators facilitates the development of neural estimators in a user-friendly manner. It caters for arbitrary models by having the user implicitly define their model via simulated data. This makes the development of neural estimators particularly straightforward for models with existing implementations (possibly in other programming languages, e.g., R or python). A convenient interface for R users is available here.","category":"page"},{"location":"#Getting-started","page":"NeuralEstimators","title":"Getting started","text":"","category":"section"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"Install NeuralEstimators using the following command inside Julia:","category":"page"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"using Pkg; Pkg.add(url = \"https://github.com/msainsburydale/NeuralEstimators.jl\")","category":"page"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"Once familiar with the details of the Framework, see the Examples.","category":"page"},{"location":"#Supporting-and-citing","page":"NeuralEstimators","title":"Supporting and citing","text":"","category":"section"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"This software was developed as part of academic research. If you would like to support it, please star the repository. If you use it in your research or other activities, please also use the following citation.","category":"page"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"@article{SZH_2023_neural_Bayes_estimators,\n\tauthor = {Sainsbury-Dale, Matthew and Zammit-Mangion, Andrew and Huser, Rapha√´l},\n\ttitle = {Likelihood-Free Parameter Estimation with Neural {B}ayes Estimators},\n\tjournal = {The American Statistician},\n\tyear = {2023},\n\tvolume = {to appear},\n\tdoi = {10.1080/00031305.2023.2249522},\n\turl = {https://doi.org/10.1080/00031305.2023.2249522}\n}","category":"page"},{"location":"#Papers-using-NeuralEstimators","page":"NeuralEstimators","title":"Papers using NeuralEstimators","text":"","category":"section"},{"location":"","page":"NeuralEstimators","title":"NeuralEstimators","text":"Likelihood-free parameter estimation with neural Bayes estimators [paper]\nNeural Bayes estimators for censored inference with peaks-over-threshold models [paper]\nNeural Bayes estimators for irregular spatial data using graph neural networks [paper]\nModern extreme value statistics for Utopian extremes [paper]","category":"page"}]
}
