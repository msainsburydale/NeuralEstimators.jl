<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples · NeuralEstimators.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../framework/">Theoretical framework</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#Univariate-data"><span>Univariate data</span></a></li><li><a class="tocitem" href="#Multivariate-data"><span>Multivariate data</span></a></li><li><a class="tocitem" href="#Gridded-spatial-data"><span>Gridded spatial data</span></a></li><li><a class="tocitem" href="#Irregular-spatial-data"><span>Irregular spatial data</span></a></li></ul></li><li><a class="tocitem" href="../advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../../API/core/">Core</a></li><li><a class="tocitem" href="../../API/architectures/">Architectures and activations functions</a></li><li><a class="tocitem" href="../../API/loss/">Loss functions</a></li><li><a class="tocitem" href="../../API/simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../../API/utility/">Miscellaneous</a></li><li><a class="tocitem" href="../../API/">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Workflow</a></li><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/workflow/examples.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h1><h2 id="Univariate-data"><a class="docs-heading-anchor" href="#Univariate-data">Univariate data</a><a id="Univariate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Univariate-data" title="Permalink"></a></h2><p>Here, we develop a neural Bayes estimator for <span>$\boldsymbol{\theta} \equiv (\mu, \sigma)&#39;$</span> from data <span>$Z_1, \dots, Z_m$</span> that are independent and identically distributed according to a <span>$N(\mu, \sigma^2)$</span> distribution. We&#39;ll use the priors <span>$\mu \sim N(0, 1)$</span> and <span>$\sigma \sim U(0.1, 1)$</span>, and we assume that the parameters are independent a priori.</p><p>Before proceeding, we load the required packages:</p><pre><code class="nohighlight hljs">using NeuralEstimators
using Flux
using Distributions
import NeuralEstimators: simulate</code></pre><p>First, we define a function to sample parameters from the prior. The sampled parameters are stored as <span>$p \times K$</span> matrices, with <span>$p$</span> the number of parameters in the model and <span>$K$</span> the number of sampled parameter vectors.</p><pre><code class="nohighlight hljs">function sample(K)
	μ = rand(Normal(0, 1), K)
	σ = rand(Uniform(0.1, 1), K)
	θ = hcat(μ, σ)&#39;
	θ = Float32.(θ)
	return θ
end</code></pre><p>Next, we implicitly define the statistical model with simulated data. The data are stored as a <code>Vector{A}</code>, where each element of the vector is associated with one parameter vector, and where <code>A</code> depends on the representation of the neural estimator. Since our data is replicated, we will use the DeepSets framework and, since each replicate is univariate, we will use a dense neural network (DNN) for the inner network. Since the inner network is a DNN, <code>A</code> should be a sub-type of <code>AbstractArray</code>, with the independent replicates stored in the final dimension.</p><pre><code class="nohighlight hljs">function simulate(parameters, m)
	Z = [θ[1] .+ θ[2] .* randn(Float32, 1, m) for θ ∈ eachcol(parameters)]
	return Z
end</code></pre><p>We now design architectures for the inner and outer neural networks, <span>$\boldsymbol{\psi}(\cdot)$</span> and <span>$\boldsymbol{\phi}(\cdot)$</span> respectively, in the DeepSets framework, and initialise the neural estimator as a <a href="../../API/core/#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a> object.</p><pre><code class="nohighlight hljs">p = 2   # number of parameters in the statistical model
w = 32  # width of each layer

ψ = Chain(Dense(1, w, relu), Dense(w, w, relu))
ϕ = Chain(Dense(w, w, relu), Dense(w, p))
architecture = DeepSet(ψ, ϕ)

θ̂ = PointEstimator(architecture)</code></pre><p>Next, we train the neural estimator using <a href="../../API/core/#NeuralEstimators.train"><code>train</code></a>, here using the default absolute-error loss. We&#39;ll train the estimator using 15 independent replicates per parameter configuration. Below, we pass our user-defined functions for sampling parameters and simulating data, but one may also pass parameter or data instances, which will be held fixed during training; see <a href="../../API/core/#NeuralEstimators.train"><code>train</code></a>.</p><pre><code class="nohighlight hljs">m = 15
θ̂ = train(θ̂, sample, simulate, m = m, epochs = 30)</code></pre><p>To test the accuracy of the resulting neural Bayes estimator, we use the function <a href="../../API/core/#NeuralEstimators.assess"><code>assess</code></a>, which can be used to assess the performance of the estimator (or multiple estimators) over a range of sample sizes. Note that, in this example, we trained the neural estimator using a single sample size, <span>$m = 15$</span>, and hence the estimator will not necessarily be optimal for other sample sizes; see <a href="../advancedusage/#Variable-sample-sizes">Variable sample sizes</a> for approaches that one could adopt if data sets with varying sample size are envisaged.</p><pre><code class="nohighlight hljs">θ     = sample(1000)
Z     = [simulate(θ, m) for m ∈ (5, 10, 15, 20, 30)]
assessment = assess([θ̂], θ, Z)</code></pre><p>The returned object is an object of type <a href="../../API/core/#NeuralEstimators.Assessment"><code>Assessment</code></a>, which contains the true parameters and their corresponding estimates, and the time taken to compute the estimates for each sample size and each estimator. The risk function may be computed using the function <a href="../../API/core/#NeuralEstimators.risk"><code>risk</code></a>:</p><pre><code class="nohighlight hljs">risk(assessment)</code></pre><p>It is often helpful to visualise the empirical sampling distribution of an estimator for a particular parameter configuration and a particular sample size. This can be done by providing <a href="../../API/core/#NeuralEstimators.assess"><code>assess</code></a> with <span>$J$</span> data sets simulated under a particular parameter configuration (below facilitated with the pre-defined method <code>simulate(parameters, m, J::Integer)</code>, which wraps the method of <code>simulate</code> that we defined earlier), and then plotting the estimates contained in the long-form <code>DataFrame</code> in the resulting <a href="../../API/core/#NeuralEstimators.Assessment"><code>Assessment</code></a> object:</p><pre><code class="nohighlight hljs">J = 100
θ = sample(1)
Z = [simulate(θ, m, J)]
assessment = assess([θ̂], θ, Z)  </code></pre><p>Once the neural Bayes estimator has been assessed, it may then be applied to observed data, with parametric/non-parametric bootstrap-based uncertainty quantification facilitated by <a href="../../API/core/#NeuralEstimators.bootstrap"><code>bootstrap</code></a> and <a href="../../API/core/#NeuralEstimators.interval"><code>interval</code></a>. Below, we use simulated data as a substitute for observed data:</p><pre><code class="nohighlight hljs">Z = simulate(θ, m)     # pretend that this is observed data
θ̂(Z)                   # point estimates from the observed data
θ̃ = bootstrap(θ̂, Z)    # non-parametric bootstrap estimates
interval(θ̃)  # confidence interval from the bootstrap estimates</code></pre><h2 id="Multivariate-data"><a class="docs-heading-anchor" href="#Multivariate-data">Multivariate data</a><a id="Multivariate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-data" title="Permalink"></a></h2><p>Suppose now that our data consists of <span>$m$</span> replicates of a <span>$d$</span>-dimensional multivariate distribution. Everything remains as given in the univariate example above, except that we now store the data as a vector of <span>$d \times m$</span> matrices (previously they were stored as <span>$1\times m$</span> matrices), and the inner network of the DeepSets representation takes a <span>$d$</span>-dimensional input (previously it took a 1-dimensional input).</p><p>&lt;!– Note that, when estimating a covariance matrix, one may wish to constrain the neural estimator to only produce parameters that imply a valid (i.e., positive definite) covariance matrix. This can be achieved by appending a  <a href="../../API/architectures/#NeuralEstimators.CovarianceMatrix"><code>CovarianceMatrix</code></a> layer to the end of the outer network of the DeepSets representation. However, this is often unnecessary as the estimator will typically learn to provide valid estimates, even if not constrained to do so. –&gt;</p><h2 id="Gridded-spatial-data"><a class="docs-heading-anchor" href="#Gridded-spatial-data">Gridded spatial data</a><a id="Gridded-spatial-data-1"></a><a class="docs-heading-anchor-permalink" href="#Gridded-spatial-data" title="Permalink"></a></h2><p>For spatial data measured on a regular grid, the estimator is typically based on a convolutional neural network (CNN), and each data set is stored as a four-dimensional array, where the first three dimensions corresponding to the width, height, and depth/channels dimensions, and the fourth dimension stores the independent replicates. Note that, for univariate spatial processes, the channels dimension is simply equal to 1. For a 16x16 spatial grid, a possible architecture is given below.</p><pre><code class="nohighlight hljs">p = 2    # number of parameters in the statistical model
w = 32   # number of neurons in each layer
d = 2    # dimension of the response variable

ψ = Chain(
	Conv((10, 10), 1 =&gt; 32,  relu),
	Conv((5, 5),  32 =&gt; 64,  relu),
	Conv((3, 3),  64 =&gt; 128, relu),
	Flux.flatten
	)
ϕ = Chain(Dense(128, 512, relu), Dense(512, p))
architecture = DeepSet(ψ, ϕ)</code></pre><h2 id="Irregular-spatial-data"><a class="docs-heading-anchor" href="#Irregular-spatial-data">Irregular spatial data</a><a id="Irregular-spatial-data-1"></a><a class="docs-heading-anchor-permalink" href="#Irregular-spatial-data" title="Permalink"></a></h2><p>This example is coming soon! The methodology involves the use of graph neural networks, which in Julia can be implemented using the package <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/stable/"><code>GraphNeuralNetworks.jl</code></a>. Some key steps:</p><ul><li>Sampling spatial locations during the training phase: see <a href="../../API/simulation/#NeuralEstimators.maternclusterprocess"><code>maternclusterprocess</code></a>.</li><li>Computing (spatially-weighted) adjacency matrices: see <a href="../../API/utility/#NeuralEstimators.adjacencymatrix"><code>adjacencymatrix</code></a>.</li><li>Storing the data as a graph: see <a href="https://carlolucibello.github.io/GraphNeuralNetworks.jl/stable/api/gnngraph/#GNNGraph-type"><code>GNNGraph</code></a>.</li><li>Constructing an appropriate architecture for the neural Bayes estimator: see <a href="../../API/architectures/#NeuralEstimators.GNN"><code>GNN</code></a> and <a href="../../API/architectures/#NeuralEstimators.WeightedGraphConv"><code>WeightedGraphConv</code></a>.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../overview/">« Overview</a><a class="docs-footer-nextpage" href="../advancedusage/">Advanced usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Monday 21 August 2023 20:50">Monday 21 August 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
