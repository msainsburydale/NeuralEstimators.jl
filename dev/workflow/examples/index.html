<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples · NeuralEstimators.jl</title><meta name="title" content="Examples · NeuralEstimators.jl"/><meta property="og:title" content="Examples · NeuralEstimators.jl"/><meta property="twitter:title" content="Examples · NeuralEstimators.jl"/><meta name="description" content="Documentation for NeuralEstimators.jl."/><meta property="og:description" content="Documentation for NeuralEstimators.jl."/><meta property="twitter:description" content="Documentation for NeuralEstimators.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralEstimators</a></li><li><a class="tocitem" href="../../methodology/">Methodology</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#Univariate-data"><span>Univariate data</span></a></li><li><a class="tocitem" href="#Gridded-data"><span>Gridded data</span></a></li><li><a class="tocitem" href="#Irregular-spatial-data"><span>Irregular spatial data</span></a></li></ul></li><li><a class="tocitem" href="../advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../../API/core/">Core</a></li><li><a class="tocitem" href="../../API/architectures/">Architectures</a></li><li><a class="tocitem" href="../../API/approximatedistributions/">Approximate distributions</a></li><li><a class="tocitem" href="../../API/loss/">Loss functions</a></li><li><a class="tocitem" href="../../API/simulation/">Model-specific functions</a></li><li><a class="tocitem" href="../../API/utility/">Miscellaneous</a></li><li><a class="tocitem" href="../../API/">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Workflow</a></li><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/workflow/examples.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h1><p>For a very simple example that can be &quot;copy-paste&quot;, see <a href="../../#Quick-start">Quick start</a> on the <a href="../../#NeuralEstimators">index page</a>. </p><p>Before proceeding to the main examples, we first load the required packages, the following of which are used throughout these examples:</p><pre><code class="language-julia hljs">using NeuralEstimators
using Flux                                  # Julia&#39;s deep-learning library
using Distributions: InverseGamma, Uniform  # sampling from probability distributions
using AlgebraOfGraphics, CairoMakie         # visualisation</code></pre><p>The following packages will be used in the examples with <a href="#Gridded-data">Gridded data</a> and <a href="#Irregular-spatial-data">Irregular spatial data</a>:  </p><pre><code class="language-julia hljs">using Distances                             # distance matrices 
using Folds                                 # parallel simulation (start Julia with --threads=auto)
using LinearAlgebra                         # Cholesky factorisation</code></pre><p>The following packages are used only in the example with <a href="#Irregular-spatial-data">Irregular spatial data</a>: </p><pre><code class="language-julia hljs">using GraphNeuralNetworks                   # GNN architecture
using Statistics: mean                            </code></pre><p>Finally, various GPU backends can be used (see the <a href="https://fluxml.ai/Flux.jl/stable/guide/gpu/#GPU-Support">Flux documentation</a> for details). For instance, to use an NVIDIA GPU in the following examples, simply load <code>CUDA.jl</code>:  </p><pre><code class="language-julia hljs">using CUDA</code></pre><p>Once a GPU package is loaded and a compatible GPU is available, the functions in <code>NeuralEstimators</code> will automatically leverage it to improve computational efficiency while ensuring memory safety via batched operations (GPU usage can be disabled by setting <code>use_gpu = false</code>).</p><h2 id="Univariate-data"><a class="docs-heading-anchor" href="#Univariate-data">Univariate data</a><a id="Univariate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Univariate-data" title="Permalink"></a></h2><p>Here, we develop a <a href="../../methodology/#Neural-Bayes-estimators">neural Bayes estimator</a> for <span>$\boldsymbol{\theta} \equiv (\mu, \sigma)&#39;$</span> from data <span>$\boldsymbol{Z} \equiv (Z_1, \dots, Z_m)&#39;$</span>, where each <span>$Z_i \overset{\mathrm{iid}}\sim N(\mu, \sigma^2)$</span>. See <a href="../../API/core/#Estimators">Estimators</a> for a list of other classes of estimators available in the package.</p><p>We begin by defining a function to sample parameters from the prior distribution. Assuming prior independence, we adopt the marginal priors <span>$\mu \sim N(0, 1)$</span> and <span>$\sigma \sim IG(3, 1)$</span>:</p><pre><code class="language-julia hljs">function sample(K)
	μ = randn(K)
	σ = rand(InverseGamma(3, 1), K)
	θ = vcat(μ&#39;, σ&#39;)
	return θ
end</code></pre><p>Next, we define the statistical model implicitly through data simulation. Since our data are replicated, the simulated data are stored as a <code>Vector{A}</code>, where each element corresponds to one parameter vector. The type <code>A</code> reflects the multivariate structure of the data. In this example, each replicate <span>$Z_1, \dots, Z_m$</span> is univariate, so <code>A</code> is a Matrix with <span>$n = 1$</span> row and <span>$m$</span> columns:</p><pre><code class="language-julia hljs">function simulate(θ, m)
    [ϑ[1] .+ ϑ[2] .* randn(1, m) for ϑ in eachcol(θ)]
end</code></pre><p>We now design our neural network. </p><p>As we are constructing a neural Bayes estimator, the neural network is a mapping <span>$\mathcal{Z}\to\Theta$</span>, and the dimensionality of the neural-network output is therefore <span>$d \equiv \textrm{dim}(\Theta) = 2$</span>. </p><p>Since our data are replicated, we adopt the DeepSets framework, implemented via the type <a href="../../API/architectures/#NeuralEstimators.DeepSet"><code>DeepSet</code></a>. DeepSets consist of two neural networks: an inner network and an outer network. The inner network extracts summary statistics from the data, and its architecture depends on the multivariate structure of the data. For unstructured data (i.e., data without spatial or temporal correlation within each replicate), we use a multilayer perceptron (MLP). The input dimension matches the dimensionality of each data replicate, while the output dimension corresponds to the number of summary statistics appropriate for the model (a common choice is <span>$d$</span>). The outer network maps the learned summary statistics to the output space (here, the parameter space, <span>$\Theta$</span>). The outer network is always an MLP. </p><p>Below is an example of a DeepSets architecture for neural Bayes estimation in this example. Note that many models have parameter constraints (e.g., variance and range parameters that must be strictly positive). These constraints can be incorporated in the final layer of the neural network by choosing appropriate activation functions for each parameter. Here, we enforce the constraint <span>$\sigma &gt; 0$</span> by applying the softplus activation function in the final layer of the outer network, ensuring that all parameter estimates are valid. For some additional ways to constrain parameter estimates, see <a href="../../API/architectures/#Output-layers">Output layers</a>. </p><pre><code class="language-julia hljs">n = 1    # dimension of each data replicate (univariate)
d = 2    # dimension of the parameter vector θ
w = 128  # width of each hidden layer 

# Final layer has output dimension d and enforces parameter constraints
final_layer = Parallel(
    vcat,
    Dense(w, 1, identity),     # μ ∈ ℝ
    Dense(w, 1, softplus)      # σ &gt; 0
)

# Inner and outer networks
ψ = Chain(Dense(n, w, relu), Dense(w, d, relu))    
ϕ = Chain(Dense(d, w, relu), final_layer)          

# Combine into a DeepSet
network = DeepSet(ψ, ϕ)</code></pre><p>We then initialise the neural Bayes estimator by wrapping the neural network in a <a href="../../API/core/#NeuralEstimators.PointEstimator"><code>PointEstimator</code></a>: </p><pre><code class="language-julia hljs">estimator = PointEstimator(network)</code></pre><p>Next, we train the estimator using <a href="../../API/core/#NeuralEstimators.train"><code>train()</code></a>, here using the default mean-absolute-error loss, so that the resulting neural Bayes estimator approximates the marginal posterior medians. We&#39;ll train the estimator using <span>$m=50$</span> independent replicates per parameter configuration. Below, we pass our user-defined functions for sampling parameters and simulating data, but one may also pass parameter or data instances, which will be held fixed during training:</p><pre><code class="language-julia hljs">m = 50
estimator = train(estimator, sample, simulate, m = m)</code></pre><p>One may wish to save a trained estimator and load it in a later session: see <a href="../advancedusage/#Saving-and-loading-neural-estimators">Saving and loading neural estimators</a> for details on how this can be done. </p><p>The function <a href="../../API/core/#NeuralEstimators.assess"><code>assess()</code></a> can be used to assess the trained estimator. Parametric and non-parametric bootstrap estimates can be obtained via <a href="../../API/core/#NeuralEstimators.bootstrap"><code>bootstrap()</code></a>, with corresponding confidence intervals computed using <a href="../../API/core/#NeuralEstimators.interval"><code>interval()</code></a>. Additionally, non-parametric bootstrap-based uncertainty quantification can be included in the assessment stage through the keyword argument <code>probs</code>:</p><pre><code class="language-julia hljs">θ_test = sample(1000)
Z_test = simulate(θ_test, m)
assessment = assess(estimator, θ_test, Z_test, probs = [0.025, 0.975])</code></pre><p>The resulting <a href="../../API/core/#NeuralEstimators.Assessment"><code>Assessment</code></a> object contains the sampled parameters, the corresponding point estimates, and the corresponding lower and upper bounds of the bootstrap intervals. This object can be used to compute various diagnostics and to visualise the neural point estimates and bootstrap intervals vs the true parameter value:  </p><pre><code class="language-julia hljs">bias(assessment)      # μ = 0.002, σ = 0.017
rmse(assessment)      # μ = 0.086, σ = 0.078
risk(assessment)      # μ = 0.055, σ = 0.056
plot(assessment)</code></pre><p><img src="../../assets/figures/univariate.png" alt="Univariate Gaussian example: Estimates vs. truth"/></p><p>As an alternative form of uncertainty quantification with neural Bayes estimators, one may approximate a set of marginal posterior quantiles by training a neural Bayes estimator under the quantile loss function, which allows one to generate approximate marginal posterior credible intervals. This is facilitated with <a href="../../API/core/#NeuralEstimators.IntervalEstimator"><code>IntervalEstimator</code></a> which, by default, targets 95% central credible intervals:</p><pre><code class="language-julia hljs">q̂ = IntervalEstimator(network)
q̂ = train(q̂, sample, simulate, m = m)</code></pre><p>The resulting posterior credible-interval estimator can also be assessed using <a href="../../API/core/#NeuralEstimators.assess"><code>assess()</code></a>. Often, these intervals have better coverage than bootstrap-based intervals.</p><p>Once an estimator is deemed to be well calibrated, it may be applied to observed data (below, we use simulated data as a substitute for observed data):</p><pre><code class="language-julia hljs">θ = sample(1)                       # true parameters
Z = simulate(θ, m)                  # &quot;observed&quot; data
estimate(estimator, Z)              # point estimate
interval(bootstrap(estimator, Z))   # 95% non-parametric bootstrap intervals
interval(q̂, Z)                      # 95% marginal posterior credible intervals</code></pre><h2 id="Gridded-data"><a class="docs-heading-anchor" href="#Gridded-data">Gridded data</a><a id="Gridded-data-1"></a><a class="docs-heading-anchor-permalink" href="#Gridded-data" title="Permalink"></a></h2><p>For data collected over a regular grid, neural estimators are typically based on a convolutional neural network (CNN; see, e.g., <a href="https://arxiv.org/abs/1603.07285">Dumoulin and Visin, 2016</a>). </p><p>When using CNNs with <code>NeuralEstimators</code>, each data set must be stored as a multi-dimensional array. The penultimate dimension stores the so-called &quot;channels&quot; (this dimension is singleton for univariate processes, two for bivariate processes), while the final dimension stores independent replicates. For example, to store <span>$50$</span> independent replicates of a bivariate spatial process measured over a <span>$10\times15$</span> grid, one would construct an array of dimension <span>$10\times15\times2\times50$</span>.</p><p>For illustration, here we develop a neural Bayes estimator for the (univariate) spatial Gaussian process model with exponential covariance function and unknown range parameter <span>$\theta &gt; 0$</span>. The spatial domain is taken to be the unit square, we simulate data on a regular square grid of size <span>$n = 16^2 = 256$</span>, and we adopt the prior <span>$\theta \sim U(0, 0.5)$</span>. </p><p>Simulation from Gaussian processes typically involves the computation of an expensive intermediate object, namely, the Cholesky factor of a covariance matrix. Storing intermediate objects can enable the fast simulation of new data sets when the parameters are held fixed. Hence, in this example, we define a custom type <code>Parameters</code> subtyping <a href="../../API/core/#NeuralEstimators.ParameterConfigurations"><code>ParameterConfigurations</code></a> for storing the matrix of parameters and the corresponding Cholesky factors: </p><pre><code class="language-julia hljs">struct Parameters{T} &lt;: ParameterConfigurations
	θ::Matrix{T}
	L
end</code></pre><p>Further, we define two constructors for our custom type: one that accepts an integer <span>$K$</span>, and another that accepts a <span>$d\times K$</span> matrix of parameters. The former constructor will be useful during the training stage for sampling from the prior distribution, while the latter constructor will be useful for parametric bootstrap (since this involves repeated simulation from the fitted model):</p><pre><code class="language-julia hljs">function sample(K::Integer)
	# Sample parameters from the prior 
	θ = 0.5 * rand(1, K)

	# Pass to matrix constructor
	Parameters(θ)
end

function Parameters(θ::Matrix)
	# Spatial locations, a 16x16 grid over the unit square
	pts = range(0, 1, length = 16)
	S = expandgrid(pts, pts)

	# Distance matrix, covariance matrices, and Cholesky factors
	D = pairwise(Euclidean(), S, dims = 1)
	K = size(θ, 2)
	L = Folds.map(1:K) do k
		Σ = exp.(-D ./ θ[k])
		cholesky(Symmetric(Σ)).L
	end

	Parameters(θ, L)
end</code></pre><p>Next, we define the model simulator, which returns simulated data as a four-dimensional array (see <a href="../../API/core/#Simulating-data">Simulating data</a> for an overview of common data formats): </p><pre><code class="language-julia hljs">function simulate(parameters::Parameters, m = 1) 
	Z = Folds.map(parameters.L) do L
		n = size(L, 1)
		z = L * randn(n, m)
		z = reshape(z, 16, 16, 1, m) 
		z
	end
	Z
end</code></pre><p>A possible neural-network architecture is as follows. Note that deeper architectures that employ residual connections (see <a href="../../API/architectures/#NeuralEstimators.ResidualBlock">ResidualBlock</a>) often lead to improved performance, and certain pooling layers (e.g., <a href="https://fluxml.ai/Flux.jl/stable/reference/models/layers/#Flux.GlobalMeanPool">GlobalMeanPool</a>) allow the neural network to accommodate grids of varying dimension; for further discussion and an illustration, see <a href="https://doi.org/10.48550/arXiv.2501.04330">Sainsbury-Dale et al. (2025, Sec. S3, S4)</a>. </p><pre><code class="language-julia hljs"># Inner network 
ψ = Chain(
      Conv((3, 3), 1 =&gt; 32, relu),   # 3x3 convolutional filter, 1 input channel to 32 output channels
      MaxPool((2, 2)),               # 2x2 max pooling for dimension reduction
      Conv((3, 3), 32 =&gt; 64, relu),  # 3x3 convolutional filter, 32 input channels to 64 output channels
      MaxPool((2, 2)),               # 2x2 max pooling for dimension reduction
      Flux.flatten                   # flatten output to feed into a fully connected layer
  )

# Outer network 
ϕ = Chain(Dense(256, 64, relu), Dense(64, 1))

# DeepSet object
network = DeepSet(ψ, ϕ)</code></pre><p>Above, we embedded our CNN within the DeepSets framework to accommodate scenarios involving replicated spatial data (e.g., when fitting models for spatial extremes). However, the package allows users to define the neural network using any Flux model. Since this example does not include independent replicates, one could instead store each simulated data set in the final dimension of a four-dimensional array, and then use a generic CNN architecture.  </p><p>Next, we initialise a point estimator and a posterior credible-interval estimator:</p><pre><code class="language-julia hljs">θ̂ = PointEstimator(network)
q̂ = IntervalEstimator(network)</code></pre><p>Now we train the estimators, here using fixed parameter instances to avoid repeated Cholesky factorisations (see <a href="../advancedusage/#Storing-expensive-intermediate-objects-for-data-simulation">Storing expensive intermediate objects for data simulation</a> and <a href="../advancedusage/#On-the-fly-and-just-in-time-simulation">On-the-fly and just-in-time simulation</a> for further discussion):</p><pre><code class="language-julia hljs">K = 10000 # number of training parameter vectors
θ_train = sample(K)
θ_val   = sample(K ÷ 10)
θ̂ = train(θ̂, θ_train, θ_val, simulate)
q̂ = train(q̂, θ_train, θ_val, simulate)</code></pre><p>Once the estimators have been trained, we assess them using empirical simulation-based methods:</p><pre><code class="language-julia hljs">θ_test = sample(1000)
Z_test = simulate(θ_test)
assessment = assess([θ̂, q̂], θ_test, Z_test)

bias(assessment)       # 0.005
rmse(assessment)       # 0.032
coverage(assessment)   # 0.953
plot(assessment)       </code></pre><p><img src="../../assets/figures/gridded.png" alt="Gridded spatial Gaussian process example: Estimates vs. truth"/></p><p>Finally, we can apply our estimators to observed data:</p><pre><code class="language-julia hljs">θ = Parameters(Matrix([0.1]&#39;))         # true parameter
Z = simulate(θ)                        # &quot;observed&quot; data
estimate(θ̂, Z)                         # point estimate: 0.11
interval(q̂, Z)                         # 95% marginal posterior credible interval: [0.08, 0.16]</code></pre><p>Note that missing data (e.g., due to cloud cover) can be accommodated using the <a href="../advancedusage/#Missing-data">missing-data methods</a> implemented in the package.</p><h2 id="Irregular-spatial-data"><a class="docs-heading-anchor" href="#Irregular-spatial-data">Irregular spatial data</a><a id="Irregular-spatial-data-1"></a><a class="docs-heading-anchor-permalink" href="#Irregular-spatial-data" title="Permalink"></a></h2><p>To cater for spatial data collected over arbitrary spatial locations, one may construct a neural estimator with a graph neural network (GNN; see <a href="https://doi.org/10.1080/10618600.2024.2433671">Sainsbury-Dale, Zammit-Mangion, Richards, and Huser, 2025</a>). The overall workflow remains as given in previous examples, with two key additional considerations.</p><p>First, if inference is to be made from a single spatial data set collected before constructing estimator, training data can be simulated using the observed spatial locations, which can be treated as fixed and known. However, if the estimator is intended for application to multiple spatial data sets with varying spatial configurations, it should be trained on a diverse set of spatial configurations. These configurations can be sampled during training, possibly using a spatial point process such as <a href="../../API/simulation/#NeuralEstimators.maternclusterprocess"><code>maternclusterprocess()</code></a>. </p><p>Second, the spatial data should be stored as a graph, which can be achieved using <a href="../../API/utility/#NeuralEstimators.spatialgraph"><code>spatialgraph()</code></a>.</p><p>For illustration, we again consider a spatial Gaussian process model with exponential covariance function, and we define a type for storing expensive intermediate objects needed for data simulation. In this example, these objects include Cholesky factors, and spatial graphs which store the adjacency matrices needed to perform graph convolutions: </p><pre><code class="language-julia hljs">struct Parameters &lt;: ParameterConfigurations
	θ::Matrix      # true parameters  
	L              # Cholesky factors
	g              # spatial graphs
	S              # spatial locations 
end</code></pre><p>Again, we define two constructors, which will be convenient for sampling parameters from the prior during training and assessment, and for parametric bootstrap sampling when making inferences from observed data:</p><pre><code class="language-julia hljs">function sample(K::Integer)
	# Sample parameters from the prior 
	θ = 0.5 * rand(1, K)

	# Sample spatial configurations from Matern cluster process on [0, 1]²
	n = rand(200:300, K)
	λ = rand(Uniform(10, 50), K)
	S = [maternclusterprocess(λ = λ[k], μ = n[k]/λ[k]) for k ∈ 1:K]

	# Pass to constructor
	Parameters(θ, S)
end

function Parameters(θ::Matrix, S)
	# Compute covariance matrices and Cholesky factors 
	L = Folds.map(axes(θ, 2)) do k
		D = pairwise(Euclidean(), S[k], dims = 1)
		Σ = Symmetric(exp.(-D ./ θ[k]))
		cholesky(Σ).L
	end

	# Construct spatial graphs
	g = spatialgraph.(S)

	# Store in Parameters object
	Parameters(θ, L, g, S)
end</code></pre><p>Next, we define a function for simulating from the model given an object of type <code>Parameters</code>. The code below enables simulation of an arbitrary number of independent replicates <code>m</code>, and one may provide a single integer for <code>m</code>, or any object that can be sampled using <code>rand(m, K)</code> (e.g., an integer range or some distribution over the possible sample sizes):</p><pre><code class="language-julia hljs">function simulate(parameters::Parameters, m)
	K = size(parameters, 2)
	m = rand(m, K)
	map(1:K) do k
		L = parameters.L[k]
		g = parameters.g[k]
		n = size(L, 1)
		Z = L * randn(n, m[k])      
		spatialgraph(g, Z)            
	end
end
simulate(parameters::Parameters, m::Integer = 1) = simulate(parameters, range(m, m))</code></pre><p>Next, we construct our GNN architecture. Here, we use an architecture tailored to isotropic spatial dependence models; for further details, see <a href="https://doi.org/10.1080/10618600.2024.2433671">Sainsbury-Dale et al. (2025, Sec. 2.2)</a>. We also employ a sparse approximation of the empirical variogram as an expert summary statistic (<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.382">Gerber and Nychka, 2021</a>).</p><p>In this example our goal is to construct a point estimator, however any other kind of estimator (see <a href="../../API/core/#Estimators">Estimators</a>) can be constructed by simply substituting the appropriate estimator class in the final line below:</p><pre><code class="language-julia hljs"># Spatial weight functions: continuous surrogates for 0-1 basis functions 
h_max = 0.15 # maximum distance to consider 
q = 10       # output dimension of the spatial weights
w = KernelWeights(h_max, q)

# Propagation module
propagation = GNNChain(
	SpatialGraphConv(1 =&gt; q, relu, w = w, w_out = q),
	SpatialGraphConv(q =&gt; q, relu, w = w, w_out = q)
)

# Readout module
readout = GlobalPool(mean)

# Inner network
ψ = GNNSummary(propagation, readout)

# Expert summary statistics, the empirical variogram
S = NeighbourhoodVariogram(h_max, q)

# Outer network
ϕ = Chain(
	Dense(2q =&gt; 128, relu), 
	Dense(128 =&gt; 128, relu), 
	Dense(128 =&gt; 1, identity)
)

# DeepSet object
network = DeepSet(ψ, ϕ; S = S)

# Point estimator
estimator = PointEstimator(network)</code></pre><p>Next, we train the estimator. </p><pre><code class="language-julia hljs">m = 1
K = 5000
θ_train = sample(K)
θ_val   = sample(K÷5)
estimator = train(estimator, θ_train, θ_val, simulate, m = m, epochs = 10)</code></pre><p>Note that the computations in GNNs are performed in parallel, making them particularly well-suited for GPUs, which typically contain thousands of cores. If you have access to an NVIDIA GPU, you can utilise it by simply loading the Julia package <code>CUDA</code>. </p><p>Next, we assess our trained estimator: </p><pre><code class="language-julia hljs">θ_test = sample(1000)
Z_test = simulate(θ_test, m)
assessment = assess(estimator, θ_test, Z_test)
bias(assessment)   
rmse(assessment)    
risk(assessment)   
plot(assessment)   </code></pre><p><img src="../../assets/figures/spatial.png" alt="Estimates from a graph neural network (GNN) based neural Bayes estimator"/></p><p>Finally, once the estimator has been assessed, it may be applied to observed data, with bootstrap-based uncertainty quantification facilitated by <a href="../../API/core/#NeuralEstimators.bootstrap"><code>bootstrap()</code></a> and <a href="../../API/core/#NeuralEstimators.interval"><code>interval()</code></a>. Note that, since the estimator was trained using spatial configurations in the unit square <span>$[0, 1] \times [0, 1]$</span>, the spatial coordinates of observed data should be scaled by a common factor such that they are also contained within this unit square; estimates of any range parameters are then scaled back accordingly. Below, we use simulated data as a substitute for observed data:</p><pre><code class="language-julia hljs">parameters = sample(1)             # sample a parameter vector and spatial locations              
θ = parameters.θ                   # true parameters
S = parameters.S                   # &quot;observed&quot; locations
Z = simulate(parameters)           # &quot;observed&quot; data    
θ̂ = estimate(estimator, Z)         # point estimate
ps = Parameters(θ̂, S)              # construct Parameters object from point estimate
bs = bootstrap(estimator, ps, simulate, m)  # parametric bootstrap estimates
interval(bs)                       # parametric bootstrap confidence interval              </code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../overview/">« Overview</a><a class="docs-footer-nextpage" href="../advancedusage/">Advanced usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.10.1 on <span class="colophon-date" title="Tuesday 15 April 2025 22:42">Tuesday 15 April 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
