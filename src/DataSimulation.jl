"""
	simulate(parameters::P, m::Integer, num_rep::Integer) where {P <: ParameterConfigurations}

Generic method that simulates `m` independent replicates for each parameter
configuration (by internally calling `simulate(parameters, m)`), repeated a
total of `num_rep` times.

See also [Data simulation](@ref).
"""
function simulate(parameters::P, m::Integer, num_rep::Integer) where {P <: ParameterConfigurations}
	v = [simulate(parameters, m) for i âˆˆ 1:num_rep]
	v = vcat(v...) # should be ok since we're only splatting num_rep vectors, which doesn't get prohibitively large even during bootstrapping. No reason not to use stack, though.
	return v
end

# Wrapper function that returns simulated data and the true parameter values
_simulate(params::P, m) where {P <: ParameterConfigurations} = (simulate(params, m), params.Î¸)



# ---- Gaussian process ----


"""
	simulategaussianprocess(L::AbstractArray{T, 2}, ÏƒÂ²::T, m::Integer)

Simulates `m` realisations from a Gau(0, ğšº + ÏƒÂ²ğˆ) distribution, where ğšº â‰¡ LL'.
"""
function simulategaussianprocess(L::AbstractArray{T, 2}, ÏƒÂ²::T, m::Integer) where T
	n = size(L, 1)
	y = similar(L, n, 1, m)
	for h âˆˆ 1:m
		y[:, :, 1, h] = simulategaussianprocess(L, ÏƒÂ²)
	end
	return y
end

function simulategaussianprocess(L::AbstractArray{T, 2}, ÏƒÂ²::T) where T
	n = size(L, 1)
	return simulategaussianprocess(L) + sqrt(ÏƒÂ²) * randn(T, n, n)
end

function simulategaussianprocess(L::AbstractArray{T, 2}) where T
	n = size(L, 1)
	y = randn(T, n)
	return L * y
end


# ---- Schlather's max-stable model ----

"""
	simulateschlather(L::AbstractArray{T, 2}; C = 3.5)
	simulateschlather(L::AbstractArray{T, 2}, m::Integer; C = 3.5)

Simulates from Schlather's max-stable model. Based on Algorithm 1.2.2 of Dey DK, Yan J (2016). Extreme value modeling and
risk analysis: methods and applications. CRC Press, Boca Raton, Florida.
"""
function simulateschlather(L::AbstractArray{T, 2}; C = 3.5) where T <: Number

	n = size(L, 1)  # number of spatial locations

	Z   = fill(zero(T), n) # TODO Why fill this with zeros? Just do undef.
	Î¶â»Â¹ = randexp(T)
	Î¶   = 1 / Î¶â»Â¹

	# A property of the model that must be enforced is E(max{0, Yáµ¢}) = 1. It can
	# be shown that this condition is satisfied if the marginal variance of Y(â‹…)
	# is equal to 2Ï€. Now, our simulation design embeds a marginal variance of 1
	# into fields generated from the cholesky factors, and hence
	# simulategaussianprocess(L) returns simulations from a Gaussian
	# process with marginal variance 1. To scale the marginal variance to
	# 2Ï€, we therefore need to multiply the field by âˆš(2Ï€).

	# Note that, compared with Algorithm 1.2.2 of Dey DK, Yan J (2016),
	# some simplifications have been made to the code below. This is because
	# max{Z(s), Î¶W(s)} â‰¡ max{Z(s), max{0, Î¶Y(s)}} = max{Z(s), Î¶Y(s)}, since
	# Z(s) is initialised to 0 and increases during simulation.
	while (Î¶ * C) > minimum(Z)
		Y = simulategaussianprocess(L)
		Y = âˆš(2Ï€)Y
		Z = max.(Z, Î¶ * Y)
		E = randexp(T)
		Î¶â»Â¹ += E
		Î¶ = 1 / Î¶â»Â¹
	end

	# Lenzi et al. used the log transform to stablise the variance, and this can
	# help avoid neural network collapse. Note that there is also a theoretical
	# justification for this transformation; it transforms from the data from
	# the unit FrÃ©chet scale to the Gumbel scale, which is typically better behaved.
	Z = log.(Z) # TODO decide if this is what we want to do; can add an arguement transform::Bool = true.

	return Z
end

function simulateschlather(L::AbstractArray{T, 2}, m::Integer; C = 3.5) where T <: Number
	n = size(L, 1)
	Z = similar(L, n, 1, m)
	for h âˆˆ 1:m
		Z[:, 1, h] = simulateschlather(L, C = C)
	end

	return Z
end


# ---- Conditional extremes ----

a(h, z; Î», Îº) = z * exp(-(h / Î»)^Îº)
b(h, z; Î², Î», Îº) = 1 + a(h, z, Î» = Î», Îº = Îº)^Î²
delta(h; Î´â‚) = 1 + exp(-(h / Î´â‚)^2)

CÌƒ(h, Ï, Î½) = matern(h, Ï, Î½)
ÏƒÌƒâ‚€(h, Ï, Î½) = âˆš(2 - 2 * CÌƒ(h, Ï, Î½))

# TODO Finish this documentation.
"""
	simulateconditionalextremes(L::AbstractArray{T, 2}, h, sâ‚€_idx, u; <keyword args>)
	simulateconditionalextremes(L::AbstractArray{T, 2}, h, sâ‚€_idx, m::Integer; <keyword args>)


Simulates from the spatial conditional extremes model.
"""
function simulateconditionalextremes(
	L::AbstractArray{T, 2}, h, sâ‚€_idx, u; # TODO should sâ‚€ just be provided rather than sâ‚€_idx? Also, is this the neatest treatment of the parameters? maybe u should be a keyword argument too.
	Ï, Î½, Îº, Î», Î², Î¼, Ï„, Î´â‚
	) where T <: Number

	# Construct the parameter Î´ used in the Subbotin distribution:
	Î´ = delta.(h, Î´â‚ = Î´â‚)

	# Observed datum at the conditioning site, Zâ‚€:
	Zâ‚€ = u + randexp(T)

	# Simulate a mean-zero Gaussian random field with unit marginal variance,
    # independently of Zâ‚€. Note that YÌƒ inherits the order of L. Therefore, we
	# can use sâ‚€_idx to access sâ‚€ in all subsequent vectors.
	n  = size(L, 1)  # number of spatial locations
	y  = randn(T, n)
	YÌƒ  = L * y

	# Adjust the Gaussian process so that it is 0 at sâ‚€
	YÌƒâ‚€ = YÌƒ .- YÌƒ[sâ‚€_idx]

	# Transform to unit variance:
	# ÏƒÌƒâ‚€ = sqrt.(2 .- 2 *  matern.(h, Ï, Î½))
	YÌƒâ‚€â‚ = YÌƒâ‚€ ./ ÏƒÌƒâ‚€.(h, Ï, Î½)
	YÌƒâ‚€â‚[sâ‚€_idx] = zero(T) # avoid pathology by setting YÌƒâ‚€â‚(sâ‚€) = 0.

	# Probability integral transform from the standard Gaussian scale to the
	# standard uniform scale, and then inverse probability integral transform
	# from the standard uniform scale to the Subbotin scale:
    Y = t.(YÌƒâ‚€â‚, Î¼, Ï„, Î´) # = Fâ‚›â»Â¹.(Î¦.(YÌƒâ‚€â‚), Î¼, Ï„, Î´)

	# Apply the functions a(â‹…) and b(â‹…) to simulate data throughout the domain:
	Z = a.(h, Zâ‚€, Î» = Î», Îº = Îº) + b.(h, Zâ‚€, Î² = Î², Î» = Î», Îº = Îº) .* Y

	# Variance stabilising transform
	Z = cbrt.(Z) # TODO decide if this is what we want to do; can add an arguement transform::Bool = true.

	return Z
end

function simulateconditionalextremes(L::AbstractArray{T, 2}, h, sâ‚€_idx, u, m::Integer; Ï, Î½, Îº, Î», Î², Î¼, Ï„, Î´â‚) where T <: Number
	n = size(L, 1)
	Z = similar(L, n, 1, m)
	Threads.@threads for k âˆˆ 1:m
		Z[:, 1, k] = simulateconditionalextremes(L, h, sâ‚€_idx, u, Ï = Ï, Î½ = Î½, Îº = Îº, Î» = Î», Î² = Î², Î¼ = Î¼, Ï„ = Ï„, Î´â‚ = Î´â‚)
	end

	return Z
end

# ---- Intermeditate functions ----

@doc raw"""
    matern(h, Ï, Î½, ÏƒÂ² = 1)
For two points separated by `h` units, compute the MatÃ©rn covariance function
with range `Ï`, smoothness `Î½`, and marginal variance `ÏƒÂ²`.

We use the parametrisation
``C(\mathbf{h}) = \sigma^2 \frac{2^{1 - \nu}}{\Gamma(\nu)} \left(\frac{\|\mathbf{h}\|}{\rho}\right) K_\nu \left(\frac{\|\mathbf{h}\|}{\rho}\right)``,
where ``\Gamma(\cdot)`` is the gamma function, and ``K_\nu(\cdot)`` is the modified Bessel
function of the second kind of order ``\nu``. This parameterisation is the same as used by the `R`
package `fields`, but differs to the parametrisation given by Wikipedia.

Note that the `Julia` functions for ``\Gamma(\cdot)`` and ``K_\nu(\cdot)``, respectively `gamma()` and
`besselk()`, do not work on the GPU and, hence, nor does `matern()`.
"""
function matern(h, Ï, Î½, ÏƒÂ² = 1)

	@assert h >= 0 "h should be non-negative"
	@assert Ï > 0 "Ï should be positive"
	@assert Î½ > 0 "Î½ should be positive"

	if h == 0
        C = ÏƒÂ²
    else
		d = h / Ï
        C = ÏƒÂ² * ((2^(1 - Î½)) / gamma(Î½)) * d^Î½ * besselk(Î½, d)
    end
    return C
end

matern(h, Ï) =  matern(h, Ï, 1)


@doc raw"""
	fâ‚›(x, Î¼, Ï„, Î´)
	Fâ‚›(q, Î¼, Ï„, Î´)
	Fâ‚›â»Â¹(p, Î¼, Ï„, Î´)

The density, distribution, and quantile functions Subbotin (delta-Laplace)
distribution with location parameter `Î¼`, scale parameter `Ï„`, and shape
parameter `Î´`:

```math
 f_S(y; \mu, \tau, \delta) = \frac{\delta}{2\tau \Gamma(1/\delta)} \exp{\left(-\left|\frac{y - \mu}{\tau}\right|^\delta\right)},\\
 F_S(y; \mu, \tau, \delta) = \frac{1}{2} + \textrm{sign}(y - \mu) \frac{1}{2 \Gamma(1/\delta)} \gamma\!\left(1/\delta, \left|\frac{y - \mu}{\tau}\right|^\delta\right),\\
 F_S^{-1}(p; \mu, \tau, \delta) = \text{sign}(p - 0.5)G^{-1}\left(2|p - 0.5|; \frac{1}{\delta}, \frac{1}{(k\tau)^\delta}\right)^{1/\delta} + \mu,
```

with ``\gamma(\cdot)`` and ``G^{-1}(\cdot)`` the unnormalised incomplete lower gamma function and quantile function of the Gamma distribution, respectively.

# Examples
```
p = [0.025, 0.05, 0.5, 0.9, 0.95, 0.975]

# Standard Gaussian:
Î¼ = 0.0; Ï„ = sqrt(2); Î´ = 2.0
Fâ‚›â»Â¹.(p, Î¼, Ï„, Î´)

# Standard Laplace:
Î¼ = 0.0; Ï„ = 1.0; Î´ = 1.0
Fâ‚›â»Â¹.(p, Î¼, Ï„, Î´)
```
"""
fâ‚›(x, Î¼, Ï„, Î´)   = Î´ * exp(-(abs((x - Î¼)/Ï„)^Î´)) / (2Ï„ * gamma(1/Î´))
Fâ‚›(q, Î¼, Ï„, Î´)   = 0.5 + 0.5 * sign(q - Î¼) * (1 / gamma(1/Î´)) * Î³(1/Î´, abs((q - Î¼)/Ï„)^Î´)
Fâ‚›â»Â¹(p, Î¼, Ï„, Î´) = Î¼ + sign(p - 0.5) * (Ï„^Î´ * quantile(Gamma(1/Î´), 2 * abs(p - 0.5)))^(1/Î´)


Ï•(y)   = pdf(Normal(0, 1), y)
Î¦(q)   = cdf(Normal(0, 1), q)
Î¦â»Â¹(p) = quantile(Normal(0, 1), p)
t(yÌƒâ‚€â‚, Î¼, Ï„, Î´) = Fâ‚›â»Â¹(Î¦(yÌƒâ‚€â‚), Î¼, Ï„, Î´)
tâ»Â¹(y, Î¼, Ï„, Î´) = Î¦â»Â¹(Fâ‚›(y, Î¼, Ï„, Î´))
tâ€²(y, Î¼, Ï„, Î´)  = Ï•(y) / fâ‚›(y, Î¼, Ï„, Î´) # NB this isn't used currently but it may be useful for unit testing
ln_tâ€²_tâ»Â¹(y, Î¼, Ï„, Î´) = log(Ï•(tâ»Â¹(y, Î¼, Ï„, Î´))) - log(fâ‚›(y, Î¼, Ï„, Î´))


# TODO add these in runtests.jl
# # Unit testing
# let
# 	# Check that the Subbotin pdf is consistent with the cdf using finite differences
# 	finite_diff(y, Î¼, Ï„, Î´, Ïµ = 0.000001) = (Fâ‚›(y + Ïµ, Î¼, Ï„, Î´) - Fâ‚›(y, Î¼, Ï„, Î´)) / Ïµ
# 	function finite_diff_check(y, Î¼, Ï„, Î´)
# 		@test abs(finite_diff(y, Î¼, Ï„, Î´) - fâ‚›(y, Î¼, Ï„, Î´)) < 0.0001
# 	end
#
# 	finite_diff_check(-1, 0.1, 3, 1.2)
# 	finite_diff_check(0, 0.1, 3, 1.2)
# 	finite_diff_check(0.9, 0.1, 3, 1.2)
# 	finite_diff_check(3.3, 0.1, 3, 1.2)
#
# 	# Check that fâ»Â¹(f(y)) â‰ˆ y
# 	Î¼ = 0.5; Ï„ = 1.3; Î´ = 2.4; y = 0.3
# 	@test abs(y - Fâ‚›â»Â¹(Fâ‚›(y, Î¼, Ï„, Î´), Î¼, Ï„, Î´)) < 0.0001
# 	@test abs(y - tâ»Â¹(t(y, Î¼, Ï„, Î´), Î¼, Ï„, Î´)) < 0.0001
# end
