#TODO add example once I add simulateconditionalGP
#TODO Improve documentation (math display isn't the best here)
@doc raw"""
    EM(simulateconditional::Function, MAP::Function, Î¸â‚€ = nothing)
A type that implements the Monte Carlo variant of the expectation-maximisation
(EM) algorithm, which at ``l``th iteration finds the value of ğ›‰ that maximises

```math
Î£â‚•á´´ â„“(ğ›‰;  ğ™â‚,  ğ™â‚‚Ë¡Ê°) + log Ï€á´´(ğ›‰),
```

where â„“(â‹…) is the complete-data log-likelihood function, ğ™ â‰¡ (ğ™â‚', ğ™â‚‚')'
denotes the complete data with ğ™â‚ and ğ™â‚‚ the observed and missing components,
respectively, the replicate ğ™â‚‚Ë¡Ê°, h = 1, â€¦, H, is sampled from the conditional probability
distribution of ğ™â‚‚ given ğ™â‚ and the previous estimates ğ›‰Ë¡â»Â¹, and
Ï€á´´(â‹…) â‰¡ {Ï€(â‹…)}á´´  is a concentrated version of the original prior density.

# Fields

The function `simulateconditional` should be of the form,

	simulateconditional(Z::A, Î¸; nsims::Integer = 1) where {A <: AbstractArray{Union{Missing, T}}} where T

and the completed-data `Z` should be returned in whatever form is
appropriate to be passed to the MAP estimator as `MAP(Z)`. For example, if the
data are gridded and the `MAP` is a neural MAP estimator based on a CNN
architecture, then `Z` should be returned as a four-dimensional array.

Note that the `MAP` estimator should return the *joint* posterior mode;
therefore, a neural MAP estimator should be trained under (a surrogate for) the
joint 0-1 loss function (see [`kpowerloss`](@ref)).

The starting values `Î¸â‚€` should be a vector, which can be provided either during
construction of the `EM` object, or when applying the `EM` object to data
(see below). The starting values given in a function call take precedence over
those stored in the object.

# Methods

Once constructed, obects of type `EM` can be applied to data via the methods,

	(em::EM)(Z::A, Î¸â‚€::Union{Nothing, Vector} = nothing; ...) where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}
	(em::EM)(Z::V, Î¸â‚€::Union{Nothing, Vector, Matrix} = nothing; ...) where {V <: AbstractVector{A}} where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}

where `Z` is the complete data containing the observed data and `Missing` values.
Note that the second method caters for the case that one has multiple data sets.
The keyword arguments are:

- `niterations::Integer = 50`: the maximum number of iterations.
- `nsims::Integer = 1`: the number of conditional replicates used to approximate the conditional expectation.
- `Î¾ = nothing`: model information needed for conditional simulation (e.g., distance matrices) or in the MAP estimator.
- `use_Î¾_in_simulateconditional::Bool = false`: if set to `true`, the conditional simulator is called as `simulateconditional(Z, Î¸, Î¾; nsims = nsims)`.
- `use_Î¾_in_MAP::Bool = false`: if set to `true`, the MAP estimator is applied to the conditionally-completed data as `MAP(Z, Î¾)`.
- `Ïµ = 0.01`: tolerance used to assess convergence; The algorithm if the relative change in parameter values from successive iterations is less than `Ïµ`.
- `return_iterates`: if `true`, the estimate at each iteration of the algorithm is returned; otherwise, only the final estimate is returned.
- `use_gpu::Bool = true`
- `verbose::Bool = false`
"""
struct EM{F,T,S}
	simulateconditional::F
	MAP::T
	Î¸â‚€::S
end
EM(simulateconditional, MAP) = EM(simulateconditional, MAP, nothing)
EM(em::EM, Î¸â‚€) = EM(em.simulateconditional, em.MAP, Î¸â‚€)

function (em::EM)(Z::A, Î¸â‚€ = nothing; args...)  where {A <: AbstractArray{T, N}} where {T, N}
	@warn "Data has been passed to the EM algorithm that contains no missing elements... the MAP estimator will be applied directly to the data"
	em.MAP(Z)
end

function (em::EM)(
	Z::A, Î¸â‚€ = nothing;
	niterations::Integer = 50,
	nsims::Integer = 1,
	Ïµ = 0.01,
	Î¾ = nothing,
	use_Î¾_in_simulateconditional::Bool = false,
	use_Î¾_in_MAP::Bool = false,
	use_gpu::Bool = true,
	verbose::Bool = false,
	return_iterates::Bool = false
	)  where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}

	if isnothing(Î¸â‚€)
		@assert !isnothing(em.Î¸â‚€) "Please provide initial estimates Î¸â‚€ in the function call when applying the `EM` object, or in the `EM` object itself."
		Î¸â‚€ = em.Î¸â‚€
	end

	if !isnothing(Î¾)
		if !use_Î¾_in_simulateconditional && !use_Î¾_in_MAP
			@warn "`Î¾` has been provided but it will not be used because `use_Î¾_in_simulateconditional` and `use_Î¾_in_MAP` are both `false`"
		end
	end

	if use_Î¾_in_simulateconditional || use_Î¾_in_MAP
		@assert !isnothing(Î¾) "`Î¾` must be provided since `use_Î¾_in_simulateconditional` or `use_Î¾_in_MAP` is true"
	end

	@assert !all(ismissing.(Z))  "The data `Z` consists of missing elements only"

	device = _checkgpu(use_gpu, verbose = verbose)
	MAP = em.MAP |> device

	verbose && @show Î¸â‚€
    Î¸â‚— = Î¸â‚€
	Î¸_all = reshape(Î¸â‚€, :, 1)
	for l âˆˆ 1:niterations

		# "Complete" the data by simulating missing data conditionally on the
		# incomplete observed data and the current parameters
		ZÌƒ = use_Î¾_in_simulateconditional ? em.simulateconditional(Z, Î¸â‚—, Î¾, nsims = nsims) : em.simulateconditional(Z, Î¸â‚—, nsims = nsims)
		ZÌƒ = ZÌƒ |> device

		# Apply the MAP estimator to the complete data
		Î¸â‚—â‚Šâ‚ = use_Î¾_in_MAP ? MAP(ZÌƒ, Î¾) : MAP(ZÌƒ)

		# Move back to the cpu (need to do this for simulateconditional in the next iteration)
		Î¸â‚—â‚Šâ‚   = cpu(Î¸â‚—â‚Šâ‚)
		Î¸_all = hcat(Î¸_all, Î¸â‚—â‚Šâ‚)

		if maximum(abs.(Î¸â‚—â‚Šâ‚-Î¸â‚—)./abs.(Î¸â‚—)) < Ïµ
			verbose && @info "The EM algorithm has converged"
			Î¸â‚— = Î¸â‚—â‚Šâ‚
			break
		end

		l == niterations && verbose && @warn "The EM algorithm has failed to converge"

		Î¸â‚— = Î¸â‚—â‚Šâ‚

		verbose && @show Î¸â‚—
	end

    return_iterates ? Î¸_all : Î¸â‚— # note that Î¸â‚— is contained in Î¸_all
end

function (em::EM)(Z::V, Î¸â‚€::Union{Vector, Matrix, Nothing} = nothing; args...) where {V <: AbstractVector{A}} where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}

	if isnothing(Î¸â‚€)
		@assert !isnothing(em.Î¸â‚€) "Please provide initial estimates `Î¸â‚€` in the function call or in the `EM` object."
		Î¸â‚€ = em.Î¸â‚€
	end

	if isa(Î¸â‚€, Vector)
		Î¸â‚€ = repeat(Î¸â‚€, 1, length(Z))
	end

	estimates = map(eachindex(Z)) do i
		em(Z[i], Î¸â‚€[:, i]; args...)
	end
	estimates = reduce(hcat, estimates)

	return estimates
end


"""
	removedata(Z::Array, Iáµ¤::Vector{Integer})
	removedata(Z::Array, p::Union{Float, Vector{Float}}; prevent_complete_missing = true)
	removedata(Z::Array, n::Integer; fixed_pattern = false, contiguous_pattern = false, variable_proportion = false)

Replaces elements of `Z` with `missing`.

The simplest method accepts a vector of integers `Iáµ¤` that give the specific indices
of the data to be removed.

Alterntivaly, there are two methods available to generate data that are
missing completely at random (MCAR).

First, a vector `p` may be given that specifies the proportion of missingness
for each element in the response vector. Hence, `p` should have length equal to
the dimension of the response vector. If a single proportion is given, it
will be replicated accordingly. If `prevent_complete_missing = true`, no
replicates will contain 100% missingness (note that this can slightly alter the
effective values of `p`).

Second, if an integer `n` is provided, all replicates will contain
`n` observations after the data are removed. If `fixed_pattern = true`, the
missingness pattern is fixed for all replicates. If `contiguous_pattern = true`,
the data will be removed in a contiguous block. If `variable_proportion = true`,
the proportion of missingness will vary across replicates, with each replicate containing
between 1 and `n` observations after data removal, sampled uniformly (note that
`variable_proportion` overrides `fixed_pattern`).

The return type is `Array{Union{T, Missing}}`.

# Examples
```
d = 5           # dimension of each replicate
m = 2000        # number of replicates
Z = rand(d, m)  # simulated data

# Passing a desired proportion of missingness
p = rand(d)
removedata(Z, p)

# Passing a desired final sample size
n = 3  # number of observed elements of each replicate: must have n <= d
removedata(Z, n)
```
"""
function removedata(Z::A, n::Integer;
					fixed_pattern::Bool = false,
					contiguous_pattern::Bool = false,
					variable_proportion::Bool = false
					) where {A <: AbstractArray{T, N}} where {T, N}
	if isa(Z, Vector) Z = reshape(Z, :, 1) end
	m = size(Z)[end]           # number of replicates
	d = prod(size(Z)[1:end-1]) # dimension of each replicate  NB assumes a singleton channel dimension

	if n == d
		# If the user requests fully observed data, we still convert Z to
		# an array with an eltype that allows missing data for type stability
		Iáµ¤ = Int64[]

	elseif variable_proportion

		Zstar = map(eachslice(Z; dims = N)) do z
			# Pass number of observations between 1:n into removedata()
			removedata(
				reshape(z, size(z)..., 1),
				StatsBase.sample(1:n, 1)[1],
				fixed_pattern = fixed_pattern,
				contiguous_pattern = contiguous_pattern,
				variable_proportion = false
				)
		end

		return stackarrays(Zstar)

	else

		# Generate the missing elements
		if fixed_pattern
			if contiguous_pattern
				start = StatsBase.sample(1:n+1, 1)[1]
				Iáµ¤ = start:(start+(d-n)-1)
			else
				Iáµ¤ = StatsBase.sample(1:d, d-n, replace = false)
				
			end
			Iáµ¤ = [Iáµ¤ .+ (i-1) * d for i âˆˆ 1:m]
		else
			if contiguous_pattern
				Iáµ¤ = map(1:m) do i
					start = (StatsBase.sample(1:n+1, 1) .+ (i-1) * d)[1]
					start:(start+(d-n)-1)
				end
			else
				Iáµ¤ = [StatsBase.sample((1:d) .+ (i-1) * d, d - n, replace = false) for i âˆˆ 1:m]
			end
		end
		Iáµ¤ = vcat(Iáµ¤...)
	end

	return removedata(Z, Iáµ¤)
end
function removedata(Z::V, n::Integer; args...) where {V <: AbstractVector{T}} where {T}
	removedata(reshape(Z, :, 1), n)[:]
end

function removedata(Z::A, p::F; args...) where {A <: AbstractArray{T, N}} where {T, N, F <: AbstractFloat}
	if isa(Z, Vector) Z = reshape(Z, :, 1) end
	d = prod(size(Z)[1:end-1]) # dimension of each replicate  NB assumes singleton channel dimension
	p = repeat([p], d)
	return removedata(Z, p; args...)
end
function removedata(Z::V, p::F; args...) where {V <: AbstractVector{T}} where {T, F <: AbstractFloat}
	removedata(reshape(Z, :, 1), p)[:]
end

function removedata(Z::A, p::Vector{F}; prevent_complete_missing::Bool = true) where {A <: AbstractArray{T, N}} where {T, N, F <: AbstractFloat}
	if isa(Z, Vector) Z = reshape(Z, :, 1) end
	m = size(Z)[end]           # number of replicates
	d = prod(size(Z)[1:end-1]) # dimension of each replicate  NB assumes singleton channel dimension
	@assert length(p) == d "The length of `p` should equal the dimenison d of each replicate"
	multivariatebernoulli = product_distribution([Bernoulli(p[i]) for i âˆˆ eachindex(p)])

	if all(p .== 1) prevent_complete_missing = false end

	if prevent_complete_missing
		Iáµ¤ = map(1:m) do _
			complete_missing = true
			while complete_missing
				Iáµ¤ = rand(multivariatebernoulli)
				complete_missing = !(0 âˆˆ Iáµ¤)
			end
			Iáµ¤
		end
	else
		Iáµ¤ = [rand(multivariatebernoulli) for _ âˆˆ 1:m]
	end

	Iáµ¤ = stackarrays(Iáµ¤)
	Iáµ¤ = findall(Iáµ¤)

	return removedata(Z, Iáµ¤)
end
function removedata(Z::V, p::Vector{F}; args...) where {V <: AbstractVector{T}} where {T, F <: AbstractFloat}
	removedata(reshape(Z, :, 1), p)[:]
end

function removedata(Z::A, Iáµ¤::V) where {A <: AbstractArray{T, N}, V <: AbstractVector{I}} where {T, N, I <: Integer}

	# Convert the Array to a type that allows missing data
	Zâ‚ = convert(Array{Union{T, Missing}}, Z)

	# Remove the data from the missing elements
	Zâ‚[Iáµ¤] .= missing

	return Zâ‚
end



"""
	encodedata(Z::A; fixed_constant::T = zero(T)) where {A <: AbstractArray{Union{Missing, T}, N}} where T, N
For data `Z` with missing entries, returns an augmented data set (U, W) where
W encodes the missingness pattern as an indicator vector and U is the original data Z
with missing entries replaced by a `fixed_constant`.

The indicator vector W is stored in the second-to-last dimension of `Z`, which
should be a singleton. If the second-to-last dimension is not singleton, then
two singleton dimensions will be added to the array, and W will be stored in
the new second-to-last dimension.

# Examples
```
using NeuralEstimators

# Generate some missing data
Z = rand(16, 16, 1, 1)
Z = removedata(Z, 0.25)	 # remove 25% of the data

# Encode the data
UW = encodedata(Z)
```
"""
function encodedata(Z::A; fixed_constant::T = zero(T)) where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}

	# Store the container type for later use
	ArrayType = containertype(Z)

	# Make some space for the indicator variable
	if N == 1 || size(Z, N-1) != 1
		Z = reshape(Z, (size(Z)..., 1, 1))
		NÌƒ = N + 2
	else
		NÌƒ = N
	end

	# Compute the indicator variable and the augmented data
	W = isnotmissing.(Z)
	U = copy(Z) # copy to avoid mutating the original data
	U[ismissing.(U)] .= fixed_constant

	# Convert from eltype of U from Union{Missing, T} to T
	# U = convert(Array{T, N}, U) # NB this doesn't work if Z was modified in the if statement
	U = convert(ArrayType{T, NÌƒ}, U)

	# Combine the augmented data and the indicator variable
	UW = cat(U, W; dims = NÌƒ - 1)

	return UW
end
isnotmissing(x) = !(ismissing(x))