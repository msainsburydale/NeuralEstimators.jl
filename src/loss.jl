# This is an internal function used in Flux to check the size of the
# arguments passed to a loss function
function _check_sizes(yÌ‚::AbstractArray, y::AbstractArray)
  for d in 1:max(ndims(yÌ‚), ndims(y))
   size(yÌ‚,d) == size(y,d) || throw(DimensionMismatch(
      "loss function expects size(yÌ‚) = $(size(yÌ‚)) to match size(y) = $(size(y))"
    ))
  end
end
_check_sizes(yÌ‚, y) = nothing  # pass-through, for constant label e.g. y = 1
@non_differentiable _check_sizes(yÌ‚::Any, y::Any)


# ---- surrogates for 0-1 loss ----

@doc raw"""
    tanhloss(Î¸Ì‚, Î¸, k; agg = mean, joint = true)

For `k` > 0, computes the loss function,

```math
L(Î¸Ì‚, Î¸) = \textrm{tanh}(|Î¸Ì‚ - Î¸|/k),
```

which approximates the 0-1 loss as `k` â†’ 0. Compared with the [`kpowerloss`](@ref), 
which may also be used as a continuous surrogate for the 0-1 loss, the gradient of
the tanh loss is bounded as |Î¸Ì‚ - Î¸| â†’ 0, which can improve numerical stability during 
training. 

If `joint = true`, the Lâ‚ norm is computed over each parameter vector, so that, with 
`k` close to zero, the resulting Bayes estimator is the mode of the joint posterior distribution;
otherwise, if `joint = false`, the Bayes estimator is the vector containing the modes of the
marginal posterior distributions.

See also [`kpowerloss`](@ref).
"""
function tanhloss(Î¸Ì‚, Î¸, k; agg = mean, joint::Bool = true)

  _check_sizes(Î¸Ì‚, Î¸)

  d = abs.(Î¸Ì‚ .- Î¸)
  if joint
     d = sum(d, dims = 1)
  end

  L = tanh_fast(d ./ k)

  return agg(L)
end


"""
    kpowerloss(Î¸Ì‚, Î¸, k; agg = mean, joint = true, safeorigin = true, Ïµ = 0.1)

For `k` > 0, the `k`-th power absolute-distance loss function,

```math
L(Î¸Ì‚, Î¸) = |Î¸Ì‚ - Î¸|áµ,
```

contains the squared-error, absolute-error, and 0-1 loss functions as special
cases (the latter obtained in the limit as `k` â†’ 0). It is Lipschitz continuous
iff `k` = 1, convex iff `k` â‰¥ 1, and strictly convex iff `k` > 1: it is
quasiconvex for all `k` > 0.

If `joint = true`, the Lâ‚ norm is computed over each parameter vector, so that, with 
`k` close to zero, the resulting Bayes estimator is the mode of the joint posterior distribution;
otherwise, if `joint = false`, the Bayes estimator is the vector containing the modes of the
marginal posterior distributions.

If `safeorigin = true`, the loss function is modified to avoid pathologies
around the origin, so that the resulting loss function behaves similarly to the
absolute-error loss in the `Ïµ`-interval surrounding the origin.

See also [`tanhloss`](@ref).
"""
function kpowerloss(Î¸Ì‚, Î¸, k; safeorigin::Bool = true, agg = mean, Ïµ = ofeltype(Î¸Ì‚, 0.1), joint::Bool = true)

   _check_sizes(Î¸Ì‚, Î¸)

   d = abs.(Î¸Ì‚ .- Î¸)
   if joint
      d = sum(d, dims = 1)
   end

   if safeorigin
     b = d .>  Ïµ
     L = vcat(d[b] .^ k, _safefunction.(d[.!b], k, Ïµ))
   else
     L = d.^k
   end

   return agg(L)
end

function _safefunction(d, k, Ïµ)
  @assert d >= 0
  Ïµ^(k - 1) * d
end

# ---- quantile loss ----

#TODO write the maths for when we have a vector Ï„
"""
    quantileloss(Î¸Ì‚, Î¸, Ï„; agg = mean)
    quantileloss(Î¸Ì‚, Î¸, Ï„::Vector; agg = mean)

The asymmetric quantile loss function,
```math
  L(Î¸Ì‚, Î¸; Ï„) = (Î¸Ì‚ - Î¸)(ğ•€(Î¸Ì‚ - Î¸ > 0) - Ï„),
```
where `Ï„` âˆˆ (0, 1) is a probability level and ğ•€(â‹…) is the indicator function.

The method that takes `Ï„` as a vector is useful for jointly approximating
several quantiles of the posterior distribution. In this case, the number of
rows in `Î¸Ì‚` is assumed to be ``pr``, where ``p`` is the number of parameters and
``r`` is the number probability levels in `Ï„` (i.e., the length of `Ï„`).

# Examples
```
p = 1
K = 10
Î¸ = rand(p, K)
Î¸Ì‚ = rand(p, K)
quantileloss(Î¸Ì‚, Î¸, 0.1)

Î¸Ì‚ = rand(3p, K)
quantileloss(Î¸Ì‚, Î¸, [0.1, 0.5, 0.9])

p = 2
Î¸ = rand(p, K)
Î¸Ì‚ = rand(p, K)
quantileloss(Î¸Ì‚, Î¸, 0.1)

Î¸Ì‚ = rand(3p, K)
quantileloss(Î¸Ì‚, Î¸, [0.1, 0.5, 0.9])
```
"""
function quantileloss(Î¸Ì‚, Î¸, Ï„; agg = mean)
  _check_sizes(Î¸Ì‚, Î¸)
  d = Î¸Ì‚ .- Î¸
  b = d .> 0
  bÌƒ = .!b
  Lâ‚ = d[b] * (1 - Ï„)
  Lâ‚‚ = -Ï„ * d[bÌƒ]
  L = vcat(Lâ‚, Lâ‚‚)
  agg(L)
end

function quantileloss(Î¸Ì‚, Î¸, Ï„::V; agg = mean) where {T, V <: AbstractVector{T}}

  Ï„ = convert(containertype(Î¸Ì‚), Ï„) # convert Ï„ to the gpu (this line means that users don't need to manually move Ï„ to the gpu)

  # Check that the sizes match
  @assert size(Î¸Ì‚, 2) == size(Î¸, 2)
  p, K = size(Î¸)

  if length(Ï„) == K # different Ï„ for each training sample => must be training continuous quantile estimator with Ï„ as input
    @ignore_derivatives Ï„ = repeat(Ï„', p) # just repeat Ï„ to match the number of parameters in the statistical model
    quantileloss(Î¸Ì‚, Î¸, Ï„; agg = agg)
  else # otherwise, we must training a discrete quantile estimator for some fixed set of probability levels

    rp = size(Î¸Ì‚, 1)
    @assert rp % p == 0
    r = rp Ã· p
    @assert length(Ï„) == r

    # repeat the arrays to facilitate broadcasting and indexing
    # note that repeat() cannot be differentiated by Zygote
    @ignore_derivatives Ï„ = repeat(Ï„, inner = (p, 1), outer = (1, K))
    @ignore_derivatives Î¸ = repeat(Î¸, r)

    quantileloss(Î¸Ì‚, Î¸, Ï„; agg = agg)
  end
end

#NB matrix method is only used internally, and therefore not documented 
function quantileloss(Î¸Ì‚, Î¸, Ï„::M; agg = mean) where {T, M <: AbstractMatrix{T}}
  d = Î¸Ì‚ .- Î¸
  b = d .> 0
  bÌƒ = .!b
  Lâ‚ = d[b] .* (1 .- Ï„[b])
  Lâ‚‚ = -Ï„[bÌƒ] .* d[bÌƒ]
  L = vcat(Lâ‚, Lâ‚‚)
  agg(L)
end


# ---- interval score ----

"""
    intervalscore(l, u, Î¸, Î±; agg = mean)
    intervalscore(Î¸Ì‚, Î¸, Î±; agg = mean)
    intervalscore(assessment::Assessment; average_over_parameters::Bool = false, average_over_sample_sizes::Bool = true)

Given an interval [`l`, `u`] with nominal coverage 100Ã—(1-`Î±`)%  and true value `Î¸`, the
interval score is defined by

```math
S(l, u, Î¸; Î±) = (u - l) + 2Î±â»Â¹(l - Î¸)ğ•€(Î¸ < l) + 2Î±â»Â¹(Î¸ - u)ğ•€(Î¸ > u),
```

where `Î±` âˆˆ (0, 1) and ğ•€(â‹…) is the indicator function.

The method that takes a single value `Î¸Ì‚` assumes that `Î¸Ì‚` is a matrix with ``2p`` rows,
where ``p`` is the number of parameters in the statistical model. Then, the first
and second set of ``p`` rows will be used as `l` and `u`, respectively.

For further discussion, see Section 6 of Gneiting, T. and Raftery, A. E. (2007),
"Strictly proper scoring rules, prediction, and estimation",
Journal of the American statistical Association, 102, 359â€“378.
"""
function intervalscore(l, u, Î¸, Î±; agg = mean)

  bâ‚ = Î¸ .< l
  bâ‚‚ = Î¸ .> u

  S = u - l
  S = S + bâ‚ .* (2 / Î±) .* (l .- Î¸)
  S = S + bâ‚‚ .* (2 / Î±) .* (Î¸ .- u)

  agg(S)
end

function intervalscore(Î¸Ì‚, Î¸, Î±; agg = mean)

  @assert size(Î¸Ì‚, 1) % 2 == 0
  p = size(Î¸Ì‚, 1) Ã· 2
  l = Î¸Ì‚[1:p, :]
  u = Î¸Ì‚[(p+1):end, :]

  intervalscore(l, u, Î¸, Î±, agg = agg)
end